{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Sentinel-1 SLC data via SARA <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `DEA Sandbox` environment only\n",
    "* **Products used:** \n",
    "[S1 SLC granules](https://copernicus.nci.org.au/sara.client/#/explore?collection=S1)\n",
    "* **Special requirements:** Need to `pip install` the `auscophub` and `PyRAT` packages directly from Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "This notebook demonstrates a recipe for working with Sentinel-1 Single Look Complex (SLC) data to quickly identify possible burn scar areas using Complex data at the native resolution of the SAR sensor. This notebook was developed during a SAR Workshop day and will be progressed into a Real World Sample as actual fire based variability is noted. The sample area used in this notebook is over [Orroral Valley](https://www.google.com/maps/place/Orroral+Valley/@-35.6168882,148.6665058,10z/data=!4m13!1m7!3m6!1s0x6b17d73435882e61:0x2440e61df2404dce!2sOrroral+Valley!3b1!8m2!3d-35.61689!4d148.9466573!3m4!1s0x6b17d73435882e61:0x2440e61df2404dce!8m2!3d-35.61689!4d148.9466573).\n",
    "\n",
    "The [Sentinel-1 mission](https://sentinel.esa.int/web/sentinel/missions/sentinel-1) comprises a constellation of two polar-orbiting satellites, operating day and night performing C-band synthetic aperture radar imaging, enabling them to acquire imagery regardless of the weather. The Single Look Complex Data product represents the [first level of processing](https://sentinel.esa.int/web/sentinel/level-1-slc-processing-algorithms) beyond raw echoes at the sensor level to form an image.\n",
    "\n",
    "[SARA](http://www.copernicus.gov.au/regionaldataaccess) provides intuitive map-based data search and download capability, as well as an API for advanced user interaction. This notebook uses the REST API via a purpose built Python client to search and download imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook sets up some basic steps to find and work with SLC data:\n",
    "\n",
    "1. Install [Auscophub](https://github.com/CopernicusAustralasia/auscophub) Python package. \n",
    "1. Locate Sentinel-1 SLC datasets over Orroral Valley using [Copernicus Hub Australia](https://copernicus.nci.org.au/sara.client/#/explore).\n",
    "2. Download the SARA results and unpack them.\n",
    "3. Perform some exploratory data extraction and plotting using GDAL [Complex Tiff](https://gdal.org/drivers/raster/gtiff.html) with `Cfloat64` datatype, and allocate enough RAM for this.\n",
    "4. Install the [PyRAT](https://github.com/birgander2/PyRAT) Python package.\n",
    "5. Load Sentinel-1 SLC data for a specific granule and produce a preview.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "This notebook requires two packages which should be installed via `!pip install --user` in a notebook cell or in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Load various packages and install additional ones in `--user` mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\u001b[0m\n",
      "\u001b[31mERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!export DISPLAY=0:0 && pip install --user git+https://github.com/whatnick/PyRAT\n",
    "!pip install --user git+https://github.com/CopernicusAustralasia/auscophub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'auscophub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b64194379bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mosgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdal\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mauscophub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaraclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# from pylab import plot, imshow, figure, scatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'auscophub'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import glob\n",
    "import datacube\n",
    "import requests\n",
    "import zipfile\n",
    "import logging\n",
    "import numpy as np\n",
    "import osgeo.gdal as gdal\n",
    "from datetime import datetime\n",
    "from auscophub import saraclient\n",
    "from shapely.geometry import Point\n",
    "# from pylab import plot, imshow, figure, scatter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from SARA\n",
    "\n",
    "### Connect to SARA and get some search results over Orroral\n",
    "- Create a 0.01 degree buffer around the point of interest\n",
    "- Perform a parametric search query and derive an array of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set location for SARA query\n",
    "orroral_polygon = Point(148.96,-35.58).buffer(0.01)\n",
    "\n",
    "queryParams = [\n",
    "               'collection=S1',\n",
    "               'instrument=C-SAR',\n",
    "               'productType=SLC',\n",
    "               'startDate=2020-01-01',\n",
    "               'completionDate=2020-02-04',\n",
    "               'page=1',\n",
    "               'orbitNumber=147',\n",
    "               f'geometry={orroral_polygon.to_wkt()}']\n",
    "\n",
    "# Run SARA query\n",
    "urlOpener = saraclient.makeUrlOpener()\n",
    "results = saraclient.searchSara(urlOpener, 1, queryParams)\n",
    "\n",
    "# Extract scene ideas from the query result\n",
    "scene_ids = [x['properties']['productIdentifier'] for x in results]\n",
    "\n",
    "# Print scene IDs\n",
    "print(scene_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download SARA results using Authenticated Access\n",
    "* [Sign up](https://copernicus.nci.org.au/sara.client/#/register) to SARA and note down the username/password for your account.\n",
    "* Create a file called **sara_creds.json**\n",
    "* Store username and password in this file in this format:\n",
    "    ```\n",
    "    {\n",
    "        \"username\":\"username@ga.gov.au\",\n",
    "        \"password\":\"download_password\"\n",
    "    }\n",
    "    ```\n",
    "* Read this JSON into the notebook and use it authenticate to SARA and download the data\n",
    "* This notebook includes a convenience download method with a progress bar. **This step can take several minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s1_file(result, verbose = False, auth = None):\n",
    "    \"\"\"\n",
    "    Download file with progressbar\n",
    "    Uses adapted version of the code here :\n",
    "    https://gist.github.com/ruxi/5d6803c116ec1130d484a4ab8c00c603\n",
    "    \"\"\"\n",
    "    local_filename = f\"{result['properties']['productIdentifier']}.zip\"\n",
    "    local_filename = os.path.join('/notebooks',local_filename)\n",
    "    url = result['properties']['services']['download']['url']\n",
    "    r = requests.get(url, stream=True, auth = auth)\n",
    "    file_size = int(r.headers['Content-Length'])\n",
    "    chunk = 1\n",
    "    chunk_size=1024\n",
    "    num_bars = int(file_size / chunk_size)\n",
    "    if verbose:\n",
    "        print(dict(file_size=file_size))\n",
    "        print(dict(num_bars=num_bars))\n",
    "\n",
    "    with open(local_filename, 'wb') as fp:\n",
    "        for chunk in tqdm.tqdm(r.iter_content(chunk_size=chunk_size), \n",
    "                               total= num_bars,\n",
    "                               unit = 'KB',\n",
    "                               desc = local_filename,\n",
    "                               leave = True # progressbar stays\n",
    "                               ):\n",
    "            fp.write(chunk)\n",
    "            fp.flush()\n",
    "    return\n",
    "\n",
    "# Load credentials and download data\n",
    "credentials = json.load(open('sara_creds.json'))\n",
    "auth=(credentials['username'], credentials['password'])\n",
    "for result in results:\n",
    "    scene_id = result['properties']['productIdentifier']\n",
    "    print(scene_id)\n",
    "    filename = f'{scene_id}.zip'\n",
    "    filename = os.path.join('/notebooks', filename)\n",
    "    if not os.path.exists(filename):\n",
    "        try:\n",
    "            download_s1_file(result, auth=auth)\n",
    "        except HTTPError as hte:\n",
    "            print(f\"Failed to Download: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data\n",
    "Please be patient: **this step can take several minutes to complete**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = datetime.now()\n",
    "for result in results:\n",
    "    scene_id = result['properties']['productIdentifier']\n",
    "    filename = os.path.join('/notebooks', f'{scene_id}.zip')\n",
    "    out_dir = f'{scene_id}.SAFE'\n",
    "    out_dir = os.path.join('/notebooks', out_dir)\n",
    "    print(f'Extracting data from {filename}')\n",
    "    if not os.path.isdir(out_dir):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            try:\n",
    "                zip_ref.extractall('/notebooks')\n",
    "            except:\n",
    "                print(f\"    Corrupted: {filename}\")\n",
    "                os.unlink(filename)\n",
    "time_finish = datetime.now()\n",
    "print(f\"Extracted in {str(time_finish-time_start)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse SLC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDAL GCP Mechanism for quick georeferencing\n",
    "- SLC data carries a grid of GCPs for indicative georeferencing\n",
    "- [Helmert transforms](https://proj.org/operations/transformations/helmert.html) can be performed for low distortion warping of SLC domain products approximately to geographic co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_ds = gdal.Open('/notebooks/S1A_IW_SLC__1SDV_20200129T191613_20200129T191639_031019_039028_1537.SAFE')\n",
    "\n",
    "sds_list = s1_ds.GetSubDatasets()\n",
    "IW1_ds = gdal.Open(sds_list[2][0])\n",
    "IW2_ds = gdal.Open(sds_list[5][0])\n",
    "IW3_ds = gdal.Open(sds_list[8][0])\n",
    "\n",
    "lon_1 = [gcp.GCPX for gcp in IW1_ds.GetGCPs()]\n",
    "lat_1 = [gcp.GCPY for gcp in IW1_ds.GetGCPs()]\n",
    "lon_2 = [gcp.GCPX for gcp in IW2_ds.GetGCPs()]\n",
    "lat_2 = [gcp.GCPY for gcp in IW2_ds.GetGCPs()]\n",
    "lon_3 = [gcp.GCPX for gcp in IW3_ds.GetGCPs()]\n",
    "lat_3 = [gcp.GCPY for gcp in IW3_ds.GetGCPs()]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "axs.scatter(lon_1, lat_1, color='k')\n",
    "axs.scatter(lon_2, lat_2, color='b')\n",
    "axs.scatter(lon_2, lat_2, color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some exploratory plotting of Orroral SLC data\n",
    "\n",
    "The exploratory plots show very good alignment of the data in both dynamic range and geographic extents purely in pixel domain without additional geometric and radiometric corrections due to uniform illumination and look-angle provided by the SAR sensor on repeat orbits. As such the SLC data can be used for relative analysis and burnt area mapping without expensive post-processing.\n",
    "\n",
    "* Plot image snippets to check alignment in pixel co-ordinates\n",
    "* Plot histograms to show any overall backscatter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [f'{scene}.SAFE/measurement' for scene in scene_ids]\n",
    "data_collection = {}\n",
    "for data in datasets:\n",
    "    tiff_files = glob.glob(os.path.join('/notebooks',data,'*.tiff'))\n",
    "    for tiff in tiff_files:\n",
    "        if 's1a-iw2' in tiff:\n",
    "            ds = gdal.Open(tiff)\n",
    "            xsize = ds.RasterXSize\n",
    "            ysize = ds.RasterYSize\n",
    "            data = ds.ReadAsArray(int(xsize/4),int(ysize/4),1000,1000)\n",
    "            data_collection[tiff] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,\n",
    "                        ncols=int(len(data_collection) / 2),\n",
    "                        constrained_layout=True)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "i = 0\n",
    "keys = list(data_collection.keys())\n",
    "for ax in axs.flat:\n",
    "    key = keys[i]\n",
    "    decibel = np.log(np.absolute(data_collection[keys[i]])**2) * 10\n",
    "    ax.imshow(decibel)\n",
    "    basename = os.path.basename(key)\n",
    "    ax.set_title(basename[12:23])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=int(len(data_collection) / 2),\n",
    "                        ncols=2,\n",
    "                        constrained_layout=True)\n",
    "fig.set_size_inches(10.5, 18.5, forward=True)\n",
    "i = 0\n",
    "keys = list(data_collection.keys())\n",
    "for ax in axs.flat:\n",
    "    key = keys[i]\n",
    "    basename = os.path.basename(key)\n",
    "    pol_date = basename[12:23]\n",
    "    data = data_collection[keys[i]]\n",
    "    data_no_nan = np.nan_to_num(np.absolute(data))\n",
    "    counts, bins = np.histogram(data_no_nan.flatten(), bins=100)\n",
    "    ax.hist(bins[:-1], bins=100, weights=counts)\n",
    "    ax.set_title(pol_date)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and manipulate data in PyRAT\n",
    "[PyRat](https://github.com/birgander2/PyRAT/wiki/About-PyRAT) (Python Radar Tools) is a flexible open-source framework for post-processing synthetic aperture radar (SAR) data. PyRAT is implementedin Python and distributed under an open-source license. It is mostly intended for post-processing of both airborne and spaceborne SAR imagery. PyRAT features an easy to use plugin-based programming interface, which allows users to quickly extend it with their own routines.\n",
    "\n",
    "This section of the notebook demostrate headless/scripted use of PyRAT on the SLC data downloaded previously.\n",
    "\n",
    "* Load data from one SLC scene into PyRAT\n",
    "* The load generates two layers\n",
    "* Perform some filtering and preview generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DISPLAY']='0:0'\n",
    "from pyrat import *\n",
    "pyrat_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = load.sentinel1(dir='/notebooks/S1A_IW_SLC__1SDV_20200129T191613_20200129T191639_031019_039028_1537.SAFE',swath=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activate(['/L1','/L2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getmeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_l1_box = filter.boxcar(layer=s1[0])\n",
    "save.pixmap('s1_l1.jpg',layer=s1[0],scaling=10)\n",
    "save.pixmap('s1_l1_box.jpg', layer=s1_l1_box,scaling=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Future work\n",
    "\n",
    "**Burn Scar Mapping**: Fire Mapping in SAR Reference : https://www.mdpi.com/2072-4292/9/8/764/htm\n",
    "\n",
    "**Entropy/Alpha and Statistical Analysis**: Analyse them in Slant Range with [PyRAT](https://github.com/birgander2/PyRAT)\n",
    "\n",
    "**Create Near-Real Time Results**: Use [Helmert Transforms](https://en.wikipedia.org/wiki/Helmert_transformation) to utilize GCP's embedded in metadata to go from pixel domain/SLC domain to real-world coordinates.\n",
    "\n",
    "**Create Accurate Results**: Convert analysis results to Ground range/Orthorectified versions using [SNAP](http://step.esa.int/main/download/snap-download/)/[Gamma](https://www.gamma-rs.ch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** February 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`sandbox compatible`, :index:`sentinel 1`, :index:`SARA`, :index:`auscophub`, :index:`gdal`, :index:`radar`, :index:`SLC`, :index:`time series`, :index:`fire mapping`, :index:`no_testing`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
