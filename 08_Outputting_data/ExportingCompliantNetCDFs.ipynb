{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting compliant NetCDF datasets for publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this notebook do?** \n",
    "\n",
    "This notebook demonstrates how to create a NetCDF output file that is compliant with the requirements of the NCI and international metadata standards. This is specifically intended to assist with products that were produced **outside** of standard `datacube` workflows: for example, where data exists in array or raster form rather than having been automatically generated using a `datacube-stats` workflow. The notebook demonstrates how to use a selection of existing `datacube` functions to create the NetCDF, as these automatically create much of the required metadata. \n",
    "\n",
    "*(This is an in-progress document which is likely to be updated regularly as this procedure is streamlined. Pelase raise an issue on the dea-notebooks repository or contact the author if you have any suggestions on improving the workflow)*\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "This notebook also uses sample data from the National Intertidal Digital Elevation Model (NIDEM) located at `/g/data/r78/rt1527/nidem/output_data/`.\n",
    "\n",
    "**Date:** August 2018\n",
    "\n",
    "**Author:** Robbi Bishop-Taylor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NetCDF`, :index:`Compliant files`, :index:`CF`, :index:`ACDD`, :index:`Publication`, :index:`NCI`, :index:`Outputting data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from datacube.drivers.netcdf import Variable, create_netcdf_storage_unit, writer as netcdf_writer\n",
    "from datacube.utils.geometry import Coordinate\n",
    "from datacube.utils.geometry import CRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import sample data\n",
    "For this example, we will create a compliant NetCDF file that contains three seperate input raster datasets. First, import the sample datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rasterio to load the input rasters\n",
    "nidem_path = '/g/data/r78/rt1527/nidem/output_data/geotiff/'\n",
    "nidem_dem = rasterio.open(nidem_path + 'nidem/NIDEM_33_130.91_-12.26.tif')\n",
    "nidem_unfiltered = rasterio.open(nidem_path + 'nidem_unfiltered/NIDEM_unfiltered_33_130.91_-12.26.tif')\n",
    "nidem_mask = rasterio.open(nidem_path + 'nidem_mask/NIDEM_mask_33_130.91_-12.26.tif')\n",
    "\n",
    "# Read data as numpy arrays\n",
    "nidem_dem_array = nidem_dem.read(1)\n",
    "nidem_unfiltered_array = nidem_unfiltered.read(1)\n",
    "nidem_mask_array = nidem_mask.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new NetCDF\n",
    "* Here we create a new NetCDF storage unit using the `create_netcdf_storage_unit` function from `datacube.drivers.netcdf`\n",
    "* This lets us set up the dataset's coordinate reference system, dataset dimensions (e.g. x and y coordinates) and create empty variables tied to the above dimensions with manually defined nodata values, units and dtypes.\n",
    "* Using the `CRS`, `Coordinate` and `Variable` functions automatically generates much of the required metadata, including `geospatial_bounds`, `geospatial_bounds_crs`, `geospatial_lat_*` and `geospatial_lon_*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datacube.drivers.netcdf._safestrings.SafeStringsDataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    date_created: 2019-05-22T17:27:44.267255\n",
      "    Conventions: CF-1.6, ACDD-1.3\n",
      "    history: NetCDF-CF file created by datacube version '1.6.2+398.g0e94625d' at 20190522.\n",
      "    geospatial_bounds: POLYGON ((130.601383569373 -11.9746230018132,130.595069713574 -12.5618627239134,130.588698595575 -13.1477581546625,131.319765093712 -13.1538034581567,131.322836107244 -12.5678942916324,131.325879516635 -11.9806414811064,130.601383569373 -11.9746230018132))\n",
      "    geospatial_bounds_crs: EPSG:4326\n",
      "    geospatial_lat_min: -13.153803458156746\n",
      "    geospatial_lat_max: -11.974623001813235\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_min: 130.58869859557532\n",
      "    geospatial_lon_max: 131.32587951663467\n",
      "    geospatial_lon_units: degrees_east\n",
      "    dimensions(sizes): x(3219), y(5102)\n",
      "    variables(dimensions): float64 \u001b[4mx\u001b[0m(x), float64 \u001b[4my\u001b[0m(y), int32 \u001b[4mcrs\u001b[0m(), float32 \u001b[4mdem\u001b[0m(y,x), float32 \u001b[4mdem_unfiltered\u001b[0m(y,x), int16 \u001b[4mmask\u001b[0m(y,x)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate coordinates for each pixel in the x and y directions based on the input dataset\n",
    "x_coords = [nidem_dem.xy(row=0, col=x_ind)[0] for x_ind in range(0, nidem_mask.width)]\n",
    "y_coords = [nidem_dem.xy(row=y_ind, col=0)[1] for y_ind in range(0, nidem_mask.height)]\n",
    "\n",
    "# Use netcdfy_coord to produce compliant coordinates\n",
    "x_coords = netcdf_writer.netcdfy_coord(np.array(x_coords))\n",
    "y_coords = netcdf_writer.netcdfy_coord(np.array(y_coords))\n",
    "\n",
    "# Create new dataset\n",
    "output_netcdf = create_netcdf_storage_unit(filename='sample.nc',\n",
    "                                           \n",
    "               # Set coordinate reference system \n",
    "               crs=CRS('EPSG:3577'),\n",
    "\n",
    "               # Set up dimensions using x and y coordinates computed above\n",
    "               coordinates={'x': Coordinate(x_coords, 'metres'),\n",
    "                            'y': Coordinate(y_coords, 'metres')},\n",
    "\n",
    "               # Set up empty variables for each layer, specifying the units and nodata\n",
    "               variables={'dem': Variable(dtype=np.dtype('float32'),\n",
    "                                          nodata=-9999,\n",
    "                                          dims=('y', 'x'),\n",
    "                                          units='metres'),\n",
    "                          'dem_unfiltered': Variable(dtype=np.dtype('float32'),\n",
    "                                                     nodata=-9999,\n",
    "                                                     dims=('y', 'x'),\n",
    "                                                     units='metres'),\n",
    "                          'mask': Variable(dtype=np.dtype('int16'),\n",
    "                                           nodata=-9999,\n",
    "                                           dims=('y', 'x'),\n",
    "                                           units='metres')},\n",
    "\n",
    "               # This can be used to specify optional NetCDF creation options like compression\n",
    "               variable_params={'dem': {}})\n",
    "\n",
    "print(output_netcdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign data and attributes to each variable\n",
    "So far, the created NetCDF contains no data. The next step is to assign each of our data arrays into the previously created variables, and set metadata for each variable. \n",
    "* Using the `netcdfy_data` function will ensure the data types are compliant.\n",
    "* Include a descriptive summary of the variable for `long_name`.\n",
    "* If applicable, use `valid_range` to set the valid numeric range for the data.\n",
    "* For most datasets, `coverage_content_type` can be set to 'modelResult' (valid options are 'image', 'thematicClassification', 'physicalMeasurement', 'auxiliaryInformation', 'qualityInformation', 'referenceInformation', 'modelResult', 'coordinate')\n",
    "* The `standard_name` attribute links the data to a specific pre-defined type of data defined by the Climate and Forecast (CF) Metadata Conventions. If applicable, select an option from this website (http://cfconventions.org/Data/cf-standard-names/55/build/cf-standard-name-table.html); e.g. 'height_above_mean_sea_level' below. If none of the `standard_name` options fit your data, it is best to leave it out, even though this will cause the NetCDF files to fail one of the ACDD tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('x', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 x(x)\n",
      "    units: metres\n",
      "    standard_name: projection_x_coordinate\n",
      "    long_name: x coordinate of projection\n",
      "unlimited dimensions: \n",
      "current shape = (3219,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('y', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 y(y)\n",
      "    units: metres\n",
      "    standard_name: projection_y_coordinate\n",
      "    long_name: y coordinate of projection\n",
      "unlimited dimensions: \n",
      "current shape = (5102,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('crs', <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 crs()\n",
      "    grid_mapping_name: albers_conical_equal_area\n",
      "    standard_parallel: [-18. -36.]\n",
      "    longitude_of_central_meridian: 132.0\n",
      "    latitude_of_projection_origin: 0.0\n",
      "    false_easting: 0.0\n",
      "    false_northing: 0.0\n",
      "    long_name: GDA94 / Australian Albers\n",
      "    semi_major_axis: 6378137.0\n",
      "    semi_minor_axis: 6356752.314140356\n",
      "    inverse_flattening: 298.257222101\n",
      "    crs_wkt: PROJCS[\"GDA94 / Australian Albers\",GEOGCS[\"GDA94\",DATUM[\"Geocentric_Datum_of_Australia_1994\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6283\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4283\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",-18],PARAMETER[\"standard_parallel_2\",-36],PARAMETER[\"latitude_of_center\",0],PARAMETER[\"longitude_of_center\",132],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"3577\"]]\n",
      "    spatial_ref: PROJCS[\"GDA94 / Australian Albers\",GEOGCS[\"GDA94\",DATUM[\"Geocentric_Datum_of_Australia_1994\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6283\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4283\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",-18],PARAMETER[\"standard_parallel_2\",-36],PARAMETER[\"latitude_of_center\",0],PARAMETER[\"longitude_of_center\",132],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"3577\"]]\n",
      "    GeoTransform: [-1.553500e+05  2.500000e+01  0.000000e+00 -1.262375e+06  0.000000e+00\n",
      " -2.500000e+01]\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used\n",
      "), ('dem', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 dem(y, x)\n",
      "    _FillValue: -9999.0\n",
      "    grid_mapping: crs\n",
      "    units: metres\n",
      "    valid_range: [-25.  25.]\n",
      "    standard_name: height_above_mean_sea_level\n",
      "    coverage_content_type: modelResult\n",
      "    long_name: NIDEM filtered by ITEM confidence (< 0.25 NDWI SD), bathymetry (> -25 m) and elevation (< 25 m)\n",
      "unlimited dimensions: \n",
      "current shape = (5102, 3219)\n",
      "filling on), ('dem_unfiltered', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 dem_unfiltered(y, x)\n",
      "    _FillValue: -9999.0\n",
      "    grid_mapping: crs\n",
      "    units: metres\n",
      "    standard_name: height_above_mean_sea_level\n",
      "    coverage_content_type: modelResult\n",
      "    long_name: NIDEM unfiltered data\n",
      "unlimited dimensions: \n",
      "current shape = (5102, 3219)\n",
      "filling on), ('mask', <class 'netCDF4._netCDF4.Variable'>\n",
      "int16 mask(y, x)\n",
      "    _FillValue: -9999\n",
      "    grid_mapping: crs\n",
      "    units: metres\n",
      "    valid_range: [1 3]\n",
      "    coverage_content_type: qualityInformation\n",
      "    long_name: NIDEM mask flagging cells with elevations greater than 25 m (value = 1), less than -25 m (value = 2), and ITEM confidence NDWI standard deviation greater than 0.25 (value = 3)\n",
      "unlimited dimensions: \n",
      "current shape = (5102, 3219)\n",
      "filling on)])\n"
     ]
    }
   ],
   "source": [
    "# dem: assign data and set variable attributes\n",
    "output_netcdf['dem'][:] = netcdf_writer.netcdfy_data(nidem_dem_array)\n",
    "output_netcdf['dem'].valid_range = [-25.0, 25.0]\n",
    "output_netcdf['dem'].standard_name = 'height_above_mean_sea_level'\n",
    "output_netcdf['dem'].coverage_content_type = 'modelResult'\n",
    "output_netcdf['dem'].long_name = 'NIDEM filtered by ITEM confidence (< 0.25 NDWI SD), ' \\\n",
    "                                 'bathymetry (> -25 m) and elevation (< 25 m)'\n",
    "\n",
    "# dem_unfiltered: assign data and set variable attributes\n",
    "output_netcdf['dem_unfiltered'][:] = netcdf_writer.netcdfy_data(nidem_unfiltered_array)\n",
    "output_netcdf['dem_unfiltered'].standard_name = 'height_above_mean_sea_level'\n",
    "output_netcdf['dem_unfiltered'].coverage_content_type = 'modelResult'\n",
    "output_netcdf['dem_unfiltered'].long_name = 'NIDEM unfiltered data'\n",
    "\n",
    "# mask: assign data and set variable attributes\n",
    "output_netcdf['mask'][:] = netcdf_writer.netcdfy_data(nidem_mask_array)\n",
    "output_netcdf['mask'].valid_range = [1, 3]\n",
    "output_netcdf['mask'].coverage_content_type = 'qualityInformation'\n",
    "output_netcdf['mask'].long_name = 'NIDEM mask flagging cells with elevations greater ' \\\n",
    "                                  'than 25 m (value = 1), less than -25 m (value = 2), ' \\\n",
    "                                  'and ITEM confidence NDWI standard deviation greater ' \\\n",
    "                                  'than 0.25 (value = 3)'\n",
    "        \n",
    "# The `variables` method lets you verify the data has been included in the dataset:\n",
    "print(output_netcdf.variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add global metadata\n",
    "The next step is to add global attributes which provide metadata for the entire NetCDF dataset including all variables.\n",
    "* This link (https://geo-ide.noaa.gov/wiki/index.php?title=NetCDF_Attribute_Convention_for_Dataset_Discovery) provides guidance on the kinds of information that can be included. Aim to include as many of the 'Highly Recommended' and 'Recommended' attributes as possible.\n",
    "* Many of the 'Recommended' attributes will be automatically generated by `datacube` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datacube.drivers.netcdf._safestrings.SafeStringsDataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    date_created: 2019-05-22T17:27:44.267255\n",
      "    Conventions: CF-1.6, ACDD-1.3\n",
      "    history: NetCDF-CF file created by datacube version '1.6.2+398.g0e94625d' at 20190522.\n",
      "    geospatial_bounds: POLYGON ((130.601383569373 -11.9746230018132,130.595069713574 -12.5618627239134,130.588698595575 -13.1477581546625,131.319765093712 -13.1538034581567,131.322836107244 -12.5678942916324,131.325879516635 -11.9806414811064,130.601383569373 -11.9746230018132))\n",
      "    geospatial_bounds_crs: EPSG:4326\n",
      "    geospatial_lat_min: -13.153803458156746\n",
      "    geospatial_lat_max: -11.974623001813235\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_min: 130.58869859557532\n",
      "    geospatial_lon_max: 131.32587951663467\n",
      "    geospatial_lon_units: degrees_east\n",
      "    title: National Intertidal Digital Elevation Model (NIDEM) 25m v 0.1.0\n",
      "    institution: Commonwealth of Australia (Geoscience Australia)\n",
      "    product_version: 0.1.0\n",
      "    license: CC BY Attribution 4.0 International License\n",
      "    time_coverage_start: 1986-01-01\n",
      "    time_coverage_end: 2016-10-31\n",
      "    cdm_data_type: Grid\n",
      "    contact: clientservices@ga.gov.au\n",
      "    publisher_email: earth.observation@ga.gov.au\n",
      "    source: OTPS TPX08 Atlas\n",
      "    keywords: Tidal, Topography, Landsat, Elevation, Intertidal, MSL, ITEM, NIDEM, DEM\n",
      "    summary: Insert a detailed multiparagraph description of the dataset here\n",
      "    dimensions(sizes): x(3219), y(5102)\n",
      "    variables(dimensions): float64 \u001b[4mx\u001b[0m(x), float64 \u001b[4my\u001b[0m(y), int32 \u001b[4mcrs\u001b[0m(), float32 \u001b[4mdem\u001b[0m(y,x), float32 \u001b[4mdem_unfiltered\u001b[0m(y,x), int16 \u001b[4mmask\u001b[0m(y,x)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add global attributes\n",
    "output_netcdf.title = 'National Intertidal Digital Elevation Model (NIDEM) 25m v 0.1.0'\n",
    "output_netcdf.institution = 'Commonwealth of Australia (Geoscience Australia)'\n",
    "output_netcdf.product_version = '0.1.0'\n",
    "output_netcdf.license = 'CC BY Attribution 4.0 International License'\n",
    "output_netcdf.time_coverage_start = '1986-01-01'\n",
    "output_netcdf.time_coverage_end = '2016-10-31'\n",
    "output_netcdf.cdm_data_type = 'Grid'\n",
    "output_netcdf.contact = 'clientservices@ga.gov.au'\n",
    "output_netcdf.publisher_email = 'earth.observation@ga.gov.au'\n",
    "output_netcdf.source = 'OTPS TPX08 Atlas'\n",
    "output_netcdf.keywords = 'Tidal, Topography, Landsat, Elevation, Intertidal, MSL, ITEM, NIDEM, DEM'\n",
    "output_netcdf.summary = \"Insert a detailed multiparagraph description of the dataset here\"\n",
    "                        \n",
    "# When you print the dataset now, the new global attributes should appear:\n",
    "print(output_netcdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the dataset\n",
    "When you have finished adding data and metadata, close the file to write it to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dataset\n",
    "output_netcdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing compliance\n",
    "At minimum, the NCI requires compliance with the Climate and Forecast Metadata Standard (CF) and the Attribute Convention for Data Discovery (ACDD). To test whether the dataset is compliant, we can run several checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate and Forecast Metadata Standard (CF) compliance\n",
    "* You can test for CF compliance using this online utility: http://puma.nerc.ac.uk/cgi-bin/cf-checker.pl\n",
    "* All CF tests should pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Convention for Data Discovery (ACDD) compliance\n",
    "* Run the compliance-checker tool loaded by the dea module on the NCI: `compliance-checker test_file.nc`\n",
    "* This is a much more detailed check, and will give a total score for the dataset and an explanation for each failed test.\n",
    "* Every effort should be made to make all 'High Priority' tests pass, but there is some flexibility (e.g. varattr may give less than a 100% score if some attributes that are not applicable for a given variable like standard_name are not set).\n",
    "* You do not need to pass all 'Medium priority' tests, but try to complete as many as practically possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Compliance Checker on the datasets from: ['sample.nc']\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                         IOOS Compliance Checker Report                         \n",
      "                                    acdd:1.3                                    \n",
      "http://wiki.esipfed.org/index.php?title=Category:Attribute_Conventions_Dataset_Discovery\n",
      "--------------------------------------------------------------------------------\n",
      "                               Corrective Actions                               \n",
      "sample.nc has 5 potential issues\n",
      "\n",
      "\n",
      "                               Highly Recommended                               \n",
      "--------------------------------------------------------------------------------\n",
      "variable \"mask\" missing the following attributes:\n",
      "* standard_name\n",
      "\n",
      "\n",
      "                                  Recommended                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Global Attributes\n",
      "* acknowledgment/acknowledgement not present\n",
      "* comment not present\n",
      "* creator_name not present\n",
      "* creator_url not present\n",
      "* creator_email not present\n",
      "* geospatial_vertical_min not present\n",
      "* geospatial_vertical_max not present\n",
      "* geospatial_vertical_positive not present\n",
      "* geospatial_bounds_vertical_crs not present\n",
      "* id not present\n",
      "* naming_authority not present\n",
      "* project not present\n",
      "* processing_level not present\n",
      "* publisher_name not present\n",
      "* publisher_url not present\n",
      "* standard_name_vocabulary not present\n",
      "* time_coverage_duration not present\n",
      "* time_coverage_resolution not present\n",
      "\n",
      "geospatial_lat_extents_match\n",
      "* Could not find lat variable to test extent of geospatial_lat_min/max, see CF-1.6 spec chapter 4.1\n",
      "\n",
      "geospatial_lon_extents_match\n",
      "* Could not find lon variable to test extent of geospatial_lon_min/max, see CF-1.6 spec chapter 4.2\n",
      "\n",
      "time_coverage_extents_match\n",
      "* Could not find time variable to test extent of time_coverage_start/time_coverage_end, see CF-1.6 spec chapter 4.4\n"
     ]
    }
   ],
   "source": [
    "!compliance-checker sample.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check file opens correctly in QGIS\n",
    "If your file contains spatial data, open the NetCDF in QGIS to verify it plots in the correct location, and that nodata values are correctly accounted for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
