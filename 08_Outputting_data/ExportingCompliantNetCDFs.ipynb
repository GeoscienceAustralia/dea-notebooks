{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting compliant NetCDF datasets for publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this notebook do?** \n",
    "\n",
    "This notebook demonstrates how to create a NetCDF output file that is compliant with the requirements of the NCI and international metadata standards. This is specifically intended to assist with products that were produced **outside** of standard `datacube` workflows: for example, where data exists in array or raster form rather than having been automatically generated using a `datacube-stats` workflow. The notebook demonstrates how to use a selection of existing `datacube` functions to create the NetCDF, as these automatically create much of the required metadata. \n",
    "\n",
    "*(This is an in-progress document which is likely to be updated regularly as this procedure is streamlined. Pelase raise an issue on the dea-notebooks repository or contact the author if you have any suggestions on improving the workflow)*\n",
    "\n",
    "**Required inputs**\n",
    "This notebook uses sample data from the National Intertidal Digital Elevation Model (NIDEM) located at `/g/data/r78/rt1527/nidem/output_data/`.\n",
    "\n",
    "**Date:** June 2018\n",
    "\n",
    "**Author:** Robbi Bishop-Taylor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NetCDF`, :index:`Compliant files`, :index:`CF`, :index:`ACDD`, :index:`Publication`, :index:`NCI`, :index:`Outputting data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from datacube.model import Variable\n",
    "from datacube.utils.geometry import Coordinate\n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.storage.storage import create_netcdf_storage_unit\n",
    "from datacube.storage import netcdf_writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import sample data\n",
    "For this example, we will create a compliant NetCDF file that contains three seperate input raster datasets. First, import the sample datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rasterio to load the input rasters\n",
    "nidem_dem = rasterio.open('/g/data/r78/rt1527/nidem/output_data/geotiff/dem/NIDEM_dem_33.tif')\n",
    "nidem_unfiltered = rasterio.open('/g/data/r78/rt1527/nidem/output_data/geotiff/dem_unfiltered/NIDEM_unfiltered_33.tif')\n",
    "nidem_mask = rasterio.open('/g/data/r78/rt1527/nidem/output_data/geotiff/mask/NIDEM_mask_33.tif')\n",
    "\n",
    "# Read data as numpy arrays\n",
    "nidem_dem_array = nidem_dem.read(1)\n",
    "nidem_unfiltered_array = nidem_unfiltered.read(1)\n",
    "nidem_mask_array = nidem_mask.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new NetCDF\n",
    "* Here we create a new NetCDF storage unit using the `create_netcdf_storage_unit` function from `datacube.storage.storage`\n",
    "* This lets us set up the dataset's coordinate reference system, dataset dimensions (e.g. x and y coordinates) and create empty variables tied to the above dimensions with manually defined nodata values, units and dtypes.\n",
    "* Using the `CRS`, `Coordinate` and `Variable` functions automatically generates much of the required metadata, including `geospatial_bounds`, `geospatial_bounds_crs`, `geospatial_lat_*` and `geospatial_lon_*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datacube.storage.netcdf_safestrings.SafeStringsDataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    date_created: 2018-06-27T16:29:06.603271\n",
      "    Conventions: CF-1.6, ACDD-1.3\n",
      "    history: NetCDF-CF file created by datacube version '1.6rc1+28.ga69dfff5' at 20180627.\n",
      "    geospatial_bounds: POLYGON ((130.601383569373 -11.9746230018132,130.595069713574 -12.5618627239134,130.588698595575 -13.1477581546625,131.319765093712 -13.1538034581567,131.322836107244 -12.5678942916324,131.325879516635 -11.9806414811064,130.601383569373 -11.9746230018132))\n",
      "    geospatial_bounds_crs: EPSG:4326\n",
      "    geospatial_lat_min: -13.153803458156746\n",
      "    geospatial_lat_max: -11.974623001813235\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_min: 130.58869859557532\n",
      "    geospatial_lon_max: 131.32587951663467\n",
      "    geospatial_lon_units: degrees_east\n",
      "    dimensions(sizes): x(3219), y(5102)\n",
      "    variables(dimensions): float64 \u001b[4mx\u001b[0m(x), float64 \u001b[4my\u001b[0m(y), int32 \u001b[4mcrs\u001b[0m(), float32 \u001b[4mdem\u001b[0m(y,x), float32 \u001b[4mdem_unfiltered\u001b[0m(y,x), int16 \u001b[4mmask\u001b[0m(y,x)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate coordinates for each pixel in the x and y directions based on the input dataset\n",
    "x_coords = [nidem_dem.xy(row=0, col=x_ind)[0] for x_ind in range(0, nidem_mask.width)]\n",
    "y_coords = [nidem_dem.xy(row=y_ind, col=0)[1] for y_ind in range(0, nidem_mask.height)]\n",
    "\n",
    "# Use netcdfy_coord to produce compliant coordinates\n",
    "x_coords = netcdf_writer.netcdfy_coord(np.array(x_coords))\n",
    "y_coords = netcdf_writer.netcdfy_coord(np.array(y_coords))\n",
    "\n",
    "# Create new dataset\n",
    "output_netcdf = create_netcdf_storage_unit(filename='sample.nc',\n",
    "                                           \n",
    "               # Set coordinate reference system \n",
    "               crs=CRS('EPSG:3577'),\n",
    "\n",
    "               # Set up dimensions using x and y coordinates computed above\n",
    "               coordinates={'x': Coordinate(x_coords, 'metres'),\n",
    "                            'y': Coordinate(y_coords, 'metres')},\n",
    "\n",
    "               # Set up empty variables for each layer, specifying the units and nodata\n",
    "               variables={'dem': Variable(dtype=np.dtype('float32'),\n",
    "                                          nodata=-9999,\n",
    "                                          dims=('y', 'x'),\n",
    "                                          units='metres'),\n",
    "                          'dem_unfiltered': Variable(dtype=np.dtype('float32'),\n",
    "                                                     nodata=-9999,\n",
    "                                                     dims=('y', 'x'),\n",
    "                                                     units='metres'),\n",
    "                          'mask': Variable(dtype=np.dtype('int16'),\n",
    "                                           nodata=-9999,\n",
    "                                           dims=('y', 'x'),\n",
    "                                           units='metres')},\n",
    "\n",
    "               # This can be used to specify optional NetCDF creation options like compression\n",
    "               variable_params={'dem': {}})\n",
    "\n",
    "print(output_netcdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign data and attributes to each variable\n",
    "So far, the created NetCDF contains no data. The next step is to assign each of our data arrays into the previously created variables, and set metadata for each variable. \n",
    "* Using the `netcdfy_data` function will ensure the data types are compliant.\n",
    "* Include a descriptive summary of the variable for `long_name`.\n",
    "* If applicable, use `valid_range` to set the valid numeric range for the data.\n",
    "* For most datasets, `coverage_content_type` can be set to 'modelResult' (valid options are 'image', 'thematicClassification', 'physicalMeasurement', 'auxiliaryInformation', 'qualityInformation', 'referenceInformation', 'modelResult', 'coordinate')\n",
    "* The `standard_name` attribute links the data to a specific pre-defined type of data defined by the Climate and Forecast (CF) Metadata Conventions. If applicable, select an option from this website (http://cfconventions.org/Data/cf-standard-names/55/build/cf-standard-name-table.html); e.g. 'height_above_mean_sea_level' below. If none of the `standard_name` options fit your data, it is best to leave it out, even though this will cause the NetCDF files to fail one of the ACDD tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('x', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 x(x)\n",
      "    units: metres\n",
      "    standard_name: projection_x_coordinate\n",
      "    long_name: x coordinate of projection\n",
      "unlimited dimensions: \n",
      "current shape = (3219,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('y', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 y(y)\n",
      "    units: metres\n",
      "    standard_name: projection_y_coordinate\n",
      "    long_name: y coordinate of projection\n",
      "unlimited dimensions: \n",
      "current shape = (5102,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('crs', <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 crs()\n",
      "    grid_mapping_name: albers_conical_equal_area\n",
      "    standard_parallel: [-18. -36.]\n",
      "    longitude_of_central_meridian: 132.0\n",
      "    latitude_of_projection_origin: 0.0\n",
      "    false_easting: 0.0\n",
      "    false_northing: 0.0\n",
      "    long_name: GDA94 / Australian Albers\n",
      "    semi_major_axis: 6378137.0\n",
      "    semi_minor_axis: 6356752.314140356\n",
      "    inverse_flattening: 298.257222101\n",
      "    crs_wkt: PROJCS[\"GDA94 / Australian Albers\",GEOGCS[\"GDA94\",DATUM[\"Geocentric_Datum_of_Australia_1994\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6283\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4283\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",-18],PARAMETER[\"standard_parallel_2\",-36],PARAMETER[\"latitude_of_center\",0],PARAMETER[\"longitude_of_center\",132],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"3577\"]]\n",
      "    spatial_ref: PROJCS[\"GDA94 / Australian Albers\",GEOGCS[\"GDA94\",DATUM[\"Geocentric_Datum_of_Australia_1994\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6283\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4283\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",-18],PARAMETER[\"standard_parallel_2\",-36],PARAMETER[\"latitude_of_center\",0],PARAMETER[\"longitude_of_center\",132],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"3577\"]]\n",
      "    GeoTransform: [-1.553500e+05  2.500000e+01  0.000000e+00 -1.262375e+06  0.000000e+00\n",
      " -2.500000e+01]\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used\n",
      "), ('dem', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 dem(y, x)\n",
      "    _FillValue: -9999.0\n",
      "    grid_mapping: crs\n",
      "    units: metres\n",
      "    valid_range: [-25.  25.]\n",
      "    standard_name: height_above_mean_sea_level\n",
      "    coverage_content_type: modelResult\n",
      "    long_name: NIDEM filtered by ITEM confidence (< 0.25 NDWI SD), bathymetry (> -25 m) and elevation (< 25 m)\n",
      "unlimited dimensions: \n",
      "current shape = (5102, 3219)\n",
      "filling on), ('dem_unfiltered', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 dem_unfiltered(y, x)\n",
      "    _FillValue: -9999.0\n",
      "    grid_mapping: crs\n",
      "    units: metres\n",
      "    standard_name: height_above_mean_sea_level\n",
      "    coverage_content_type: modelResult\n",
      "    long_name: NIDEM unfiltered data\n",
      "unlimited dimensions: \n",
      "current shape = (5102, 3219)\n",
      "filling on), ('mask', <class 'netCDF4._netCDF4.Variable'>\n",
      "int16 mask(y, x)\n",
      "    _FillValue: -9999\n",
      "    grid_mapping: crs\n",
      "    units: metres\n",
      "    valid_range: [1 3]\n",
      "    coverage_content_type: qualityInformation\n",
      "    long_name: NIDEM mask flagging cells with elevations greater than 25 m (value = 1), less than -25 m (value = 2), and ITEM confidence NDWI standard deviation greater than 0.25 (value = 3)\n",
      "unlimited dimensions: \n",
      "current shape = (5102, 3219)\n",
      "filling on)])\n"
     ]
    }
   ],
   "source": [
    "# dem: assign data and set variable attributes\n",
    "output_netcdf['dem'][:] = netcdf_writer.netcdfy_data(nidem_dem_array)\n",
    "output_netcdf['dem'].valid_range = [-25.0, 25.0]\n",
    "output_netcdf['dem'].standard_name = 'height_above_mean_sea_level'\n",
    "output_netcdf['dem'].coverage_content_type = 'modelResult'\n",
    "output_netcdf['dem'].long_name = 'NIDEM filtered by ITEM confidence (< 0.25 NDWI SD), ' \\\n",
    "                                 'bathymetry (> -25 m) and elevation (< 25 m)'\n",
    "\n",
    "# dem_unfiltered: assign data and set variable attributes\n",
    "output_netcdf['dem_unfiltered'][:] = netcdf_writer.netcdfy_data(nidem_unfiltered_array)\n",
    "output_netcdf['dem_unfiltered'].standard_name = 'height_above_mean_sea_level'\n",
    "output_netcdf['dem_unfiltered'].coverage_content_type = 'modelResult'\n",
    "output_netcdf['dem_unfiltered'].long_name = 'NIDEM unfiltered data'\n",
    "\n",
    "# mask: assign data and set variable attributes\n",
    "output_netcdf['mask'][:] = netcdf_writer.netcdfy_data(nidem_mask_array)\n",
    "output_netcdf['mask'].valid_range = [1, 3]\n",
    "output_netcdf['mask'].coverage_content_type = 'qualityInformation'\n",
    "output_netcdf['mask'].long_name = 'NIDEM mask flagging cells with elevations greater ' \\\n",
    "                                  'than 25 m (value = 1), less than -25 m (value = 2), ' \\\n",
    "                                  'and ITEM confidence NDWI standard deviation greater ' \\\n",
    "                                  'than 0.25 (value = 3)'\n",
    "        \n",
    "# The `variables` method lets you verify the data has been included in the dataset:\n",
    "print(output_netcdf.variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add global metadata\n",
    "The next step is to add global attributes which provide metadata for the entire NetCDF dataset including all variables.\n",
    "* This link (https://geo-ide.noaa.gov/wiki/index.php?title=NetCDF_Attribute_Convention_for_Dataset_Discovery) provides guidance on the kinds of information that can be included. Aim to include as many of the 'Highly Recommended' and 'Recommended' attributes as possible.\n",
    "* Many of the 'Recommended' attributes will be automatically generated by `datacube` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datacube.storage.netcdf_safestrings.SafeStringsDataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    date_created: 2018-06-27T16:29:06.603271\n",
      "    Conventions: CF-1.6, ACDD-1.3\n",
      "    history: NetCDF-CF file created by datacube version '1.6rc1+28.ga69dfff5' at 20180627.\n",
      "    geospatial_bounds: POLYGON ((130.601383569373 -11.9746230018132,130.595069713574 -12.5618627239134,130.588698595575 -13.1477581546625,131.319765093712 -13.1538034581567,131.322836107244 -12.5678942916324,131.325879516635 -11.9806414811064,130.601383569373 -11.9746230018132))\n",
      "    geospatial_bounds_crs: EPSG:4326\n",
      "    geospatial_lat_min: -13.153803458156746\n",
      "    geospatial_lat_max: -11.974623001813235\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_min: 130.58869859557532\n",
      "    geospatial_lon_max: 131.32587951663467\n",
      "    geospatial_lon_units: degrees_east\n",
      "    title: National Intertidal Digital Elevation Model (NIDEM) 25m v 0.1.0\n",
      "    institution: Commonwealth of Australia (Geoscience Australia)\n",
      "    product_version: 0.1.0\n",
      "    license: CC BY Attribution 4.0 International License\n",
      "    time_coverage_start: 1986-01-01\n",
      "    time_coverage_end: 2016-10-31\n",
      "    cdm_data_type: Grid\n",
      "    contact: clientservices@ga.gov.au\n",
      "    publisher_email: earth.observation@ga.gov.au\n",
      "    source: OTPS TPX08 Atlas\n",
      "    keywords: Tidal, Topography, Landsat, Elevation, Intertidal, MSL, ITEM, NIDEM, DEM\n",
      "    summary: Insert a detailed multiparagraph description of the dataset here\n",
      "    dimensions(sizes): x(3219), y(5102)\n",
      "    variables(dimensions): float64 \u001b[4mx\u001b[0m(x), float64 \u001b[4my\u001b[0m(y), int32 \u001b[4mcrs\u001b[0m(), float32 \u001b[4mdem\u001b[0m(y,x), float32 \u001b[4mdem_unfiltered\u001b[0m(y,x), int16 \u001b[4mmask\u001b[0m(y,x)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add global attributes\n",
    "output_netcdf.title = 'National Intertidal Digital Elevation Model (NIDEM) 25m v 0.1.0'\n",
    "output_netcdf.institution = 'Commonwealth of Australia (Geoscience Australia)'\n",
    "output_netcdf.product_version = '0.1.0'\n",
    "output_netcdf.license = 'CC BY Attribution 4.0 International License'\n",
    "output_netcdf.time_coverage_start = '1986-01-01'\n",
    "output_netcdf.time_coverage_end = '2016-10-31'\n",
    "output_netcdf.cdm_data_type = 'Grid'\n",
    "output_netcdf.contact = 'clientservices@ga.gov.au'\n",
    "output_netcdf.publisher_email = 'earth.observation@ga.gov.au'\n",
    "output_netcdf.source = 'OTPS TPX08 Atlas'\n",
    "output_netcdf.keywords = 'Tidal, Topography, Landsat, Elevation, Intertidal, MSL, ITEM, NIDEM, DEM'\n",
    "output_netcdf.summary = \"Insert a detailed multiparagraph description of the dataset here\"\n",
    "                        \n",
    "# When you print the dataset now, the new global attributes should appear:\n",
    "print(output_netcdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the dataset\n",
    "When you have finished adding data and metadata, close the file to write it to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dataset\n",
    "output_netcdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing compliance\n",
    "At minimum, the NCI requires compliance with the Climate and Forecast Metadata Standard (CF) and the Attribute Convention for Data Discovery (ACDD). To test whether the dataset is compliant, we can run several checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate and Forecast Metadata Standard (CF) compliance\n",
    "* You can test for CF compliance using this online utility: http://puma.nerc.ac.uk/cgi-bin/cf-checker.pl\n",
    "* All CF tests should pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Convention for Data Discovery (ACDD) compliance\n",
    "* Run the compliance-checker tool loaded by the dea module on the NCI: `compliance-checker test_file.nc`\n",
    "* This is a much more detailed check, and will give a total score for the dataset and an explanation for each failed test.\n",
    "* Every effort should be made to make all 'High Priority' tests pass, but there is some flexibility (e.g. varattr may give less than a 100% score if some attributes that are not applicable for a given variable like standard_name are not set).\n",
    "* You do not need to pass all 'Medium priority' tests, but try to complete as many as practically possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Compliance Checker on the dataset from: sample.nc\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                     The dataset scored 28 out of 51 points                     \n",
      "                             during the acdd check                              \n",
      "--------------------------------------------------------------------------------\n",
      "                               Scoring Breakdown:                               \n",
      "\n",
      "\n",
      "                                 High Priority                                  \n",
      "--------------------------------------------------------------------------------\n",
      "    Name                            :Priority: Score\n",
      "Conventions                             :3:     2/2\n",
      "keywords                                :3:     1/1\n",
      "summary                                 :3:     1/1\n",
      "title                                   :3:     1/1\n",
      "varattr                                 :3:     8/9\n",
      "\n",
      "\n",
      "                                Medium Priority                                 \n",
      "--------------------------------------------------------------------------------\n",
      "    Name                            :Priority: Score\n",
      "acknowledgment/acknowledgement          :2:     0/1\n",
      "comment                                 :2:     0/1\n",
      "creator_email                           :2:     0/1\n",
      "creator_name                            :2:     0/1\n",
      "creator_url                             :2:     0/1\n",
      "date_created                            :2:     1/1\n",
      "date_created_is_iso                     :2:     1/1\n",
      "date_issued_is_iso                      :2:     0/0\n",
      "date_metadata_modified_is_iso           :2:     0/0\n",
      "date_modified_is_iso                    :2:     0/0\n",
      "geospatial_bounds                       :2:     1/1\n",
      "geospatial_bounds_crs                   :2:     1/1\n",
      "geospatial_bounds_vertical_crs          :2:     0/1\n",
      "geospatial_lat_extents_match            :2:     0/1\n",
      "geospatial_lat_max                      :2:     1/1\n",
      "geospatial_lat_min                      :2:     1/1\n",
      "geospatial_lon_extents_match            :2:     0/1\n",
      "geospatial_lon_max                      :2:     1/1\n",
      "geospatial_lon_min                      :2:     1/1\n",
      "geospatial_vertical_max                 :2:     0/1\n",
      "geospatial_vertical_min                 :2:     0/1\n",
      "geospatial_vertical_positive            :2:     0/1\n",
      "history                                 :2:     1/1\n",
      "id                                      :2:     0/1\n",
      "id_has_no_blanks                        :2:     0/0\n",
      "institution                             :2:     1/1\n",
      "license                                 :2:     1/1\n",
      "metadata_link                           :2:     0/1\n",
      "naming_authority                        :2:     0/1\n",
      "processing_level                        :2:     0/1\n",
      "project                                 :2:     0/1\n",
      "publisher_email                         :2:     1/1\n",
      "publisher_name                          :2:     0/1\n",
      "publisher_url                           :2:     0/1\n",
      "source                                  :2:     1/1\n",
      "standard_name_vocabulary                :2:     0/1\n",
      "time_coverage_duration                  :2:     0/1\n",
      "time_coverage_end                       :2:     1/1\n",
      "time_coverage_extents_match             :2:     0/1\n",
      "time_coverage_resolution                :2:     0/1\n",
      "time_coverage_start                     :2:     1/1\n",
      "vertical_extents                        :2:     0/0\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                  Reasoning for the failed tests given below:                   \n",
      "\n",
      "\n",
      "Name                             Priority:     Score:Reasoning\n",
      "--------------------------------------------------------------------------------\n",
      "varattr                                :3:     8/ 9 :  \n",
      "    mask                               :3:     2/ 3 :  \n",
      "        var_std_name                   :3:     1/ 2 : Var mask missing attr\n",
      "                                                      standard_name\n",
      "acknowledgment/acknowledgement         :2:     0/ 1 : acknowledgement global\n",
      "                                                      attribute is recommended\n",
      "comment                                :2:     0/ 1 : Attr comment not present\n",
      "creator_email                          :2:     0/ 1 : Attr creator_email not\n",
      "                                                      present\n",
      "creator_name                           :2:     0/ 1 : Attr creator_name not\n",
      "                                                      present\n",
      "creator_url                            :2:     0/ 1 : Attr creator_url not\n",
      "                                                      present\n",
      "geospatial_bounds_vertical_crs         :2:     0/ 1 : Attr\n",
      "                                                      geospatial_bounds_vertical\n",
      "                                                      _crs not present\n",
      "geospatial_lat_extents_match           :2:     0/ 1 : Could not find lat\n",
      "                                                      variable to test extent of\n",
      "                                                      geospatial_lat_min/max,\n",
      "                                                      see CF-1.6 spec chapter\n",
      "                                                      4.1\n",
      "geospatial_lon_extents_match           :2:     0/ 1 : Could not find lon\n",
      "                                                      variable to test extent of\n",
      "                                                      geospatial_lon_min/max,\n",
      "                                                      see CF-1.6 spec chapter\n",
      "                                                      4.2\n",
      "geospatial_vertical_max                :2:     0/ 1 : Attr\n",
      "                                                      geospatial_vertical_max\n",
      "                                                      not present\n",
      "geospatial_vertical_min                :2:     0/ 1 : Attr\n",
      "                                                      geospatial_vertical_min\n",
      "                                                      not present\n",
      "geospatial_vertical_positive           :2:     0/ 1 : Attr\n",
      "                                                      geospatial_vertical_positi\n",
      "                                                      ve not present\n",
      "id                                     :2:     0/ 1 : Attr id not present\n",
      "metadata_link                          :2:     0/ 1 : Attr metadata_link not\n",
      "                                                      present\n",
      "naming_authority                       :2:     0/ 1 : Attr naming_authority not\n",
      "                                                      present\n",
      "processing_level                       :2:     0/ 1 : Attr processing_level not\n",
      "                                                      present\n",
      "project                                :2:     0/ 1 : Attr project not present\n",
      "publisher_name                         :2:     0/ 1 : Attr publisher_name not\n",
      "                                                      present\n",
      "publisher_url                          :2:     0/ 1 : Attr publisher_url not\n",
      "                                                      present\n",
      "standard_name_vocabulary               :2:     0/ 1 : Attr\n",
      "                                                      standard_name_vocabulary\n",
      "                                                      not present\n",
      "time_coverage_duration                 :2:     0/ 1 : Attr\n",
      "                                                      time_coverage_duration not\n",
      "                                                      present\n",
      "time_coverage_extents_match            :2:     0/ 1 : Could not find time\n",
      "                                                      variable to test extent of\n",
      "                                                      time_coverage_start/time_c\n",
      "                                                      overage_end, see CF-1.6\n",
      "                                                      spec chapter 4.4\n",
      "time_coverage_resolution               :2:     0/ 1 : Attr\n",
      "                                                      time_coverage_resolution\n",
      "                                                      not present\n",
      "contributor_name                       :1:     0/ 1 : Attr contributor_name not\n",
      "                                                      present\n",
      "contributor_role                       :1:     0/ 1 : Attr contributor_role not\n",
      "                                                      present\n",
      "creator_institution                    :1:     0/ 1 : Attr creator_institution\n",
      "                                                      not present\n",
      "creator_type                           :1:     0/ 2 : Attr creator_type not\n",
      "                                                      present\n",
      "date_issued                            :1:     0/ 1 : Attr date_issued not\n",
      "                                                      present\n",
      "date_metadata_modified                 :1:     0/ 1 : Attr\n",
      "                                                      date_metadata_modified not\n",
      "                                                      present\n",
      "date_modified                          :1:     0/ 1 : Attr date_modified not\n",
      "                                                      present\n",
      "geospatial_lat_resolution              :1:     0/ 1 : Attr\n",
      "                                                      geospatial_lat_resolution\n",
      "                                                      not present\n",
      "geospatial_lon_resolution              :1:     0/ 1 : Attr\n",
      "                                                      geospatial_lon_resolution\n",
      "                                                      not present\n",
      "geospatial_vertical_resolution         :1:     0/ 1 : Attr\n",
      "                                                      geospatial_vertical_resolu\n",
      "                                                      tion not present\n",
      "geospatial_vertical_units              :1:     0/ 1 : Attr\n",
      "                                                      geospatial_vertical_units\n",
      "                                                      not present\n",
      "instrument                             :1:     0/ 1 : Attr instrument not\n",
      "                                                      present\n",
      "instrument_vocabulary                  :1:     0/ 1 : Attr instrument_vocabulary\n",
      "                                                      not present\n",
      "keywords_vocabulary                    :1:     0/ 1 : Attr keywords_vocabulary\n",
      "                                                      not present\n",
      "platform                               :1:     0/ 1 : Attr platform not present\n",
      "platform_vocabulary                    :1:     0/ 1 : Attr platform_vocabulary\n",
      "                                                      not present\n",
      "program                                :1:     0/ 1 : Attr program not present\n",
      "publisher_institution                  :1:     0/ 1 : Attr publisher_institution\n",
      "                                                      not present\n",
      "publisher_type                         :1:     0/ 2 : Attr publisher_type not\n",
      "                                                      present\n",
      "references                             :1:     0/ 1 : Attr references not\n",
      "                                                      present\n"
     ]
    }
   ],
   "source": [
    "!compliance-checker sample.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check file opens correctly in QGIS\n",
    "If your file contains spatial data, open the NetCDF in QGIS to verify it plots in the correct location, and that nodata values are correctly accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
