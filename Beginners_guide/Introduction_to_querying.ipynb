{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook currently compatible with the `NCI`|`DEA Sandbox` environment only**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "All DEA analyses require the basic construction of a data query which specifies the what? where? and when? of the data request.\n",
    "Each query returns an xarray dataset containing the contents of your request.\n",
    "It is essential to understand the xarray dataset as it is fundamental to the structure of the datacube.\n",
    "Manipulations, transformations and visualisation of the xarray contents provide datacube users with the ability to explore DEA datasets and pose and answer scientific questions.\n",
    "This notebook introduces how to construct and customise datacube queries in addition to introducing the xarray dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Users of this notebook should have a basic understanding of:\n",
    "* how to run a [Jupyter notebook](future link to Intro_to_Jupyter)\n",
    "* the basic structure of the DEA [satellite datasets](future link to Intro_to_DEA)\n",
    "* how to identify [DEA products and measurements](future link to Intro_to_products_and_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook will introduce how to load data from the datacube through the construction of a query and use of the *load* function.\n",
    "Topics covered include:\n",
    "* Loading data\n",
    "* Reading the resulting xarray dataset\n",
    "* Customising the load function\n",
    "  * crs\n",
    "  * multi-sensor queries\n",
    "  * loading cloud-masked data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical details\n",
    "* **Products used:** `product_name`, `product_name`, `product_name`\n",
    "* **Analyses used:** NDWI water index, geomedian compositing, pixel drill\n",
    "* **Special requirements:** An _optional_ description of any special requirements, e.g. If running on the [NCI](https://nci.org.au/), ensure that `module load otps` is run prior to launching this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this introduction to querying, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Use standard import commands; some are shown below. \n",
    "Begin with any `iPython` magic commands, followed by standard Python packages, then any additional functionality you need from the `Scripts` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import datacube\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "# import xarray as xr\n",
    "\n",
    "# sys.path.append(\"../Scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Give your datacube app a unique name that is consistent with the purpose of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "# Temporary solution to account for Collection 3 data being in a different\n",
    "# database on the NCI\n",
    "try:\n",
    "    dc = datacube.Datacube(app='Introduction_to_querying', env='c3-samples')\n",
    "except:\n",
    "    dc = datacube.Datacube(app='Introduction_to_querying')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load in module datacube.api.core:\n",
      "\n",
      "load(product=None, measurements=None, output_crs=None, resolution=None, resampling=None, skip_broken_datasets=False, dask_chunks=None, like=None, fuse_func=None, align=None, datasets=None, progress_cbk=None, **query) method of datacube.api.core.Datacube instance\n",
      "    Load data as an ``xarray`` object.  Each measurement will be a data variable in the :class:`xarray.Dataset`.\n",
      "    \n",
      "    See the `xarray documentation <http://xarray.pydata.org/en/stable/data-structures.html>`_ for usage of the\n",
      "    :class:`xarray.Dataset` and :class:`xarray.DataArray` objects.\n",
      "    \n",
      "    **Product and Measurements**\n",
      "        A product can be specified using the product name, or by search fields that uniquely describe a single\n",
      "        product.\n",
      "        ::\n",
      "    \n",
      "            product='ls5_ndvi_albers'\n",
      "    \n",
      "        See :meth:`list_products` for the list of products with their names and properties.\n",
      "    \n",
      "        A product can also be selected by searching using fields, but must only match one product.\n",
      "        For example::\n",
      "    \n",
      "            platform='LANDSAT_5',\n",
      "            product_type='ndvi'\n",
      "    \n",
      "        The ``measurements`` argument is a list of measurement names, as listed in :meth:`list_measurements`.\n",
      "        If not provided, all measurements for the product will be returned.\n",
      "        ::\n",
      "    \n",
      "            measurements=['red', 'nir', 'swir2']\n",
      "    \n",
      "    **Dimensions**\n",
      "        Spatial dimensions can specified using the ``longitude``/``latitude`` and ``x``/``y`` fields.\n",
      "    \n",
      "        The CRS of this query is assumed to be WGS84/EPSG:4326 unless the ``crs`` field is supplied,\n",
      "        even if the stored data is in another projection or the `output_crs` is specified.\n",
      "        The dimensions ``longitude``/``latitude`` and ``x``/``y`` can be used interchangeably.\n",
      "        ::\n",
      "    \n",
      "            latitude=(-34.5, -35.2), longitude=(148.3, 148.7)\n",
      "    \n",
      "        or ::\n",
      "    \n",
      "            x=(1516200, 1541300), y=(-3867375, -3867350), crs='EPSG:3577'\n",
      "    \n",
      "        The ``time`` dimension can be specified using a tuple of datetime objects or strings with\n",
      "        `YYYY-MM-DD hh:mm:ss` format. E.g::\n",
      "    \n",
      "            time=('2001-04', '2001-07')\n",
      "    \n",
      "        For EO-specific datasets that are based around scenes, the time dimension can be reduced to the day level,\n",
      "        using solar day to keep scenes together.\n",
      "        ::\n",
      "    \n",
      "            group_by='solar_day'\n",
      "    \n",
      "        For data that has different values for the scene overlap the requires more complex rules for combining data,\n",
      "        such as GA's Pixel Quality dataset, a function can be provided to the merging into a single time slice.\n",
      "    \n",
      "        See :func:`datacube.helpers.ga_pq_fuser` for an example implementation.\n",
      "    \n",
      "    \n",
      "    **Output**\n",
      "        To reproject or resample the data, supply the ``output_crs``, ``resolution``, ``resampling`` and ``align``\n",
      "        fields.\n",
      "    \n",
      "        To reproject data to 25m resolution for EPSG:3577::\n",
      "    \n",
      "            dc.load(product='ls5_nbar_albers', x=(148.15, 148.2), y=(-35.15, -35.2), time=('1990', '1991'),\n",
      "                    output_crs='EPSG:3577`, resolution=(-25, 25), resampling='cubic')\n",
      "    \n",
      "    :param str product: the product to be included.\n",
      "    \n",
      "    :param measurements:\n",
      "        Measurements name or list of names to be included, as listed in :meth:`list_measurements`.\n",
      "    \n",
      "        If a list is specified, the measurements will be returned in the order requested.\n",
      "        By default all available measurements are included.\n",
      "    \n",
      "    :type measurements: list(str), optional\n",
      "    \n",
      "    :param query:\n",
      "        Search parameters for products and dimension ranges as described above.\n",
      "    \n",
      "    :param str output_crs:\n",
      "        The CRS of the returned data.  If no CRS is supplied, the CRS of the stored data is used.\n",
      "    \n",
      "    :param (float,float) resolution:\n",
      "        A tuple of the spatial resolution of the returned data.\n",
      "        This includes the direction (as indicated by a positive or negative number).\n",
      "    \n",
      "        Typically when using most CRSs, the first number would be negative.\n",
      "    \n",
      "    :param str|dict resampling:\n",
      "        The resampling method to use if re-projection is required. This could be a string or\n",
      "        a dictionary mapping band name to resampling mode. When using a dict use ``'*'`` to\n",
      "        indicate \"apply to all other bands\", for example ``{'*': 'cubic', 'fmask': 'nearest'}`` would\n",
      "        use `cubic` for all bands except ``fmask`` for which `nearest` will be used.\n",
      "    \n",
      "        Valid values are: ``'nearest', 'cubic', 'bilinear', 'cubic_spline', 'lanczos', 'average',\n",
      "        'mode', 'gauss',  'max', 'min', 'med', 'q1', 'q3'``\n",
      "    \n",
      "        Default is to use ``nearest`` for all bands.\n",
      "        .. seealso:: :meth:`load_data`\n",
      "    \n",
      "    :param (float,float) align:\n",
      "        Load data such that point 'align' lies on the pixel boundary.\n",
      "        Units are in the co-ordinate space of the output CRS.\n",
      "    \n",
      "        Default is (0,0)\n",
      "    \n",
      "    :param dict dask_chunks:\n",
      "        If the data should be lazily loaded using :class:`dask.array.Array`,\n",
      "        specify the chunking size in each output dimension.\n",
      "    \n",
      "        See the documentation on using `xarray with dask <http://xarray.pydata.org/en/stable/dask.html>`_\n",
      "        for more information.\n",
      "    \n",
      "    :param xarray.Dataset like:\n",
      "        Uses the output of a previous ``load()`` to form the basis of a request for another product.\n",
      "        E.g.::\n",
      "    \n",
      "            pq = dc.load(product='ls5_pq_albers', like=nbar_dataset)\n",
      "    \n",
      "    :param str group_by:\n",
      "        When specified, perform basic combining/reducing of the data.\n",
      "    \n",
      "    :param fuse_func:\n",
      "        Function used to fuse/combine/reduce data with the ``group_by`` parameter. By default,\n",
      "        data is simply copied over the top of each other, in a relatively undefined manner. This function can\n",
      "        perform a specific combining step, eg. for combining GA PQ data. This can be a dictionary if different\n",
      "        fusers are needed per band.\n",
      "    \n",
      "    :param datasets:\n",
      "        Optional. If this is a non-empty list of :class:`datacube.model.Dataset` objects, these will be loaded\n",
      "        instead of performing a database lookup.\n",
      "    \n",
      "    :param int limit:\n",
      "        Optional. If provided, limit the maximum number of datasets\n",
      "        returned. Useful for testing and debugging.\n",
      "    \n",
      "    :param progress_cbk: Int, Int -> None\n",
      "        if supplied will be called for every file read with `files_processed_so_far, total_files`. This is\n",
      "        only applicable to non-lazy loads, ignored when using dask.\n",
      "    \n",
      "    :return: Requested data in a :class:`xarray.Dataset`\n",
      "    :rtype: :class:`xarray.Dataset`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Testing cell\n",
    "help(dc.load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Loading data from the datacube uses the *load* function.\n",
    "\n",
    "The function requires the following minimum arguments:\n",
    "\n",
    "* *product*; A specifc product to load. To revise DEA products, see the [Introduction_to_products_and_measurements](future link to Intro_to_products_and_measurements)\n",
    "* *x*; Defines the spatial region in the *x* dimension\n",
    "* *y*; Defines the spatial region in the *y* dimension\n",
    "* *time*; Defines the temporal extent.\n",
    "\n",
    "Lets run a query to load all datasets within the landsat 7 nbart annual geomedian product for Moreton Bay in QLD.\n",
    "The *load* function requires the minimum following criteria:\n",
    "\n",
    "* product: ls7_nbart_geomedian_annual\n",
    "* location: x=(153.3, 153.4), y=(-27.5, -27.6)\n",
    "* time period: 2015-01-01 to 2016-01-01\n",
    "\n",
    "Run the following cell to load all matching datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This runs as a minimum viable query using ls7_nbart_geomedian_annual. It doesn't work using ga_ls5t_ard_3\n",
    "data = dc.load(product='ls7_nbart_geomedian_annual', \n",
    "               x=(153.3, 153.4), y=(-27.5, -27.6),\n",
    "               time=('2015-01-01', '2016-01-01'))\n",
    "\n",
    "# #Whereas this does work with the ls5 product but requires more info in the query. \n",
    "# data = dc.load(product='ga_ls5t_ard_3', \n",
    "#                x=(2067437.5, 2078937.5), y=(-3168487.5, -3155812.5), crs='EPSG:3577',          \n",
    "#                time=('2008-01-01', '2008-02-01'),\n",
    "#                output_crs = 'EPSG: 3577',\n",
    "#                resolution = (25,25))\n",
    "\n",
    "#This is an issue because I want to run the example using a basic product that has a range of measurements from which to search.\n",
    "#LS5 ard offers the measurements but I also want to show a bare bones query before tailoring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2, x: 461, y: 508)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2015-01-01 2016-01-01\n",
      "  * y        (y) float64 -3.156e+06 -3.156e+06 ... -3.168e+06 -3.168e+06\n",
      "  * x        (x) float64 2.067e+06 2.067e+06 2.067e+06 ... 2.079e+06 2.079e+06\n",
      "Data variables:\n",
      "    blue     (time, y, x) int16 519 496 480 499 503 506 ... 366 316 287 289 300\n",
      "    green    (time, y, x) int16 563 555 545 558 552 553 ... 565 487 456 415 460\n",
      "    red      (time, y, x) int16 308 306 312 314 307 308 ... 490 419 400 365 390\n",
      "    nir      (time, y, x) int16 207 183 183 189 187 ... 2866 2650 2505 2440 2538\n",
      "    swir1    (time, y, x) int16 89 88 88 99 112 117 ... 1752 1368 1127 1120 1229\n",
      "    swir2    (time, y, x) int16 75 98 87 82 91 94 96 ... 894 898 657 573 495 553\n",
      "Attributes:\n",
      "    crs:      EPSG:3577\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the result xarray.Dataset\n",
    "The variable *data* has returned an xarray Dataset containing all matching datasets.\n",
    "\n",
    "*Dimensions* \n",
    "* identifies the number of temporal datasets returned in the search as well as the number of pixels in the x and y directions of the data query.\n",
    "\n",
    "*Coordinates* \n",
    "* *time* identifies the date attributed to each returned dataset\n",
    "* *x* and *y* are the coordinates for the pixels within the spatial bounds of your query\n",
    "\n",
    "*Data variables*\n",
    "* These are the measurements available for the nominated product. For every date (time) returned by the query, the spectral response for each pixel (y, x) is returned as an array for each measurement.\n",
    "\n",
    "*Attributes*\n",
    "* *crs* identifies the coordinate reference system. By default, the *x* and *y* arguments accept queries in a geographical co-ordinate system WGS84, identified by the EPSG code *4326*, which is the same as within Google Earth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customising the *load* function\n",
    "\n",
    "The *load* function can be tailored to refine a query.\n",
    "\n",
    "Common customisation options include:\n",
    "* *measurements*:   The ``measurements`` argument is a list of measurement names, as listed in `dc.list_measurements()`. \n",
    "                    If not provided, all measurements for the product will be returned.\n",
    "                \n",
    "* *crs*:            The CRS of the query is assumed to be WGS84/EPSG:4326 unless the ``crs`` field is supplied, even if the stored \n",
    "                    data is in another projection or the `output_crs` is specified.\n",
    "                    The dimensions ``longitude``/``latitude`` and ``x``/``y`` can be used interchangeably.\n",
    "\n",
    "* *time*:           The ``time`` dimension can be specified using a tuple of datetime objects or strings with\n",
    "                    `YYYY-MM-DD hh:mm:ss` format. E.g:\n",
    "                    time=('2001-04', '2001-07')\n",
    "                \n",
    "* *group_by*:       For EO-specific datasets that are based around scenes, the time dimension can be reduced to the day level,\n",
    "                    using solar day to keep scenes together.\n",
    "                    group_by='solar_day'             \n",
    "                \n",
    "* *reproject/resample*: To reproject or resample the data, supply the ``output_crs``, ``resolution``, ``resampling`` and ``align``\n",
    "                    fields.\n",
    "                    Eg. To reproject data to 25m resolution for EPSG:3577:\n",
    "                    dc.load(product='ls5_nbar_albers', x=(148.15, 148.2), y=(-35.15, -35.2), time=('1990', '1991'),\n",
    "                        output_crs='EPSG:3577`, resolution=(-25, 25), resampling='cubic')             \n",
    "\n",
    "For help or more customisation options, run help(dc.load) in an empty cell\n",
    "\n",
    "Example syntax on the use of these options follows in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crs\n",
    "Users can query via the native co-ordinate system that the product is stored in, and supply the *crs* argument.\n",
    "\n",
    "Run the cell below. Note that the result is identical to the initial query you ran in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                     (time: 1, x: 461, y: 508)\n",
      "Coordinates:\n",
      "  * time                        (time) datetime64[ns] 2008-01-24T23:33:03.370408\n",
      "  * y                           (y) float64 -3.168e+06 -3.168e+06 ... -3.156e+06\n",
      "  * x                           (x) float64 2.067e+06 2.067e+06 ... 2.079e+06\n",
      "Data variables:\n",
      "    nbar_blue                   (time, y, x) int16 883 736 1448 ... 342 342 359\n",
      "    nbar_green                  (time, y, x) int16 990 692 1711 ... 326 292 359\n",
      "    nbar_red                    (time, y, x) int16 919 733 1634 ... 198 225 225\n",
      "    nbar_nir                    (time, y, x) int16 1655 1519 2538 ... 181 216\n",
      "    nbar_swir_1                 (time, y, x) int16 1047 1002 1859 ... 76 76 76\n",
      "    nbar_swir_2                 (time, y, x) int16 764 731 1283 ... 82 82 50\n",
      "    nbart_blue                  (time, y, x) int16 878 732 1440 ... 342 342 359\n",
      "    nbart_green                 (time, y, x) int16 985 688 1702 ... 326 292 359\n",
      "    nbart_red                   (time, y, x) int16 914 728 1625 ... 198 225 225\n",
      "    nbart_nir                   (time, y, x) int16 1646 1511 2526 ... 181 216\n",
      "    nbart_swir_1                (time, y, x) int16 1040 995 1848 ... 76 76 76\n",
      "    nbart_swir_2                (time, y, x) int16 759 727 1275 ... 82 82 50\n",
      "    oa_fmask                    (time, y, x) uint8 1 1 1 1 1 2 2 ... 5 5 5 5 5 5\n",
      "    oa_nbar_contiguity          (time, y, x) uint8 1 1 1 1 1 1 1 ... 1 1 1 1 1 1\n",
      "    oa_nbart_contiguity         (time, y, x) uint8 1 1 1 1 1 1 1 ... 1 1 1 1 1 1\n",
      "    oa_azimuthal_exiting        (time, y, x) float32 -52.79128 ... -80.79672\n",
      "    oa_azimuthal_incident       (time, y, x) float32 -171.13414 ... 83.91238\n",
      "    oa_combined_terrain_shadow  (time, y, x) uint8 1 1 1 1 1 1 1 ... 1 1 1 1 1 1\n",
      "    oa_exiting_angle            (time, y, x) float32 0.8042993 ... 0.29374656\n",
      "    oa_incident_angle           (time, y, x) float32 33.77885 ... 34.263702\n",
      "    oa_relative_azimuth         (time, y, x) float32 15.432808 ... 195.2909\n",
      "    oa_relative_slope           (time, y, x) float32 -118.342865 ... 164.7091\n",
      "    oa_satellite_azimuth        (time, y, x) float32 99.214874 ... 279.20328\n",
      "    oa_satellite_view           (time, y, x) float32 0.20097993 ... 0.29374656\n",
      "    oa_solar_azimuth            (time, y, x) float32 83.78207 ... 83.91238\n",
      "    oa_solar_zenith             (time, y, x) float32 34.360928 ... 34.263702\n",
      "    oa_time_delta               (time, y, x) float32 2.93645 ... 0.637697\n",
      "Attributes:\n",
      "    crs:      EPSG: 3577\n"
     ]
    }
   ],
   "source": [
    "data_native_crs = dc.load(product='ga_ls5t_ard_3', \n",
    "               x=(2067437.5, 2078937.5), y=(-3168487.5, -3155812.5), crs='EPSG:3577',          \n",
    "               time=('2008-01-01', '2008-02-01'),\n",
    "               output_crs = 'EPSG: 3577',\n",
    "               resolution = (25,25))\n",
    "print (data_native_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc.list_measurements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a query across multiple sensors/products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_range = (-27.715, -27.755)\n",
    "lon_range = (153.42, 153.46)\n",
    "time_range = ('1988', '2018')\n",
    "time_step = '2Y'\n",
    "tide_range = (0.50, 1.00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cloud-masked Landsat data\n",
    "The first step in this analysis is to load in Landsat data for the `lat_range`, `lon_range` and `time_range` we provided above. \n",
    "The code below first connects to the datacube database, and then uses the `load_cloudmaskedlandsat` function to load in data from the Landsat 5, 7 and 8 satellites for the area and time included in `lat_range`, `lon_range` and `time_range`. \n",
    "The function will also automatically mask out clouds from the dataset, allowing us to focus on pixels that contain useful data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'query' dictionary object, which contains the longitudes, \n",
    "# latitudes and time provided above\n",
    "query = {\n",
    "    'y': lat_range,\n",
    "    'x': lon_range,\n",
    "    'time': time_range,\n",
    "    'measurements': ['nbart_red', 'nbart_green', 'nbart_blue', 'nbart_swir_1'],\n",
    "    'resolution': (-30, 30),\n",
    "}\n",
    "\n",
    "# Identify the most common projection system in the input query \n",
    "output_crs = mostcommon_crs(dc=dc, product='ga_ls5t_ard_3', query=query)\n",
    "\n",
    "# Load available data from all three Landsat satellites\n",
    "landsat_ds = load_ard(dc=dc, \n",
    "                      products=['ga_ls5t_ard_3', \n",
    "                                'ga_ls7e_ard_3', \n",
    "                                'ga_ls8c_ard_3'], \n",
    "                      lazy_load=True,\n",
    "                      output_crs=output_crs,\n",
    "                      align=(15, 15),\n",
    "                      group_by='solar_day',\n",
    "                      **query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended next steps\n",
    "\n",
    "Recommend notebooks to follow on from this one: list products, list measurements, run a basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** September 2019\n",
    "\n",
    "**Compatible `datacube` version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7+43.gc873f3ea\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`sandbox_compatible`, :index:`nci_compatible`, :index:`template`, :index:`dc.load`, :index:`plotting`, :index:`landsat8`, :index:`pixeldrill`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
