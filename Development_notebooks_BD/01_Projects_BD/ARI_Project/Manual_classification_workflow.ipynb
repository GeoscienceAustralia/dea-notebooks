{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Imagery for ARI Manual Classification Workflow <img align=\"right\" src=\"../../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule),\n",
    "[ga_ls5t_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The ability to extract pixel boundaries as a shapefile or other vector file type is very useful for remote sensing applications where the boundaries of the pixel are needed. \n",
    "This is useful for matching drone imagery with remotely sensed imagery. The Fractional Cover of Water project requires us to use satellite imagery from Landsat and Sentinel 2 satellites that match our drone imagery from our field sites. We take the matching imagery, find the pixel edges, and then manually classify what is in the pixels (what type of wet vegetation we have and what fraction of the pixel it covers), in order to create input data for the algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The notebook uses drone imagery to classify the land cover type, including `Floating, Emergent, OpenWater, GreenVeg(PV), DryVeg(NPV), BareSoil(BS), Forel-Ule water colour (if the type is OpenWater)`\n",
    "\n",
    "* first bring in the drone data in resolution (1, -1) (unit meter)\n",
    "* classify the pixels into categories listed above\n",
    "* save the results as raster into `geotiff`\n",
    "\n",
    "To use the notebook, please refer the instruction video and doc linked below\n",
    "- xxx\n",
    "- xxx\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get started\n",
    "\n",
    "### 1. Upload drone image (refer the instruction doc), then find out the file name by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set the variable `drone_tif_path` accordingly, \n",
    "e.g. `drone_tif_path = \"./Sbends_Orthomosaic_export_TueAug18040306687120.tif\"` from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file name if necessary\n",
    "drone_tif_path = \"./Sbends_Orthomosaic_export_TueAug18040306687120.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `Run -> Run All Cells`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import datacube\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "import xarray as xr\n",
    "import re\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "from datacube.utils.geometry import GeoBox\n",
    "from odc.algo import xr_reproject\n",
    "\n",
    "from rasterio import warp\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook, show\n",
    "from bokeh.layouts import layout, column, row\n",
    "from bokeh.models import (CheckboxGroup, Select, ColumnDataSource, HoverTool, YearsTicker, Legend,\n",
    "                          CustomJS, LegendItem, field, Range1d, Circle, Button, RadioGroup, TextInput, WheelZoomTool,\n",
    "                          ResetTool, BoxZoomTool, SaveTool, LinearColorMapper, CategoricalColorMapper, \n",
    "                          Label, PreText, FileInput, Toggle)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.palettes import Blues256\n",
    "from bokeh.colors import RGB, named\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.dea_dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the drone orthomosaic for your wetland of interest\n",
    "The path here points to the example_data folder; change if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the local path of output raster or can be changed later\n",
    "results_tif_path = './test.tif'\n",
    "# don't change this unless required\n",
    "drone_res_tgt = (1, 1)\n",
    "furgb = np.array([\n",
    "        [1,33,88,188],\n",
    "        [2,49,109,197],\n",
    "        [3,50,124,187],\n",
    "        [4,75,128,160],\n",
    "        [5,86,143,150],\n",
    "        [6,109,146,152],\n",
    "        [7,105,140,134],\n",
    "        [8,117,158,114],\n",
    "        [9,123,166,84],\n",
    "        [10,125,174,56],\n",
    "        [11,149,182,69],\n",
    "        [12,148,182,96],\n",
    "        [13,165,188,118],\n",
    "        [14,170,184,109],\n",
    "        [15,173,181,95],\n",
    "        [16,168,169,101],\n",
    "        [17,174,159,92],\n",
    "        [18,179,160,83],\n",
    "        [19,175,138,68],\n",
    "        [20,164,105,5],\n",
    "        [21,161,44,4]], dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drone_tif(fname, res_tgt):\n",
    "    drone = xr.open_rasterio(fname, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "    drone = assign_crs(drone)\n",
    "    affine, width, height = warp.calculate_default_transform(drone.crs, 'EPSG:3577', drone.shape[1], drone.shape[2],\n",
    "                                             *drone.geobox.extent.boundingbox)\n",
    "    tgt_affine, tgt_width, tgt_height = warp.aligned_target(affine, width, height, res_tgt)\n",
    "    drone_geobox = GeoBox(tgt_width, tgt_height, tgt_affine, 'EPSG:3577')\n",
    "    drone_tgt = xr_reproject(drone, drone_geobox, resampling= 'bilinear' )\n",
    "    return drone_tgt.load()\n",
    "\n",
    "def load_results_tif(fname):\n",
    "    results = xr.open_rasterio(fname, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "    return results.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_tgt = load_drone_tif(drone_tif_path, drone_res_tgt)\n",
    "rgba_image = np.empty((drone_tgt.shape[1], drone_tgt.shape[2]), dtype='uint32')\n",
    "view = rgba_image.view(dtype='uint8').reshape(drone_tgt.shape[1], drone_tgt.shape[2], drone_tgt.shape[0])\n",
    "for i in range(3):\n",
    "    view[:, :, i] = (drone_tgt.data[i]).astype('uint8')\n",
    "view[:, :, 3] = 255\n",
    "scale_factor = np.array([drone_tgt.x.data.min() if drone_tgt.x.data.min() > 0 else drone_tgt.x.data.max(),\n",
    "                         drone_tgt.y.data.min() if drone_tgt.y.data.min() > 0 else drone_tgt.y.data.max()])\n",
    "xr_results = xr.DataArray(data=[np.zeros(rgba_image.shape, dtype='uint8')] * 2, dims=['band', 'y', 'x'], \n",
    "                     coords={'band': [1, 2], \n",
    "                     'y': drone_tgt.coords['y'], 'x':drone_tgt.coords['x']}, attrs={'nodata':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_doc(doc):\n",
    "    drone_source = ColumnDataSource(data={'img': [np.flip(rgba_image, axis=0)]})\n",
    "    results_source = ColumnDataSource(data={'category': [np.zeros(rgba_image.shape, dtype='uint8')],\n",
    "                                           'forel_ule': [np.zeros(rgba_image.shape, dtype='uint8')]})\n",
    "    \n",
    "    drone_file_input = TextInput(value=drone_tif_path, title=\"Load drone imagery\", height=50, width=600,\n",
    "                                sizing_mode='fixed')\n",
    "    def open_drone_tif(attrname, old, new):\n",
    "        fname = drone_file_input.value\n",
    "        if not path.exists(fname):\n",
    "            print(\"file doesn't exist!\")\n",
    "            return\n",
    "        drone_tgt = load_drone_tif(fname, drone_res_tgt)\n",
    "        rgba_image = np.empty((drone_tgt.shape[1], drone_tgt.shape[2]), dtype='uint32')\n",
    "        view = rgba_image.view(dtype='uint8').reshape(drone_tgt.shape[1], drone_tgt.shape[2], drone_tgt.shape[0])\n",
    "        for i in range(3):\n",
    "            view[:, :, i] = (drone_tgt.data[i]).astype('uint8')\n",
    "        view[:, :, 3] = 255\n",
    "        scale_factor = np.array([drone_tgt.x.data.min() if drone_tgt.x.data.min() > 0 else drone_tgt.x.data.max(),\n",
    "                         drone_tgt.y.data.min() if drone_tgt.y.data.min() > 0 else drone_tgt.y.data.max()])\n",
    "        drone_source.data['img'] = [np.flip(rgba_image, axis=0)]\n",
    "        global xr_results\n",
    "        xr_results = xr.DataArray(data=[np.zeros(rgba_image.shape, dtype='uint8')] * 2, dims=['band', 'y', 'x'], \n",
    "                     coords={'band': [1, 2], \n",
    "                     'y': drone_tgt.coords['y'], 'x':drone_tgt.coords['x']}, attrs={'nodata':0})\n",
    "        results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "        \n",
    "    drone_file_input.on_change('value', open_drone_tif)\n",
    "    \n",
    "    result_file_input = TextInput(value=\"./test.tif\", title=\"Results tiff file\", height=50, width=600,\n",
    "                                sizing_mode='fixed')\n",
    "    result_save_button = Button(label=\"Save results\", button_type=\"success\")\n",
    "    result_load_button = Button(label=\"Load results\", button_type=\"success\")\n",
    "    def open_result_tif(event):\n",
    "        fname = result_file_input.value\n",
    "        if not path.exists(fname):\n",
    "            print(\"file doesn't exist!\")\n",
    "            return\n",
    "        global xr_results\n",
    "        xr_results = load_results_tif(fname)\n",
    "        results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "        \n",
    "    def save_result_tif(event):\n",
    "        fname = result_file_input.value\n",
    "        if path.exists(fname):\n",
    "            time_now = str(datetime.now()).replace(':', '').replace(' ', '').replace('-', '')\n",
    "            os.rename(fname, fname + '.bak' + time_now)\n",
    "        write_cog(xr_results, fname)\n",
    "        \n",
    "    result_load_button.on_click(open_result_tif)\n",
    "    result_save_button.on_click(save_result_tif)\n",
    "    \n",
    "    drone_fig = figure(tooltips=[('x-cood', \"$x{0.0}\"), ('y-coord', \"$y{0.0}\")], title=\"image %s\" %(\"drone\"), \n",
    "            x_axis_type='auto', y_axis_type='auto', x_minor_ticks=10, y_minor_ticks=10,\n",
    "            x_axis_label=\"x origin %s\" % scale_factor[0],\n",
    "            y_axis_label=\"y origin %s\" % scale_factor[1])\n",
    "    drone_fig.toolbar.active_scroll = drone_fig.select_one(WheelZoomTool)\n",
    "    drone_tag = ['drone', 1]\n",
    "    drone_fig.image_rgba(image='img', source=drone_source, \n",
    "                x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "               dw=drone_tgt.shape[2], dh=drone_tgt.shape[1],\n",
    "                         tags=drone_tag,\n",
    "                         level=\"image\")\n",
    "    transparent_white = RGB(255, 255, 255, 0)\n",
    "    cats_color = [named.lawngreen.to_rgb(), named.limegreen.to_rgb(), named.olive.to_rgb(),\n",
    "                  named.deepskyblue.to_rgb(), named.darkgreen.to_rgb(), named.beige.to_rgb(),\n",
    "                  named.brown.to_rgb()]\n",
    "    cats_color_mapper = LinearColorMapper(cats_color, low=1, high=len(cats_color), low_color=transparent_white)\n",
    "    water_color = [RGB(f[1], f[2], f[3], 255) for f in furgb]\n",
    "    water_color_mapper = LinearColorMapper(water_color, low=1, high=21, low_color=transparent_white)\n",
    "    water_tag = ['forel_ule', 21]\n",
    "    cats_tag = ['cats', 10]\n",
    "    water_image = drone_fig.image(image='forel_ule', source=results_source, x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "                dw=drone_tgt.shape[2], dh=drone_tgt.shape[1], \n",
    "                color_mapper=water_color_mapper,\n",
    "                global_alpha=0.8,\n",
    "                level=\"image\", tags=water_tag)\n",
    "    \n",
    "    cats_image = drone_fig.image(image='category', source=results_source, x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "                dw=drone_tgt.shape[2], dh=drone_tgt.shape[1], \n",
    "                color_mapper=cats_color_mapper,\n",
    "                global_alpha=0.8,\n",
    "                level=\"image\", tags=cats_tag)\n",
    "   \n",
    "    coords_label = PreText(text=\"null\", width=100, sizing_mode='fixed')\n",
    "    js_code = \"\"\"\n",
    "        var ind_x = Math.floor(cb_obj.x);\n",
    "        var ind_y = Math.floor(cb_obj.y);\n",
    "        var data_s = source.data;\n",
    "        console.log(\"x:\", ind_x);\n",
    "        console.log(\"y:\", ind_y);\n",
    "        target.text = \"x=\" + ind_x.toString() +\";\" + \"y=\" + ind_y.toString();\n",
    "    \"\"\"\n",
    "    js_callback = CustomJS(args={'source': drone_source, 'target': coords_label}, \n",
    "                           code=js_code)\n",
    "    drone_fig.js_on_event('tap', js_callback)\n",
    "    \n",
    "    def get_ind_from_coords():\n",
    "        if (coords_label.text == \"null\"):\n",
    "            print(\"pick a pixel please\")\n",
    "            return (None, None)\n",
    "        coords = coords_label.text.split(';')\n",
    "        ind_x = coords[0].split('=')[1]\n",
    "        ind_y = coords[1].split('=')[1]\n",
    "        return (abs(int(ind_y)), abs(int(ind_x)))\n",
    "\n",
    "    cats = [\"NA\", \"Overstory\",\"Emergent\",\"Floating\",\"OpenWater\",\"GreenVeg\",\"DryVeg\",\"Bare\"]  \n",
    "    radio_group = RadioGroup(labels=cats, active=0, height=800, height_policy=\"fixed\", aspect_ratio=0.1)\n",
    "    forel_ule_scale = TextInput(value=\"0\", title=\"Forel-Ule Water Colour\", width=100, sizing_mode='fixed')  \n",
    "    def choose_cat(attrname, old, new):\n",
    "        ind_y, ind_x = get_ind_from_coords()\n",
    "        if ind_y is None or ind_x is None:\n",
    "            return\n",
    "        if attrname == 'active':\n",
    "            xr_results[0][ind_y, ind_x] = radio_group.active\n",
    "            results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        if attrname == 'value':  \n",
    "            check_numbers = re.match(r'^[0-9]+$', forel_ule_scale.value)\n",
    "            if check_numbers is None:\n",
    "                print(\"only input numbers\", forel_ule_scale.value)\n",
    "                forel_ule_scale.value = \"0\"\n",
    "            elif int(forel_ule_scale.value) < 0 or int(forel_ule_scale.value) > 21:\n",
    "                print(\"invalid value, please check!\")\n",
    "                forel_ule_scale.value = \"0\"\n",
    "            elif radio_group.active != 4 and int(forel_ule_scale.value) > 0:\n",
    "                forel_ule_scale.value = \"0\"\n",
    "                print(\"cannot set value for non-water\")\n",
    "            xr_results[1][ind_y, ind_x] = int(forel_ule_scale.value)\n",
    "            results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "            \n",
    "    radio_group.on_change('active', choose_cat)\n",
    "    forel_ule_scale.on_change('value', choose_cat)\n",
    "    \n",
    "    def coords_change(attrname, old, new):\n",
    "        ind_y, ind_x = get_ind_from_coords()\n",
    "        if ind_y is None or ind_x is None:\n",
    "            return\n",
    "        radio_group.active = xr_results[0].data[ind_y, ind_x]\n",
    "        forel_ule_scale.value = str(xr_results[1].data[ind_y, ind_x])\n",
    "        \n",
    "    coords_label.on_change('text', coords_change)\n",
    "                  \n",
    "    overlay_toggle_category = Toggle(label=\"Overlay category\", button_type=\"success\",\n",
    "                                     height=50, width=150, sizing_mode='fixed', active=True)\n",
    "    overlay_toggle_water_color = Toggle(label=\"Overlay water color\", button_type=\"success\", \n",
    "                                        height=50, width=150, sizing_mode='fixed', active=True)\n",
    "    \n",
    "    def overlay_results(event):\n",
    "        if (overlay_toggle_water_color.active):\n",
    "            water_image.visible = True\n",
    "        else:\n",
    "            water_image.visible = False\n",
    "        if (overlay_toggle_category.active):\n",
    "            cats_image.visible = True\n",
    "        else:\n",
    "            cats_image.visible = False\n",
    "            \n",
    "    overlay_toggle_category.on_click(overlay_results)\n",
    "    overlay_toggle_water_color.on_click(overlay_results)\n",
    "    \n",
    "    control_group = column(coords_label, forel_ule_scale, radio_group)\n",
    "    result_group = row(result_file_input, column(result_load_button, result_save_button))\n",
    "    layouts = layout([drone_file_input, result_group, [overlay_toggle_category, overlay_toggle_water_color],\n",
    "                      [control_group, drone_fig]], sizing_mode='scale_height')\n",
    "    doc.add_root(layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remote_jupyter_proxy_url(port):\n",
    "    \"\"\"\n",
    "    Callable to configure Bokeh's show method when a proxy must be\n",
    "    configured.\n",
    "\n",
    "    If port is None we're asking about the URL\n",
    "    for the origin header.\n",
    "    \"\"\"\n",
    "    base_url = \"https://app.sandbox.dea.ga.gov.au/\"\n",
    "    host = urllib.parse.urlparse(base_url).netloc\n",
    "    # If port is None we're asking for the URL origin\n",
    "    # so return the public hostname.\n",
    "    if port is None:\n",
    "        return host\n",
    "\n",
    "    service_url_path = os.environ['JUPYTERHUB_SERVICE_PREFIX']\n",
    "    proxy_url_path = 'proxy/%d' % port\n",
    "\n",
    "    user_url = urllib.parse.urljoin(base_url, service_url_path)\n",
    "    full_url = urllib.parse.urljoin(user_url, proxy_url_path)\n",
    "    return full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you know your url\n",
    "# notebook_url = \"http://localhost:8889\"\n",
    "show(plot_doc, notebook_url=remote_jupyter_proxy_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** August 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`,:index:`landsat 5`, :index:`landsat 7`, :index:`landsat 8`, :index:`sentinel 2`, :index:`dea_datahandling`, :index:`dea_plotting`, :index:`rgb`, :index:`load_ard`, :index:`vectorise`, :index:`shapefile`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
