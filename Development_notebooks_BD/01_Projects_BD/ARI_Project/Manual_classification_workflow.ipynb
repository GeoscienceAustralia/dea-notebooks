{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Imagery for ARI Manual Classification Workflow <img align=\"right\" src=\"../../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule),\n",
    "[ga_ls5t_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The ability to extract pixel boundaries as a shapefile or other vector file type is very useful for remote sensing applications where the boundaries of the pixel are needed. \n",
    "This is useful for matching drone imagery with remotely sensed imagery. The Fractional Cover of Water project requires us to use satellite imagery from Landsat and Sentinel 2 satellites that match our drone imagery from our field sites. We take the matching imagery, find the pixel edges, and then manually classify what is in the pixels (what type of wet vegetation we have and what fraction of the pixel it covers), in order to create input data for the algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook uses Digital Earth Australia to retrieve satellite data, creates a vector file from the pixel boundaries of the data, and exports to file.\n",
    "\n",
    "* first bring in the drone data\n",
    "* then take the extents off the drone data to use for loading the landsat and sentinel data pixel outlines\n",
    "* then load the outlines for each\n",
    "\n",
    "    1. We load some data for a chosen time frame and area using the dea-notebooks `load_ard` function\n",
    "    2. Then we convert our raster data into a polygon per pixel\n",
    "    3. Then we export our pixel edges polygons as a vector file (e.g. ESRI Shapefile or GeoJSON)\n",
    "    4. This loop is repeated (once for Sentinel-2 data and once for Landsat data)\n",
    "    \n",
    "* then we create a clickable thing that lets us add data about each LS and Sentinel 2 pixel to each (respective) vector file\n",
    "* the data for each pixel / shapefile columns needs to include: `Floating, Emergent, OpenWater, GreenVeg(PV), DryVeg(NPV), BareSoil(BS), Forel-Ule water colour (to add later)` \n",
    "* then we save out the shapefile with a sensible name, preserving dates and times and saying it's been changed.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import datacube\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "import xarray as xr\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "from datacube.utils.geometry import GeoBox\n",
    "from odc.algo import xr_reproject\n",
    "\n",
    "from rasterio import warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import curdoc, output_notebook, show\n",
    "from bokeh.layouts import layout, column, row\n",
    "from bokeh.models import (CheckboxGroup, Select, ColumnDataSource, HoverTool, YearsTicker, Legend,\n",
    "                          CustomJS, LegendItem, field, Range1d, Circle, Button, RadioGroup, TextInput, WheelZoomTool,\n",
    "                          ResetTool, BoxZoomTool, SaveTool, LinearColorMapper, CategoricalColorMapper, \n",
    "                          Label, PreText, FileInput, Toggle)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.palettes import Blues256\n",
    "from bokeh.colors import RGB, named\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dea_dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the drone orthomosaic for your wetland of interest\n",
    "The path here points to the example_data folder; change if necessary.\n",
    "You need to have the data exported from DroneDeploy in Web Mercator projection, `epsg:3857`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_tif_path = '/g/data/r78/rjd547/ARI/drone_imagery/Sbends_Orthomosaic_TueAug18040306687120/Sbends_Orthomosaic_export_TueAug18040306687120.tif'\n",
    "results_tif_path = './'\n",
    "drone_res_tgt = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drone_tif(fname, res_tgt):\n",
    "    drone = xr.open_rasterio(fname, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "    affine, width, height = warp.calculate_default_transform(drone.crs, 'EPSG:3577', drone.shape[1], drone.shape[2],\n",
    "                                             *drone.geobox.extent.boundingbox)\n",
    "    tgt_affine, tgt_width, tgt_height = warp.aligned_target(affine, width, height, res_tgt)\n",
    "    drone_geobox = GeoBox(tgt_width, tgt_height, tgt_affine, 'EPSG:3577')\n",
    "    drone_tgt = xr_reproject(drone, drone_geobox, resampling= 'bilinear' )\n",
    "    return drone_tgt.load()\n",
    "\n",
    "def load_results_tif(fname):\n",
    "    results = xr.open_rasterio(fname, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "    return results.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_tgt = load_drone_tif(drone_tif_path, drone_res_tgt)\n",
    "rgba_image = np.empty((drone_tgt.shape[1], drone_tgt.shape[2]), dtype='uint32')\n",
    "view = rgba_image.view(dtype='uint8').reshape(drone_tgt.shape[1], drone_tgt.shape[2], drone_tgt.shape[0])\n",
    "for i in range(3):\n",
    "    view[:, :, i] = (drone_tgt.data[i]).astype('uint8')\n",
    "view[:, :, 3] = 255\n",
    "scale_factor = np.array([drone_tgt.x.data.min() if drone_tgt.x.data.min() > 0 else drone_tgt.x.data.max(),\n",
    "                         drone_tgt.y.data.min() if drone_tgt.y.data.min() > 0 else drone_tgt.y.data.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_doc(doc):\n",
    "    drone_file_input = TextInput(value=drone_tif_path, title=\"Load drone imagery\", height=50, width=600,\n",
    "                                sizing_mode='fixed')\n",
    "    def open_drone_tif(attrname, old, new):\n",
    "        fname = drone_file_input.value\n",
    "        if not path.exists(fname):\n",
    "            print(\"file doesn't exist!\")\n",
    "            return\n",
    "        drone_tgt = load_drone_tif(fname, drone_res_tgt)\n",
    "        rgba_image = np.empty((drone_tgt.shape[1], drone_tgt.shape[2]), dtype='uint32')\n",
    "        view = rgba_image.view(dtype='uint8').reshape(drone_tgt.shape[1], drone_tgt.shape[2], drone_tgt.shape[0])\n",
    "        for i in range(3):\n",
    "            view[:, :, i] = (drone_tgt.data[i]).astype('uint8')\n",
    "        view[:, :, 3] = 255\n",
    "        scale_factor = np.array([drone_tgt.x.data.min() if drone_tgt.x.data.min() > 0 else drone_tgt.x.data.max(),\n",
    "                         drone_tgt.y.data.min() if drone_tgt.y.data.min() > 0 else drone_tgt.y.data.max()])\n",
    "        drone_source.data['img'] = [np.flip(rgba_image, axis=0)]\n",
    "        \n",
    "    drone_file_input.on_change('value', open_drone_tif)\n",
    "    \n",
    "    result_file_input = TextInput(value=\"./test.tif\", title=\"Results tiff file\", height=50, width=600,\n",
    "                                sizing_mode='fixed')\n",
    "    result_save_button = Button(label=\"Save results\", button_type=\"success\")\n",
    "    result_load_button = Button(label=\"Load results\", button_type=\"success\")\n",
    "    def open_result_tif(event):\n",
    "        fname = result_file_input.value\n",
    "        if not path.exists(fname):\n",
    "            print(\"file doesn't exist!\")\n",
    "            return\n",
    "        xr_results = load_results_tif(fname)\n",
    "        results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "        \n",
    "    def save_result_tif(event):\n",
    "        fname = result_file_input.value\n",
    "        if path.exists(fname):\n",
    "            time_now = str(datetime.now()).replace(':', '').replace(' ', '').replace('-', '')\n",
    "            os.rename(fname, fname + '.bak' + time_now)\n",
    "        write_cog(xr_results, fname)\n",
    "        \n",
    "    result_load_button.on_click(open_result_tif)\n",
    "    result_save_button.on_click(save_result_tif)\n",
    "\n",
    "    drone_source = ColumnDataSource(data={'img': [np.flip(rgba_image, axis=0)]})\n",
    "    results_source = ColumnDataSource(data={'category': [np.zeros(rgba_image.shape, dtype='uint8')],\n",
    "                                           'forel_ule': [np.zeros(rgba_image.shape, dtype='uint8')]})\n",
    "    xr_results = []\n",
    "    for value in results_source.data.values():\n",
    "        xr_results += value\n",
    "    xr_results = xr.DataArray(data=xr_results, dims=['band', 'y', 'x'], \n",
    "                     coords={'band': list(results_source.data.keys()), \n",
    "                     'y': drone_tgt.coords['y'], 'x':drone_tgt.coords['x']}, attrs={'nodata':0})\n",
    "    \n",
    "    drone_fig = figure(tooltips=[('x-cood', \"$x{0.0}\"), ('y-coord', \"$y{0.0}\")], title=\"image %s\" %(\"drone\"), \n",
    "            x_axis_type='auto', y_axis_type='auto', x_minor_ticks=10, y_minor_ticks=10,\n",
    "            x_axis_label=\"x origin %s\" % scale_factor[0],\n",
    "            y_axis_label=\"y origin %s\" % scale_factor[1])\n",
    "    drone_fig.toolbar.active_scroll = drone_fig.select_one(WheelZoomTool)\n",
    "    drone_tag = ['drone', 1]\n",
    "    drone_fig.image_rgba(image='img', source=drone_source, \n",
    "                x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "               dw=drone_tgt.shape[2], dh=drone_tgt.shape[1],\n",
    "                         tags=drone_tag,\n",
    "                         level=\"image\")\n",
    "    transparent_white = RGB(255, 255, 255, 0)\n",
    "    cats_color = [named.lawngreen.to_rgb(), named.limegreen.to_rgb(), named.olive.to_rgb(),\n",
    "                  named.deepskyblue.to_rgb(), named.darkgreen.to_rgb(), named.beige.to_rgb(),\n",
    "                  named.brown.to_rgb()]\n",
    "    cats_color_mapper = LinearColorMapper(cats_color, low=1, high=len(cats_color), low_color=transparent_white)\n",
    "    water_color_mapper = LinearColorMapper(Blues256, low=1, high=21, low_color=transparent_white)\n",
    "    water_tag = ['forel_ule', 21]\n",
    "    cats_tag = ['cats', 10]\n",
    "    water_image = drone_fig.image(image='forel_ule', source=results_source, x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "                dw=drone_tgt.shape[2], dh=drone_tgt.shape[1], \n",
    "                color_mapper=water_color_mapper,\n",
    "                global_alpha=0.8,\n",
    "                level=\"image\", tags=water_tag)\n",
    "    \n",
    "    cats_image = drone_fig.image(image='category', source=results_source, x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "                dw=drone_tgt.shape[2], dh=drone_tgt.shape[1], \n",
    "                color_mapper=cats_color_mapper,\n",
    "                global_alpha=0.8,\n",
    "                level=\"image\", tags=cats_tag)\n",
    "   \n",
    "    coords_label = PreText(text=\"null\", width=100, sizing_mode='fixed')\n",
    "    js_code = \"\"\"\n",
    "        var ind_x = Math.floor(cb_obj.x);\n",
    "        var ind_y = Math.floor(cb_obj.y);\n",
    "        var data_s = source.data;\n",
    "        console.log(\"x:\", ind_x);\n",
    "        console.log(\"y:\", ind_y);\n",
    "        target.text = \"x=\" + ind_x.toString() +\";\" + \"y=\" + ind_y.toString();\n",
    "    \"\"\"\n",
    "    js_callback = CustomJS(args={'source': drone_source, 'target': coords_label}, \n",
    "                           code=js_code)\n",
    "    drone_fig.js_on_event('tap', js_callback)\n",
    "    \n",
    "    \n",
    "    def get_ind_from_coords():\n",
    "        if (coords_label.text == \"null\"):\n",
    "            print(\"pick a pixel please\")\n",
    "            return (None, None)\n",
    "        coords = coords_label.text.split(';')\n",
    "        ind_x = coords[0].split('=')[1]\n",
    "        ind_y = coords[1].split('=')[1]\n",
    "        return (abs(int(ind_y)), abs(int(ind_x)))\n",
    "\n",
    "    cats = [\"NA\", \"Overstory\",\"Emergent\",\"Floating\",\"OpenWater\",\"GreenVeg\",\"DryVeg\",\"Bare\"]  \n",
    "    radio_group = RadioGroup(labels=cats, active=0, height=800, height_policy=\"fixed\", aspect_ratio=0.1)\n",
    "    forel_ule_scale = TextInput(value=\"0\", title=\"Forel-Ule Water Colour\", width=100, sizing_mode='fixed')  \n",
    "    def choose_cat(attrname, old, new):\n",
    "        print(\"what change\", attrname)\n",
    "        ind_y, ind_x = get_ind_from_coords()\n",
    "        if ind_y is None or ind_x is None:\n",
    "            return\n",
    "        if attrname == 'active':\n",
    "            print(\"set cat\")\n",
    "            xr_results[0][ind_y, ind_x] = radio_group.active\n",
    "            results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        if attrname == 'value':  \n",
    "            check_numbers = re.match(r'^[0-9]+$', forel_ule_scale.value)\n",
    "            if check_numbers is None:\n",
    "                print(\"only input numbers\", forel_ule_scale.value)\n",
    "                forel_ule_scale.value = \"0\"\n",
    "            elif int(forel_ule_scale.value) < 0 or int(forel_ule_scale.value) > 21:\n",
    "                print(\"invalid value, please check!\")\n",
    "                forel_ule_scale.value = \"0\"\n",
    "            elif radio_group.active != 4 and int(forel_ule_scale.value) > 0:\n",
    "                forel_ule_scale.value = \"0\"\n",
    "                print(\"cannot set value for non-water\")\n",
    "            xr_results[1][ind_y, ind_x] = int(forel_ule_scale.value)\n",
    "            results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "            \n",
    "    radio_group.on_change('active', choose_cat)\n",
    "    forel_ule_scale.on_change('value', choose_cat)\n",
    "    \n",
    "    def coords_change(attrname, old, new):\n",
    "        ind_y, ind_x = get_ind_from_coords()\n",
    "        if ind_y is None or ind_x is None:\n",
    "            return\n",
    "        print(\"pre water\", xr_results[1].data[ind_y, ind_x])\n",
    "        radio_group.active = xr_results[0].data[ind_y, ind_x]\n",
    "        forel_ule_scale.value = str(xr_results[1].data[ind_y, ind_x])\n",
    "        print(\"cat\", xr_results[0].data[ind_y, ind_x])\n",
    "        print(\"water\", xr_results[1].data[ind_y, ind_x])\n",
    "        \n",
    "    coords_label.on_change('text', coords_change)\n",
    "                  \n",
    "    overlay_toggle_category = Toggle(label=\"Overlay category\", button_type=\"success\",\n",
    "                                     height=50, width=150, sizing_mode='fixed', active=True)\n",
    "    overlay_toggle_water_color = Toggle(label=\"Overlay water color\", button_type=\"success\", \n",
    "                                        height=50, width=150, sizing_mode='fixed', active=True)\n",
    "    \n",
    "    def overlay_results(event):\n",
    "        if (overlay_toggle_water_color.active):\n",
    "            water_image.visible = True\n",
    "        else:\n",
    "            water_image.visible = False\n",
    "        if (overlay_toggle_category.active):\n",
    "            cats_image.visible = True\n",
    "        else:\n",
    "            cats_image.visible = False\n",
    "            \n",
    "    overlay_toggle_category.on_click(overlay_results)\n",
    "    overlay_toggle_water_color.on_click(overlay_results)\n",
    "    \n",
    "    control_group = column(coords_label, forel_ule_scale, radio_group)\n",
    "    result_group = row(result_file_input, column(result_load_button, result_save_button))\n",
    "    layouts = layout([drone_file_input, result_group, [overlay_toggle_category, overlay_toggle_water_color],\n",
    "                      [control_group, drone_fig]], sizing_mode='scale_height')\n",
    "    doc.add_root(layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(plot_doc, notebook_url=\"http://localhost:8889\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** August 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`,:index:`landsat 5`, :index:`landsat 7`, :index:`landsat 8`, :index:`sentinel 2`, :index:`dea_datahandling`, :index:`dea_plotting`, :index:`rgb`, :index:`load_ard`, :index:`vectorise`, :index:`shapefile`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
