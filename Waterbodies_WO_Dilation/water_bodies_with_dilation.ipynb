{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39e7f8-315d-4712-9bc0-27db1c5836c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datacube\n",
    "import rasterio\n",
    "import boto3\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import re\n",
    "from datacube.utils.dask import start_local_dask\n",
    "from datacube import Datacube\n",
    "from osgeo import ogr, gdal, osr\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.stats as sps\n",
    "import awswrangler as wr\n",
    "import rioxarray as rioxr\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "from datacube.utils.dask import start_local_dask\n",
    "from datacube import Datacube\n",
    "\n",
    "from dea_tools.spatial import xr_vectorize, xr_rasterize\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69b259-d27b-4f17-a796-f9c213141e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = start_local_dask(n_workers=1, threads_per_worker=60, memory_limit='400GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d677f2-320a-4588-8d3c-ae3a6ad34f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_seamask(shape_file, data_shape, data_crs, orig_coords, resolution):\n",
    "    \"\"\"\n",
    "        creak mask without oceans\n",
    "        input:\n",
    "            shape_file: the shape file of Australia coastline\n",
    "            data_shape: the shape of loaded data to be masked upon\n",
    "            orig_coords: the origin of the image for gdal to decide the transform\n",
    "            resolution: pixel size with signs, e.g., (30, -30) for C3 and (25, -25) for C2\n",
    "        output:\n",
    "            a numpy array of mask, where valid pixels = 1\n",
    "    \"\"\"\n",
    "    source_ds = ogr.Open(shape_file)\n",
    "    source_layer = source_ds.GetLayer()\n",
    "    source_layer.SetAttributeFilter(\"FEAT_CODE!='sea'\")\n",
    "\n",
    "    yt, xt = data_shape\n",
    "    xres = resolution[0]\n",
    "    yres = resolution[1]\n",
    "    no_data = 0\n",
    "\n",
    "    xcoord, ycoord = orig_coords\n",
    "    geotransform = (xcoord - (xres*0.5), xres, 0, ycoord - (yres*0.5), 0, yres)\n",
    "\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xt, yt, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform(geotransform)\n",
    "    albers = osr.SpatialReference()\n",
    "    albers.ImportFromEPSG(int(data_crs))\n",
    "    target_ds.SetProjection(albers.ExportToWkt())\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    band.SetNoDataValue(no_data)\n",
    "\n",
    "    gdal.RasterizeLayer(target_ds, [1], source_layer, burn_values=[1])\n",
    "    return band.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0fd69-4edb-4b89-9980-62ddc7181f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_polygons(wo_annual_dataset, au_shape, o_file):\n",
    "    \"\"\"\n",
    "    Generate polygons of waterbodies with annual wo summary\n",
    "    \"\"\"\n",
    "    c3_land_raster = generate_seamask(au_shape, wo_annual_dataset.count_clear.shape[1:], 3577,\n",
    "                                  (wo_annual_dataset.x.data.min(), wo_annual_dataset.y.data.max()), (30, -30))\n",
    "    count_clear = wo_annual_dataset.count_clear.where(wo_annual_dataset.count_clear > -999, 0).sum(dim='time').load()\n",
    "    count_wet = wo_annual_dataset.count_wet.where(wo_annual_dataset.count_wet > -999, 0).sum(dim='time').load()\n",
    "    frequency = count_wet/count_clear\n",
    "    polygons_low = xr_vectorize((frequency > fq_low) & (count_clear >= t_pixels) & c3_land_raster)1\n",
    "    polygons_high = xr_vectorize((frequency > fq_high) & (count_clear >= t_pixels) & c3_land_raster)\n",
    "    polygons_low = polygons_low[(polygons_low.attribute>0) & (polygons_low.geometry.area <= max_area)]\n",
    "    polygons_high = polygons_high[(polygons_high.geometry.area >= min_area) & (polygons_high.geometry.area <= max_area)\n",
    "                                       & (polygons_high.attribute>0)]\n",
    "    filtered_polygons = gpd.sjoin(left_df=polygons_low, \n",
    "                 right_df=polygons_high, \n",
    "                 how=\"inner\", predicate=\"intersects\").reset_index().drop_duplicates(subset=[\"index\"])\n",
    "    filtered_polygons = pd.concat([filtered_polygons, polygons_high]).dissolve().buffer(1e-4).explode(index_parts=True).reset_index().drop(columns=[\"level_0\", \"level_1\"])\n",
    "    filtered_polygons.to_file(o_file, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e224c30-7840-419e-a295-e73b43657ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_large_polygons(large_polygons, pp_thresh=0.005):\n",
    "    \"\"\"\n",
    "    explode large polygons according to compactness threshold\n",
    "    \"\"\"\n",
    "    tmp_polygons = large_polygons\n",
    "    exploded_polygons = []\n",
    "    b_size = 50\n",
    "    pp_values = tmp_polygons.geometry.area * 4 *np.pi / (tmp_polygons.geometry.length ** 2)\n",
    "    tmp_polygons = tmp_polygons[pp_values <= pp_thresh].buffer(-b_size)\n",
    "    while tmp_polygons.size > 0:\n",
    "        print(tmp_polygons)\n",
    "        i = 1\n",
    "        while (tmp_polygons.type == \"Polygon\").any():\n",
    "            i += 1\n",
    "            print(i*b_size)\n",
    "            tmp_polygons = tmp_polygons.buffer(-b_size)\n",
    "        tmp_polygons = tmp_polygons.explode(index_parts=True).buffer(i*b_size)\n",
    "        pp_values = tmp_polygons.geometry.area * 4 *np.pi / (tmp_polygons.geometry.length ** 2)\n",
    "        exploded_polygons += [tmp_polygons[pp_values > pp_thresh]]\n",
    "        tmp_polygons = tmp_polygons[pp_values <= pp_thresh].buffer(-i*b_size)\n",
    "    return gpd.GeoDataFrame(geometry=pd.concat(exploded_polygons)).reset_index().drop(columns=[\"level_0\", \"level_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fae2a-85f1-48f9-a3d3-df9c2a9b54be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wo_x_dirs = wr.s3.list_directories(wo_bucket)\n",
    "wo_file_dirs = []\n",
    "for x_idx in wo_x_dirs:\n",
    "    wo_file_dirs += wr.s3.list_directories(x_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca606cd-23d7-4a92-956c-b323d19f72b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "landsat_shape = \"./landsat_au/landsat_au.shp\"\n",
    "grid_shape = \"./au-grid.geojson\"\n",
    "au_shape = \"./aus_map/cstauscd_r_3577.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854635c-98b7-4957-8f09-60dc99d04af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wo_bands = ['count_clear', 'count_wet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de21f5d-cec9-4b28-8908-f926b367799d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_pixels = 128\n",
    "fq_low = 0.05\n",
    "fq_high = 0.1\n",
    "min_area = 3125\n",
    "max_area = 5000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0c7e8-97fa-4694-9c21-88f090bdeb1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate polygons from dilated wo annual summary\n",
    "for f_dir in wo_file_dirs:\n",
    "    print(f_dir)\n",
    "    if os.path.exists('_'.join(f_dir.split(\"/\")[-3:-1])+'_dilation_6.geojson'):\n",
    "        continue\n",
    "    wo_dataset = None\n",
    "    for i in range(1987, 2023):\n",
    "        dataset = None\n",
    "        for band in wo_bands:\n",
    "            non_empty_list = wr.s3.list_objects(f_dir + str(i) + \"--P1Y\", boto3_session=session, suffix=[band+'.tif'])\n",
    "            if non_empty_list == []:\n",
    "                continue\n",
    "            for o in non_empty_list:\n",
    "                data = rioxr.open_rasterio(o, chunks={'x':3200, 'y':3200})\n",
    "                data.name = band\n",
    "            tmp_set = data.to_dataset()\n",
    "            tmp_set = tmp_set.rename_dims({'band': 'time'})\n",
    "            tmp_set = tmp_set.rename_vars({'band': 'time'})\n",
    "            tmp_set.time.data[0] = i\n",
    "            if dataset is None:\n",
    "                dataset = tmp_set\n",
    "            else:\n",
    "                dataset = xr.merge([dataset, tmp_set])\n",
    "        if wo_dataset is None:\n",
    "            wo_dataset = dataset\n",
    "        else:\n",
    "            wo_dataset = xr.concat([wo_dataset, dataset], dim='time')\n",
    "    derive_polygons(wo_dataset, au_shape, '_'.join(f_dir.split(\"/\")[-3:-1])+'_dilation_6.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50de3ab-53fe-4f60-9918-20f2d6e2c3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate polygons from non-dilated wo summary\n",
    "dc = datacube.Datacube()\n",
    "for f_dir in wo_file_dirs:\n",
    "    if os.path.exists('_'.join(f_dir.split(\"/\")[-3:-1])+'.geojson'):\n",
    "        continue\n",
    "    region_code = ''.join(f_dir.split(\"/\")[-3:-1])\n",
    "    print(region_code)\n",
    "    datasets = dc.find_datasets(product='ga_ls_wo_fq_cyear_3', region_code=region_code)\n",
    "    wo_dataset = dc.load(\n",
    "        datasets=datasets,\n",
    "        measurements=wo_bands,\n",
    "        output_crs=\"EPSG:3577\",\n",
    "        resolution=(-30, 30),\n",
    "        dask_chunks={\"time\": 1}\n",
    "    )\n",
    "    derive_polygons(wo_dataset, au_shape, '_'.join(f_dir.split(\"/\")[-3:-1])+'.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b04da-f0ad-431c-90c5-613b3714cb91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_polygons_dilation = None\n",
    "w_polygons = None\n",
    "for f_dir in wo_file_dirs:\n",
    "    print(f_dir)\n",
    "    if os.path.exists('_'.join(f_dir.split(\"/\")[-3:-1])+\"_poly.png\"):\n",
    "        continue\n",
    "    w_polygons_dilation = gpd.GeoDataFrame.from_file('_'.join(f_dir.split(\"/\")[-3:-1])+'_dilation_6.geojson')\n",
    "    w_polygons = gpd.GeoDataFrame.from_file('_'.join(f_dir.split(\"/\")[-3:-1])+'.geojson')\n",
    "    print(f\"load finish {datetime.now()}\")\n",
    "    u_dilation = w_polygons_dilation.overlay(w_polygons, how='difference')\n",
    "    u_current = w_polygons.overlay(w_polygons_dilation, how='difference')\n",
    "    print(f\"diff finish {datetime.now()}\")\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    w_polygons_dilation.plot(ax=ax, color='hotpink', label='dilation 6');\n",
    "    w_polygons.plot(ax=ax, color='steelblue', alpha=0.5, label='no dilation');\n",
    "    lines = [\n",
    "        Line2D([0], [0], linestyle=\"none\", marker=\"s\", markersize=10, markerfacecolor=t.get_facecolor())\n",
    "        for t in ax.collections[-2:]\n",
    "    ]\n",
    "    labels = [t.get_label() for t in ax.collections[-2:]]\n",
    "    ax.legend(lines, labels)\n",
    "    plt.savefig('_'.join(f_dir.split(\"/\")[-3:-1])+\"_poly.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 16)) \n",
    "    u_dilation.plot(ax=ax, edgecolor='hotpink', cmap='Set1', figsize=(16, 16), label=\"dilation-current\")\n",
    "    u_current.plot(ax=ax, alpha=0.5, edgecolor='steelblue', cmap='Set1', label=\"current-dilation\")\n",
    "    lines = [\n",
    "        Line2D([0], [0], linestyle=\"none\", marker=\"s\", markersize=10, markerfacecolor=t.get_edgecolor())\n",
    "        for t in ax.collections\n",
    "    ]\n",
    "    labels = [t.get_label() for t in ax.collections]\n",
    "    ax.legend(lines, labels)\n",
    "    plt.savefig('_'.join(f_dir.split(\"/\")[-3:-1])+\"_diff.png\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    c_dens, c_bins, _ = plt.hist(u_dilation.geometry.area/(30*30), bins=30, label=\"dilation-current\", color=\"pink\")\n",
    "    plt.hist(u_current.geometry.area/(30*30), bins=c_bins, alpha=.5, label=\"current-dilation\", color=\"steelblue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig('_'.join(f_dir.split(\"/\")[-3:-1])+\"_area.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885289a7-fef2-4fd0-8d80-d3ce8e5a0ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and further process all the polygons saved in the geojson earlier\n",
    "o_dilation = []\n",
    "o_current = []\n",
    "\n",
    "for f_dir in wo_file_dirs:\n",
    "    w_polygons_dilation = gpd.GeoDataFrame.from_file('_'.join(f_dir.split(\"/\")[-3:-1])+'_dilation_6.geojson')\n",
    "    w_polygons = gpd.GeoDataFrame.from_file('_'.join(f_dir.split(\"/\")[-3:-1])+'.geojson')\n",
    "    o_dilation += [w_polygons_dilation]\n",
    "    o_current += [w_polygons]\n",
    "o_dilation = pd.concat(o_dilation)\n",
    "o_current = pd.concat(o_current)\n",
    "exploded_polygons_dilation = explode_large_polygons(o_dilation)\n",
    "exploded_polygons_current = explode_large_polygons(o_current)\n",
    "\n",
    "sorted_current = exploded_polygons_current.sort_values(by=\"geometry\",\n",
    "                                                    key=lambda col: col.values.area,\n",
    "                                                    ascending=False)\n",
    "sorted_dilation = exploded_polygons_dilation.sort_values(by=\"geometry\", \n",
    "                                                        key=lambda col: col.values.area, \n",
    "                                                        ascending=False)\n",
    "u_current = exploded_polygons_current.overlay(exploded_polygons_dilation,\n",
    "                                              how='difference').dissolve().explode(index_parts=True).reset_index().drop(columns=[\"level_0\", \"level_1\"])\n",
    "u_dilation = exploded_polygons_dilation.overlay(exploded_polygons_current,\n",
    "                                                how='difference').dissolve().explode(index_parts=True).reset_index().drop(columns=[\"level_0\", \"level_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd0f2f-1140-4ca7-9e0d-8a7898d9aa1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the distribution of polygon area\n",
    "fig, ax1 = plt.subplots(figsize=(16, 9))\n",
    "num_boxes = 2\n",
    "labels = [\"dilation\", \"current\"]\n",
    "ax1.boxplot([np.log(exploded_polygons_dilation.geometry.area/(30*30)), \n",
    "             np.log(exploded_polygons_current.geometry.area/(30*30))], 0, 'o', 0)\n",
    "ax1.set_ylim(0.5, num_boxes + 0.5)\n",
    "ax1.set_yticklabels(labels,rotation=0, fontsize=12)\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"all_tiles_area.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f0245-06b9-4fb3-ad4f-3195fc0cab2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the difference of polygon in area\n",
    "fig, ax1 = plt.subplots(figsize=(16, 9))\n",
    "num_boxes = 2\n",
    "labels = [\"dilation-current\", \"current-dilation\"]\n",
    "ax1.boxplot([np.log(u_dilation.geometry.area), \n",
    "             np.log(u_current.geometry.area)], 0, 'o', 0)\n",
    "ax1.set_ylim(0.5, num_boxes + 0.5)\n",
    "ax1.set_yticklabels(labels,rotation=0, fontsize=12)\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"all_tiles_area_diff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af5ee9-7891-406e-a317-147c3cbea3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot histgram of polygons area\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "c_dens, c_bins, _ = plt.hist(np.log(exploded_polygons_dilation.geometry.area), bins=50, \n",
    "                             density=True, label=\"dilation\", color=\"pink\")\n",
    "plt.hist(np.log(exploded_polygons_current.geometry.area), bins=c_bins, \n",
    "         density=True, alpha=.5, label=\"current\", color=\"steelblue\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"all_tiles_area_hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dac8df-2bcf-42b2-80f5-73da5e4f0773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the histgram of difference of polygons in area\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "c_dens, c_bins, _ = plt.hist(np.log(u_dilation.geometry.area), bins=50, \n",
    "                             density=True, label=\"dilation-current\", color=\"pink\")\n",
    "plt.hist(np.log(u_current.geometry.area), bins=c_bins, \n",
    "         density=True, alpha=.5, label=\"current-dilation\", color=\"steelblue\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"all_tiles_area_diff_hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00237022-b492-4eda-83d2-82eea696bc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the difference of top 20 polygons\n",
    "for i in range(20):\n",
    "    fig, ax = plt.subplots(figsize=(16, 16)) \n",
    "    if i == 11:\n",
    "        sorted_dilation.iloc[i:i+1].plot(ax=ax, color='hotpink', label='dilation 6');\n",
    "        sorted_current.iloc[i+1:i+2].plot(ax=ax, color=\"steelblue\", alpha=.5, label='current')\n",
    "    elif i == 12:\n",
    "        sorted_dilation.iloc[i:i+1].plot(ax=ax, color='hotpink', label='dilation 6');\n",
    "        sorted_current.iloc[i-1:i].plot(ax=ax, color=\"steelblue\", alpha=.5, label='current')\n",
    "    else:\n",
    "        sorted_dilation.iloc[i:i+1].plot(ax=ax, color='hotpink', label='dilation 6');\n",
    "        sorted_current.iloc[i:i+1].plot(ax=ax, color=\"steelblue\", alpha=.5, label='current')\n",
    "    lines = [\n",
    "        Line2D([0], [0], linestyle=\"none\", marker=\"s\", markersize=10, markerfacecolor=t.get_facecolor())\n",
    "        for t in ax.collections[-2:]\n",
    "    ]\n",
    "    labels = [t.get_label() for t in ax.collections[-2:]]\n",
    "    ax.legend(lines, labels)\n",
    "    plt.savefig(\"large_poly_\"+str(i)+\".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
