{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate FC with field data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find field data; this field data is the Star transects from [the JRSRP geoserver wfs service](https://field-geoserver.jrsrp.com/geoserver/aus/wfs?service=wfs&version=1.1.0&request=GetFeature&typeNames=aus:star_transects&outputFormat=csv) which can be visualised through [the TERN Landscapes-JRSRP Field Data Portal](https://field.jrsrp.com/) and is available as a csv\n",
    "2. Load corresponding surface reflectance from datacube or pickle;\n",
    "3. Calculate FC and compare to field data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sensor_name\n",
    "#sensor_name = 'Landsat 8 noscaling'\n",
    "#sensor_name = 'Landsat 8 current'\n",
    "sensor_name = 'Landsat 8'\n",
    "#sensor_name = 'Landsat 7'\n",
    "#sensor_name = 'Sentinel 2A'\n",
    "#sensor_name = 'Sentinel 2B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import datacube\n",
    "from fc.fractional_cover import compute_fractions\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from dea_datahandling import load_ard\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute the fractional covers as viewed by the satellite for the site\n",
    "## Required a site properties object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the fractional covers as viewed by the satellite for the site\n",
    "# Required a site properties object\n",
    "\n",
    "def fractionalCoverSatView(siteProperties):\n",
    "    '''equations to calculate fractional cover from the csv data'''\n",
    "    nTotal = siteProperties['num_points']\n",
    "    \n",
    "    # Canopy Layer\n",
    "    nCanopyBranch = siteProperties['over_b'] * nTotal / 100.0\n",
    "    nCanopyDead = siteProperties['over_d'] * nTotal / 100.0\n",
    "    nCanopyGreen = siteProperties['over_g'] * nTotal / 100.0\n",
    "    \n",
    "    # Midstory Layer\n",
    "    nMidBranch = siteProperties['mid_b'] * nTotal / 100.0\n",
    "    nMidGreen = siteProperties['mid_g'] * nTotal / 100.0\n",
    "    nMidDead = siteProperties['mid_d'] * nTotal / 100.0\n",
    "    \n",
    "    # Ground Layer\n",
    "    nGroundDeadLitter = (siteProperties['dead'] + siteProperties['litter']) * nTotal / 100.0\n",
    "    nGroundCrustDistRock = (siteProperties['crust'] + siteProperties['dist'] + siteProperties['rock']) * nTotal / 100.0\n",
    "    nGroundGreen = siteProperties['green'] * nTotal / 100.0\n",
    "    nGroundCrypto = siteProperties['crypto'] * nTotal / 100.0\n",
    "    \n",
    "    # Work out the canopy elements as viewed from above\n",
    "    canopyFoliageProjectiveCover = nCanopyGreen / (nTotal - nCanopyBranch)\n",
    "    canopyDeadProjectiveCover = nCanopyDead / (nTotal - nCanopyBranch)\n",
    "    canopyBranchProjectiveCover = nCanopyBranch / nTotal * (1.0 - canopyFoliageProjectiveCover - canopyDeadProjectiveCover)\n",
    "    canopyPlantProjectiveCover = (nCanopyGreen+nCanopyDead + nCanopyBranch) / nTotal\n",
    "    \n",
    "    # Work out the midstorey fractions\n",
    "    midFoliageProjectiveCover = nMidGreen / nTotal\n",
    "    midDeadProjectiveCover = nMidDead / nTotal\n",
    "    midBranchProjectiveCover = nMidBranch / nTotal\n",
    "    midPlantProjectiveCover = (nMidGreen + nMidDead + nMidBranch) / nTotal\n",
    "    \n",
    "    # Work out the midstorey  elements as viewed by the satellite using a gap fraction method\n",
    "    satMidFoliageProjectiveCover = midFoliageProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidDeadProjectiveCover = midDeadProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidBranchProjectiveCover = midBranchProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidPlantProjectiveCover = midPlantProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    \n",
    "    # Work out the groundcover fractions as seen by the observer\n",
    "    groundPVCover = nGroundGreen / nTotal\n",
    "    groundNPVCover = nGroundDeadLitter / nTotal\n",
    "    groundBareCover = nGroundCrustDistRock / nTotal\n",
    "    groundCryptoCover = nGroundCrypto / nTotal\n",
    "    groundTotalCover = (nGroundGreen + nGroundDeadLitter + nGroundCrustDistRock) / nTotal\n",
    "    \n",
    "    # Work out the ground cover proportions as seen by the satellite\n",
    "    satGroundPVCover = groundPVCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundNPVCover = groundNPVCover * ( 1- midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundBareCover = groundBareCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundCryptoCover = groundCryptoCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundTotalCover = groundTotalCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    \n",
    "    # Final total covers calculated using gap probabilities through all layers\n",
    "    totalPVCover = canopyFoliageProjectiveCover + satMidFoliageProjectiveCover + satGroundPVCover\n",
    "    totalNPVCover = canopyDeadProjectiveCover + canopyBranchProjectiveCover + satMidDeadProjectiveCover + satMidBranchProjectiveCover + satGroundNPVCover\n",
    "    totalBareCover = satGroundBareCover\n",
    "    totalCryptoCover = satGroundCryptoCover\n",
    "    \n",
    "    return np.array([totalPVCover,totalNPVCover+totalCryptoCover,totalBareCover])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients for FC computation\n",
    "These are the `Landsat 8 Fudge Factor` used to make the spectrally different sensor on Landsat 8 perform similarly to Landsats 5 and 7 in the Fractional Cover algorithm. These are incorporated in to the Collection 3 config as `regression_coefficients` in [C3 product definition yaml](https://github.com/opendatacube/datacube-alchemist/blob/C3_Processing/examples/c3_config_fc.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients for FC compute\n",
    "\n",
    "#these were used in collection 2 but are not correct as don't multiply by 10000/ 1e4\n",
    "ls8_coefficients_current = {'blue': [0.00041, 0.9747], 'green': [0.00289, 0.99779], 'red': [0.00274, 1.00446], \n",
    "                       'nir': [4e-05, 0.98906], 'swir1': [0.00256, 0.99467], 'swir2': [-0.00327, 1.02551]}\n",
    "\n",
    "#use these ones, they are correct (need to multiply by 10000 as the algorithm expects 0-10000 not 0-1)\n",
    "ls8_coefficients = {'blue': [0.00041*1e4, 0.9747], 'green': [0.00289*1e4, 0.99779], 'red': [0.00274*1e4, 1.00446], \n",
    "                       'nir': [4e-05*1e4, 0.98906], 'swir1': [0.00256*1e4, 0.99467], 'swir2': [-0.00327*1e4, 1.02551]}\n",
    "\n",
    "s2_coefficients = {'blue':[-0.0022*1e4, 0.9551],\n",
    "                   'green':[0.0031*1e4, 1.0582],\n",
    "                   'red':[0.0064*1e4, 0.9871],\n",
    "                   'nir':[0.012*1e4, 1.0187],\n",
    "                   'swir1':[0.0079*1e4, 0.9528],\n",
    "                   'swir2':[-0.0042*1e4, 0.9688]}\n",
    "\n",
    "# compute FC \n",
    "def compute_fc(input_ds, regression_coefficients):\n",
    "    '''takes input dataset and multiplies by regression coefficients to compute fractional cover.\n",
    "    returns an xarray DataArray with pv,npv,bs,ue bands'''\n",
    "    \n",
    "    input_data = input_ds.to_array().data\n",
    "    is_valid_array= (input_data >0).all(axis=0)\n",
    "    # Set nodata to 0                                                       \n",
    "    input_data[:, ~is_valid_array] = 0\n",
    "    # compute fractional_cover\n",
    "    output_data = compute_fractions(input_data, regression_coefficients)\n",
    "    output_data[:, ~is_valid_array] = -1\n",
    "    return xr.DataArray(output_data, dims=('band','y','x'),\n",
    "                        coords={'x':input_ds.x, 'y':input_ds.y, 'band':['pv', 'npv', 'bs', 'ue']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select good pixels using pixel quality\n",
    "def ls_good(pq):\n",
    "    return masking.make_mask(pq, cloud_acca = \"no_cloud\", cloud_fmask = \"no_cloud\",\n",
    "                             cloud_shadow_acca = \"no_cloud_shadow\",\n",
    "                             cloud_shadow_fmask = \"no_cloud_shadow\",\n",
    "                             contiguous = True)\n",
    "def s2_good(pq):\n",
    "    return pq == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the query for each sensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral bands used for fractional cover calculation\n",
    "\n",
    "#this is correct for collection3  \n",
    "ls_bands = ['nbart_green','nbart_red','nbart_nir','nbart_swir_1','nbart_swir_2']\n",
    "\n",
    "#this is correct for collection 3\n",
    "s2_bands = ['nbart_green','nbart_red','nbart_nir_1','nbart_swir_2','nbart_swir_3']\n",
    "\n",
    "# sensor specific configurations - note no Landsat 5 as doesn't overlap with site surveys\n",
    "\n",
    "sensor_config = {'Landsat 7':{'startdate':'1999-05-01', #updated for collection3\n",
    "                              'product':'ga_ls7e_ard_3', \n",
    "                              'bands':ls_bands,\n",
    "                              'resolution':(-30,30), \n",
    "                              'fc_coefficients': None}, \n",
    "                 \n",
    "                 'Landsat 8 noscaling':{'startdate':'2013-03-01',\n",
    "                                        'product':'ga_ls8c_ard_3', \n",
    "                                        'bands':ls_bands,\n",
    "                                        'resolution':(-30,30), \n",
    "                                        'fc_coefficients': None}, \n",
    "                 \n",
    "                 'Landsat 8':{'startdate':'2013-03-01', \n",
    "                              'product':'ga_ls8c_ard_3', \n",
    "                              'bands':ls_bands,\n",
    "                              'resolution':(-30,30), \n",
    "                              'fc_coefficients':ls8_coefficients}, \n",
    "                 \n",
    "                 'Landsat 8 current':{'startdate':'2013-03-01', \n",
    "                                      'product':'ga_ls8c_ard_3', \n",
    "                                      'bands':ls_bands,\n",
    "                                      'resolution':(-30,30), \n",
    "                                      'fc_coefficients':ls8_coefficients_current}, \n",
    "                 \n",
    "                 'Sentinel 2A':{'startdate':'2015-07-01', \n",
    "                                'product':'s2a_ard_granule', \n",
    "                                'bands':s2_bands,\n",
    "                                'resolution':(-10,10), \n",
    "                                'fc_coefficients':s2_coefficients},\n",
    "                 \n",
    "                'Sentinel 2B':{'startdate':'2017-06-01', \n",
    "                               'product':'s2b_ard_granule', \n",
    "                               'bands':s2_bands,\n",
    "                               'resolution':(-10,10), \n",
    "                               'fc_coefficients':s2_coefficients}\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load field data in from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load star_transects field data \n",
    "field = pd.read_csv('star_transects.csv')\n",
    "field['geometry'] = field.geom.apply(wkt.loads)\n",
    "field = gpd.GeoDataFrame(field)\n",
    "\n",
    "#field data comes in in WGS84\n",
    "field.crs = {'init': 'EPSG:4326'}\n",
    "\n",
    "#transform to Australian Albers Equal Area \n",
    "field = field.to_crs({'init':'EPSG:3577'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by date - get dates later than the first observation of the satellite\n",
    "field = field.loc[field['obs_time'] > sensor_config[sensor_name]['startdate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate field measured fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate field measured fractions\n",
    "field = field.merge(\n",
    "    field.apply(fractionalCoverSatView, axis=1, result_type= 'expand').rename(\n",
    "        columns = {0:'total_pv',1:'total_npv',2:'total_bs'}),\n",
    "    left_index=True, right_index=True)\n",
    "field = field[field.apply(lambda x: x['total_pv']+x['total_npv']+x['total_bs'], axis=1) >0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match to albers tiles to check distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "Albers_Australia_Coast_and_Islands.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: Albers_Australia_Coast_and_Islands.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a05904e2cb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Match to albers tiles to check distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malbers_tiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Albers_Australia_Coast_and_Islands.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0malbers_tiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'EPSG:3577'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbers_tiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'intersects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m field_tiles = albers_tiles.merge(matched.groupby('label')['FID'].count().sort_values(ascending=False).to_frame('count').reset_index()\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0;32m--> 257\u001b[0;31m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: Albers_Australia_Coast_and_Islands.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Match to albers tiles to check distribution\n",
    "albers_tiles = gpd.read_file('Albers_Australia_Coast_and_Islands.shp')\n",
    "albers_tiles.crs = {'init':'EPSG:3577'}\n",
    "matched = gpd.sjoin(field, albers_tiles, how='inner', op = 'intersects')\n",
    "field_tiles = albers_tiles.merge(matched.groupby('label')['FID'].count().sort_values(ascending=False).to_frame('count').reset_index()\n",
    "    , on='label', how='right')\n",
    "print(\"Total number of data points is\",len(field))\n",
    "print(\"Largest number of data points in a tile is\", field_tiles.loc[field_tiles['count'].idxmax()]['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual check of field data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check of field data distribution\n",
    "f, axes = plt.subplots(1, 2, figsize=(14,7))\n",
    "plt.suptitle('Density of field data (star transects per albers tile)', size =14)\n",
    "ax0 = field.plot(markersize=1, ax=axes[0])\n",
    "albers_tiles.plot(alpha=0.2, ax = ax0)\n",
    "\n",
    "ax1 =field_tiles.plot(column='count', cmap = 'viridis', ax=axes[1])\n",
    "albers_tiles.plot(alpha=0.2, ax = ax1)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from cube\n",
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find temporally and spatially aligned EO data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test data\n",
    "# row = field.iloc[-1]\n",
    "# sensor_name = 'Landsat 8'\n",
    "# plot_rad = 50\n",
    "# window_days = 60 #window_days = 15\n",
    "# #sensor_config = sensor_config[sensor_name]\n",
    "# sensor_config =sensor_config['Landsat 8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nTotal = siteProperties['num_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate fractional cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractional cover\n",
    "def fractionalCover(row, sensor_config = sensor_config[sensor_name], plot_rad = 50, window_days = 15):\n",
    "    '''this finds data within 15 days of an observation and 50 ??? of an observation\n",
    "    #FIXME check nodata defaults here to -1, I think we need to replace with 255 '''\n",
    "\n",
    "    # nodata default to return in case no data matches the chosen window around the field observation\n",
    "    fc_dict = {'fc_time': '', 'pv': -1, 'npv': -1, 'bs': -1, 'pv_std': -1, 'npv_std': -1, 'bs_std': -1 }\n",
    "\n",
    "    # define search - grab near observations in space and time\n",
    "    x = row.geometry.x - plot_rad, row.geometry.x + plot_rad\n",
    "    y = row.geometry.y - plot_rad, row.geometry.y + plot_rad\n",
    "    time = (str(np.datetime64(row.obs_time) - np.timedelta64(window_days,'D')),\n",
    "            str(np.datetime64(row.obs_time) + np.timedelta64(window_days,'D'))\n",
    "           )\n",
    "\n",
    "    #use a reusable query dictionary\n",
    "    query = {'measurements':sensor_config['bands'],\n",
    "             'group_by':'solar_day',\n",
    "             'x' : x, \n",
    "             'y' : y,  \n",
    "             'time' : time, \n",
    "             'crs' : 'EPSG:3577', #this defines the crs of the input query\n",
    "             'resolution' : sensor_config['resolution'],\n",
    "             'output_crs' : 'EPSG:3577'}          \n",
    "\n",
    "    try: \n",
    "        #need to test if load_ard will return data here, as the alternative is that the data is not returned\n",
    "        nbart = load_ard(dc,\n",
    "            products = [sensor_config['product']], #need square brackets to deliver as a list\n",
    "            min_gooddata=1, #need all valid pixels for the comparison\n",
    "            fmask_categories=['valid'], #don't want snow or water in fractional cover comparison\n",
    "            mask_pixel_quality=True, #this could give us some issues with dtype later on\n",
    "            mask_contiguity='nbart_contiguity',\n",
    "            ls7_slc_off=True,\n",
    "            **query); #suppress output for this function to save printing space\n",
    "        \n",
    "    except ValueError:\n",
    "        print(f\"No data found at {x},{y},{time}\")\n",
    "        return fc_dict\n",
    "    \n",
    "    # If there aren't any results, this function will return nodata values.\n",
    "    if len(nbart.time) == 0: return fc_dict\n",
    "\n",
    "    ### choose the closest clear timestep to keep\n",
    "\n",
    "    # only keep closest time\n",
    "    nbart = nbart.isel(time=[np.abs(nbart.time-np.datetime64(row.obs_time)).argmin()])\n",
    "\n",
    "    # compute FC\n",
    "    fc = nbart.groupby('time').apply(compute_fc,\n",
    "                                     regression_coefficients = sensor_config['fc_coefficients'],\n",
    "                                    ).to_dataset(dim='band')\n",
    "\n",
    "    ## Not sure why groupby was needed here?\n",
    "    #fc_mean = fc.where(fc>=0).groupby('time').mean()\n",
    "    # fc_std = fc.where(fc>=0).groupby('time').std()\n",
    "        # take average\n",
    "    fc_mean = fc.where(fc>=0).groupby('time').mean(dim=['x','y'])\n",
    "    fc_std = fc.where(fc>=0).groupby('time').std(dim=['x','y'])\n",
    "\n",
    "    fc_dict['fc_time'] = fc.time.values[0].astype(str)\n",
    "    for var_name in fc_mean.data_vars:\n",
    "        fc_dict[var_name.lower()] = fc_mean[var_name].values[0]\n",
    "        fc_dict[var_name.lower()+'_std'] = fc_std[var_name].values[0]\n",
    "        \n",
    "    return fc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Fractional Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# If there aren't any results, this function will return nodata values.\n",
    "fractions = field.apply(fractionalCover, axis=1, result_type = 'expand')\n",
    "field = field.merge(fractions, how = 'inner', left_index=True, right_index=True)\n",
    "field = field[field['pv']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.to_file('field_with_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = gpd.read_file('field_with_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "def validate(field_all, title=None):\n",
    "    field = field_all[(field_all[['pv','npv','bs']]>=0.).all(axis=1)]\n",
    "    field = field[(field[['pv_std','npv_std','bs_std']]<=10.).all(axis=1)]\n",
    "    field = field[field['ue'] <25]\n",
    "    print(\"# of validation points:\", len(field))\n",
    "    \n",
    "    regr = linear_model.LinearRegression(fit_intercept=False)    \n",
    "\n",
    "    f = plt.figure(figsize=(12,12))\n",
    "    gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "    xedges=yedges=list(np.arange(0,102,2))\n",
    "    X, Y = np.meshgrid(xedges, yedges)\n",
    "    cmname='YlGnBu'\n",
    "    if title: plt.suptitle(title)\n",
    "    \n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    field.plot(markersize=1, ax= ax1, color='r')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_title('Field Sites')\n",
    "    ax1.text(0.05, 0.05, \"%d points\"%len(field), transform=ax1.transAxes)\n",
    "    \n",
    "    rmses = []\n",
    "    for band_id, band in enumerate(['BS','PV','NPV']):\n",
    "        arr1 = field['total_%s'%band.lower()].values.ravel()*100.\n",
    "        arr2 = field[band.lower()].values.ravel()\n",
    "        regr.fit(arr1[:,np.newaxis], arr2[:,np.newaxis])\n",
    "        \n",
    "        print('Band:{0}, slope={1}, r2={2}'.format(band, regr.coef_[0][0],\n",
    "                                                regr.score(arr1[:,np.newaxis], arr2[:,np.newaxis])))\n",
    "        sr = spearmanr(arr1, arr2)[0]\n",
    "        print('Correlations:', pearsonr(arr1, arr2)[0], sr, kendalltau(arr1, arr2)[0])\n",
    "        rmse = np.sqrt(mean_squared_error(arr1, arr2))\n",
    "        print('RMSE:',rmse)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "        ax1 = plt.subplot(gs[band_id+1])\n",
    "        ax1.scatter(arr1, arr2, s=3)\n",
    "        ax1.set_title(band)\n",
    "        \n",
    "        ax1.plot([0,100],[0,100])\n",
    "        ax1.plot(np.arange(0,100,10), regr.predict(np.arange(0,100,10)[:,np.newaxis]), ':')\n",
    "        ax1.text(5, 95, 'spearmanr = {0:.2f}'.format(sr))\n",
    "        ax1.text(5, 90, 'rmse = {0:.2f}'.format(rmse))\n",
    "        ax1.set_xlabel('Field Measured')\n",
    "        ax1.set_ylabel('%s FC'%sensor_name.upper())\n",
    "        ax1.set_xlim((0,100))\n",
    "        ax1.set_ylim((0,100))\n",
    "    \n",
    "    f.savefig('validate_fc_%s.png'%''.join(sensor_name.split()))\n",
    "\n",
    "\n",
    "validate(field, title=sensor_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
