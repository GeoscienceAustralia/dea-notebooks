{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating cloud dilation options for Landsat Fmask <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* [**Sign up to the DEA Sandbox**](https://docs.dea.ga.gov.au/setup/sandbox.html) to run this notebook interactively from a browser\n",
    "* **Compatibility:** Notebook currently compatible with the `DEA Sandbox` environment\n",
    "* **Products used:** \n",
    "[ga_ls5t_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3),\n",
    "[ga_ls9c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls9c_ard_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages used for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-a63808d4-2c24-11ee-80e2-56bd89368d21</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/james.miller@ga.gov.au/proxy/8787/status\" target=\"_blank\">/user/james.miller@ga.gov.au/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/james.miller@ga.gov.au/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">776f3e52</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/user/james.miller@ga.gov.au/proxy/8787/status\" target=\"_blank\">/user/james.miller@ga.gov.au/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 1\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 62\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 477.21 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-d78a83fb-d747-4a4f-9f7c-0c22f781297b</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:39765\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/james.miller@ga.gov.au/proxy/8787/status\" target=\"_blank\">/user/james.miller@ga.gov.au/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 62\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 477.21 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:37381\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 62\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/user/james.miller@ga.gov.au/proxy/45999/status\" target=\"_blank\">/user/james.miller@ga.gov.au/proxy/45999/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 477.21 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:44873\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-zkkzsvfc\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39765' processes=1 threads=62, memory=477.21 GiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datacube\n",
    "from datacube.utils.masking import make_mask\n",
    "from odc.algo import mask_cleanup, erase_bad, enum_to_bool, to_f32\n",
    "from datacube.utils.geometry import CRS, Geometry, GeoBox\n",
    "from odc.algo import to_f32, xr_geomedian, int_geomedian\n",
    "from dea_tools.plotting import rgb\n",
    "from dea_tools.datahandling import load_ard\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import fiona\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, \"../Tools/\")\n",
    "from dea_tools.dask import create_local_dask_cluster\n",
    "\n",
    "# Launch Dask cluster\n",
    "client = create_local_dask_cluster(return_client=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Cloud_dilation-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_buffering = 0\n",
    "end_buffering = 20\n",
    "bands = [\n",
    "    \"nbart_blue\",\n",
    "    \"nbart_red\",\n",
    "    \"nbart_green\",\n",
    "    \"nbart_nir\",\n",
    "    \"nbart_swir_1\",\n",
    "    \"nbart_swir_2\",\n",
    "    \"oa_fmask\",\n",
    "]\n",
    "products = [\n",
    "    \"ga_ls5t_ard_3\",\n",
    "    \"ga_ls7e_ard_3\",\n",
    "    \"ga_ls8c_ard_3\",\n",
    "#    \"ga_ls9c_ard_3\",\n",
    "]\n",
    "maturity = \"final\"\n",
    "time_period = None  # (\"1990\", \"1995\")   # ('2015-01-01', '2015-05-01')  # # Set to none for entire sensor record, otherwise:  # ('2015-01-01', '2015-05-01')\n",
    "#time_period = ('2015-01-01', '2016-01-01')\n",
    "\n",
    "# full validation path-rows - most have been commented out for faster testing\n",
    "path_row_list = [\n",
    "#    \"113082\",\n",
    "#    \"111077\",\n",
    "#    \"108083\",\n",
    "#    \"108079\",\n",
    "#    \"105069\",\n",
    "#    \"103073\",\n",
    "    \"099079\",\n",
    "#    \"098077\",\n",
    "#    \"098071\",\n",
    "    \"097081\",\n",
    "#    \"095082\",\n",
    "#    \"094085\",\n",
    "    \"093086\",\n",
    "    \"096072\",\n",
    "#    \"091089\",\n",
    "    \"090086\",\n",
    "#    \"090084\",\n",
    "#    \"090085\",\n",
    "    \"091079\",\n",
    "#    \"090084\",\n",
    "    \"089084\",\n",
    "#    \"090079\",\n",
    "#    \"089079\",\n",
    "]\n",
    "\n",
    "geomedian_threads = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def landsat_scene_poly(path_row, radius=None):\n",
    "    \"\"\"\n",
    "    Get geometry for a given landsat path row\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_row : string\n",
    "        Path row to search for\n",
    "    radius : int, optional\n",
    "        If provided, the centroid of the path row geom will be buffered\n",
    "        by `radius` metres to provide a smaller geometry located within\n",
    "        the path row, reducing memory and processing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geometry : geometry\n",
    "        geopolygon for given path row\n",
    "    \"\"\"\n",
    "\n",
    "    # Path to Landsat file on S3\n",
    "    landsat_shape = \"https://data.dea.ga.gov.au/derivative/ga_ls_path_row_grid.geojson\"\n",
    "\n",
    "    # Select feature\n",
    "    with fiona.open(landsat_shape) as all_shapes:\n",
    "        for s in all_shapes:\n",
    "            # landsat pathrows dont include 0 in front hence convert path-row to int to drop 0\n",
    "            if s[\"properties\"].get(\"PR\") == int(path_row):\n",
    "                # Extract geom\n",
    "                geom = Geometry(s[\"geometry\"], crs=CRS(\"EPSG:4326\"))\n",
    "\n",
    "                # Buffer centroid by X and return geom\n",
    "                if radius is not None:\n",
    "                    geom = geom.to_crs(\"EPSG:3577\").centroid.buffer(radius)\n",
    "\n",
    "                return geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select spatiotemporal query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for full path-row geopolygon\n",
    "def define_query_params(path_row, time_period, maturity, radius=None):\n",
    "    \"\"\"\n",
    "    Create query params for odc load\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_row : string\n",
    "        Path row to search for\n",
    "    time_period : list\n",
    "        Time range\n",
    "    maturity : string\n",
    "        The dataset maturity level to include in the analysis\n",
    "    radius : int, optional\n",
    "        If provided, the centroid of the path row geom will be buffered\n",
    "        by `radius` metres to provide a smaller geometry located within\n",
    "        the path row, reducing memory and processing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    query_params : dictionary\n",
    "        qury params to use for odc load\n",
    "    \"\"\"\n",
    "    query_poly = landsat_scene_poly(path_row, radius)\n",
    "    query_params = dict(\n",
    "        geopolygon=query_poly,\n",
    "        time=time_period,\n",
    "        region_code=path_row,\n",
    "        dataset_maturity=maturity,\n",
    "    )\n",
    "    return query_params\n",
    "\n",
    "\n",
    "# for small scale fast tests\n",
    "def define_query_params_lat_lon_test(time_period):\n",
    "    query_params = dict(x=(140, 140.1), y=(-30, -30.1), time=time_period)\n",
    "    return query_params\n",
    "\n",
    "def define_load_params(bands, load_product, query_params):\n",
    "    \"\"\"\n",
    "    Define load params\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bands : list\n",
    "        measurement bands\n",
    "    load_product : string\n",
    "        odc product\n",
    "    query_params: dictionary\n",
    "        odc query parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    load_params : dict\n",
    "        dictionary of load params\n",
    "    \"\"\"\n",
    "    # Find matching datasets\n",
    "    dss = dc.find_datasets(product=load_product, **query_params)\n",
    "\n",
    "    # Identify native CRS from datasets; fall back on \"EPSG:3577\"\n",
    "    # if no data is found to prevent an error\n",
    "    native_crs = dss[0].crs if len(dss) > 0 else \"EPSG:3577\"\n",
    "\n",
    "    # Set load params (measurements to load, Dask chunking, resampling etc)\n",
    "    load_params = dict(\n",
    "        measurements=bands,\n",
    "        output_crs=native_crs,  # Native CRS\n",
    "        resolution=(-30, 30),  # Native resolution\n",
    "        align=(15, 15),  # Required for native resolution load\n",
    "        group_by=\"solar_day\",\n",
    "        dask_chunks={},\n",
    "        skip_broken_datasets=True, # having around one-three failed timesteps due to s3 read errors for ls5\n",
    "    )\n",
    "        \n",
    "    return load_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(load_params, load_product, query_params):\n",
    "    \"\"\"\n",
    "    Load odc data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    load_params : dictionary\n",
    "        load parameters dictionary\n",
    "    load_product : string\n",
    "        odc product\n",
    "    query_params: dictionary\n",
    "        odc query parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ds : dataset\n",
    "        geospatial satellite data dataset\n",
    "    \"\"\"\n",
    "    # Lazily load data\n",
    "    ds = dc.load(product=load_product,\n",
    "                 **query_params,\n",
    "                 **load_params)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def load_data_geomedian(load_params, load_product, query_params):\n",
    "    \"\"\"\n",
    "    Load odc data for geomedian applying cloud filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    load_params : dictionary\n",
    "        load parameters dictionary\n",
    "    load_product : string\n",
    "        odc products\n",
    "    query_params: dictionary\n",
    "        odc query parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ds : dataset\n",
    "        geospatial satellite data dataset\n",
    "    \"\"\" \n",
    "    print(load_product)\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=[load_product],\n",
    "                  min_gooddata=0.90,\n",
    "                  **query_params,\n",
    "                  **load_params\n",
    "    )\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fmask cloud and shadow mask\n",
    "Based on content from: https://docs.dea.ga.gov.au/notebooks/How_to_guides/Masking_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_cloud_shadow_mask(ds):\n",
    "    \"\"\"\n",
    "    Calculate cloud shadow mask\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : dataset\n",
    "        data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cloud_shadow_mask : xr.DataArray\n",
    "        cloud shadow mask\n",
    "    nodata_mask: xr.DataArray\n",
    "        nodata mask\n",
    "    \"\"\"\n",
    "    # Identify pixels that are either \"nodata\", \"cloud\" or \"cloud_shadow\"\n",
    "    nodata_mask = enum_to_bool(ds.oa_fmask, categories=[\"nodata\"])\n",
    "    cloud_shadow_mask = enum_to_bool(ds.oa_fmask, categories=[\"cloud\", \"shadow\"])\n",
    "\n",
    "    return cloud_shadow_mask, nodata_mask\n",
    "\n",
    "\n",
    "# Plot\n",
    "# cloud_shadow_mask.isel(time=slice(4, 12)).plot(col=\"time\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying dilation using `mask_cleanup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_geomedian(ds, geomedian_threads):\n",
    "    \"\"\"\n",
    "    Apply geomedian\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : dataset\n",
    "        odc data\n",
    "    geomedian_threads: integer\n",
    "        number of threads for processing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geomedian : dataset\n",
    "     computed geomedian for input dataset\n",
    "    \"\"\"\n",
    "    geomedian = int_geomedian(ds, \n",
    "                              num_threads=geomedian_threads)\n",
    "    geomedian = geomedian.compute()\n",
    "    rgb(geomedian, size=10)\n",
    "    return geomedian\n",
    "\n",
    "def get_std(buffer_size, ds, cloud_shadow_mask, nodata_mask, ds_baseline):\n",
    "    \"\"\"\n",
    "    Calculate standard deviation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    buffer_size : integer\n",
    "        pixel buffer size\n",
    "    ds : dataset\n",
    "        odc data\n",
    "    cloud_shadow_mask : xr.DataArray\n",
    "        cloud shadow mask\n",
    "    nodata_mask: xr.DataArray\n",
    "        nodata mask\n",
    "    ds_baseline: dataset\n",
    "        geomedian baseline dataset for comparison\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    std_df : pandas.DataFrame\n",
    "        A pandas DataFrame containing mean standard deviation for\n",
    "        each satellite band\n",
    "    negative_diffs_mean_df: pandas.DataFrame\n",
    "        A pandas DataFrame containing mean difference for cloud shadow \n",
    "        between buffered dataset and geomedian baseline\n",
    "    positive_diffs_mean_df: pandas.DataFrame\n",
    "        A pandas DataFrame containing mean difference for cloud masking \n",
    "        between buffered dataset and geomedian baseline    \n",
    "    \"\"\"\n",
    "    # Dilate all cloud and cloud shadow pixels by n pixels (uses a circular disk)\n",
    "    cloud_shadow_buffered = mask_cleanup(\n",
    "        mask=cloud_shadow_mask, mask_filters=[(\"dilation\", buffer_size)]\n",
    "    )\n",
    "\n",
    "    # Apply the mask and drop cloud masking band\n",
    "    combined_mask = cloud_shadow_buffered | nodata_mask\n",
    "    clear_buffered = erase_bad(ds.drop(\"oa_fmask\"), combined_mask)\n",
    "\n",
    "    # Convert to float, setting all nodata pixels to `np.nan` (required\n",
    "    # for the standard deviation calculation)\n",
    "    clear_buffered = to_f32(clear_buffered)\n",
    "\n",
    "    # Calculate the mean of standard deviation through time at each pixel.\n",
    "    # Xarray will apply this to each band in the dataset individually\n",
    "    std_ds = clear_buffered.std(dim=\"time\").mean().compute()\n",
    "\n",
    "    # Convert xarray.DataSet to pandas.DataFrame\n",
    "    std_df = std_ds.drop(\"spatial_ref\").to_array().to_dataframe(name=\"std\")\n",
    "    \n",
    "    # Subtract the cloud free baseline from our loaded data\n",
    "    # returning a dataset of differences for each pixel \n",
    "    # (bright clouds will have higher values than the baseline, dark shadows will lower values)\n",
    "    ds_diffs = clear_buffered - ds_baseline\n",
    "    \n",
    "    # If we want to look at cloud shadow, we could mask to negative differences only:\n",
    "    ds_negative_diffs = ds_diffs.where(ds_diffs < 0)\n",
    "    # (or clouds only):  \n",
    "    ds_positive_diffs = ds_diffs.where(ds_diffs > 0)\n",
    "    \n",
    "    # Summarise those differences across time similar to our current code:\n",
    "    negative_diffs_mean_ds = ds_negative_diffs.mean(dim=\"time\").mean()\n",
    "    positive_diffs_mean_ds = ds_positive_diffs.mean(dim=\"time\").mean()\n",
    "    negative_diffs_mean_df = negative_diffs_mean_ds.drop(\"spatial_ref\").to_array().to_dataframe(name=\"mean\")\n",
    "    positive_diffs_mean_df = positive_diffs_mean_ds.drop(\"spatial_ref\").to_array().to_dataframe(name=\"mean\")\n",
    "    \n",
    "    return std_df, negative_diffs_mean_df, positive_diffs_mean_df\n",
    "\n",
    "\n",
    "def std_buffer_comp(start_buffering, end_buffering, ds, cloud_shadow_mask, nodata_mask, ds_baseline):\n",
    "    \"\"\"\n",
    "    Calculate buffer comparison standard deviation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_buffering, end_buffering : integer\n",
    "        pixel buffer size\n",
    "    ds : dataset\n",
    "        odc data\n",
    "    cloud_shadow_mask : xr.DataArray\n",
    "        cloud shadow mask\n",
    "    nodata_mask: xr.DataArray\n",
    "        nodata mask\n",
    "    ds_baseline: dataset\n",
    "        geomedian baseline dataset for comparison\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    std_buffer_df : pandas.DataFrame\n",
    "        A pandas DataFrame containing mean standard deviation per buffer\n",
    "        pixel per band\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}\n",
    "    negative_dict = {}\n",
    "    positive_dict = {}\n",
    "    \n",
    "\n",
    "    # Loop through each buffer radius\n",
    "    for buffer in range(start_buffering, end_buffering + 1):\n",
    "        # Calculate mean standard deviation through time for buffer\n",
    "        std_df, negative_diffs_mean_df, positive_diffs_mean_df = get_std(buffer, ds, cloud_shadow_mask, nodata_mask, ds_baseline)\n",
    "\n",
    "        # Add outputs to dictionary with cloud buffer as key\n",
    "        output_dict[buffer] = std_df\n",
    "        negative_dict[buffer] = negative_diffs_mean_df\n",
    "        positive_dict[buffer] = positive_diffs_mean_df\n",
    "\n",
    "        # Print results\n",
    "        print(\n",
    "            f\"Buffer in pixels: {buffer}, {': '.join(std_df.round(1).to_string(index_names=False).split())}\"\n",
    "        )\n",
    "\n",
    "    # Concatenate outputs into a single dataframe, then unstack to wide \n",
    "    # format with each variable as a column\n",
    "    std_buffer_df = pd.concat(output_dict, names=[\"pixel_buffer\", \"variable\"])[\n",
    "        \"std\"\n",
    "    ].unstack(\"variable\")\n",
    "\n",
    "    negative_buffer_df = pd.concat(negative_dict, names=[\"pixel_buffer\", \"variable\"])[\n",
    "        \"mean\"\n",
    "    ].unstack(\"variable\")\n",
    "    \n",
    "    positive_buffer_df = pd.concat(positive_dict, names=[\"pixel_buffer\", \"variable\"])[\n",
    "        \"mean\"\n",
    "    ].unstack(\"variable\")\n",
    "    \n",
    "    return std_buffer_df, negative_buffer_df, positive_buffer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot standard deviation and gradient vs buffer size in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_std_gradient_buffer(\n",
    "    context, std_buffer_df, path_row, product, start_buffering, end_buffering, export_figure=True\n",
    "):\n",
    "    # Set up three panel fig\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    # Apply numpy gradient to each column in dataset\n",
    "    std_gradient_df = std_buffer_df.apply(np.gradient, axis=0)\n",
    "\n",
    "    # Plot standard deviation\n",
    "    std_buffer_df.plot(\n",
    "        ax=axes[0],\n",
    "        xlabel=\"Buffer distance\",\n",
    "        ylabel=f\"{context}\",\n",
    "        title=f\"{context} per buffer pixel\",\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    # Plot gradient\n",
    "    std_gradient_df.plot(\n",
    "        ax=axes[1],\n",
    "        xlabel=\"Buffer distance\",\n",
    "        ylabel=f\"{context} gradient\",\n",
    "        title=f\"{context} gradient per buffer pixel\",\n",
    "    )\n",
    "\n",
    "    # Add labels to every second item\n",
    "    for index in std_gradient_df.index[::2]:\n",
    "        axes[1].text(\n",
    "            index,\n",
    "            std_gradient_df.nbart_blue.loc[index],\n",
    "            round(std_gradient_df.nbart_blue.loc[index], 2),\n",
    "            size=8,\n",
    "        )\n",
    "\n",
    "    # Plot mean of all gradients\n",
    "    std_gradient_df_mean = std_gradient_df.mean(axis=1).to_frame(\"All bands\")\n",
    "    std_gradient_df_mean.plot(\n",
    "        ax=axes[2],\n",
    "        xlabel=\"Buffer distance\",\n",
    "        ylabel=f\"{context} gradient\",\n",
    "        title=f\"{context} gradient per buffer pixel\",\n",
    "    )\n",
    "\n",
    "    # Add labels to every second item\n",
    "    for index in std_gradient_df_mean.index[::2]:\n",
    "        axes[2].text(\n",
    "            index,\n",
    "            std_gradient_df_mean[\"All bands\"].loc[index],\n",
    "            round(std_gradient_df_mean[\"All bands\"].loc[index], 2),\n",
    "            size=8,\n",
    "        )\n",
    "\n",
    "    # Set grid and x-ticks\n",
    "    for ax in axes:\n",
    "        ax.grid(alpha=0.1)\n",
    "        ax.set_xticks([i for i in range(start_buffering, end_buffering)])\n",
    "\n",
    "    # Add title above subplots\n",
    "    fig.suptitle(f\"Path/row {path_row}, {product}\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally export figure\n",
    "    if export_figure:\n",
    "        fig.savefig(\n",
    "            f\"output_data/{path_row}_{product}_{context}_plots.jpg\", bbox_inches=\"tight\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cloud Buffering Analysis for all selected validation products and path-rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing path/row 099079, product ga_ls5t_ard_3\n",
      "ga_ls5t_ard_3\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "Counting good quality pixels for each time step using fmask\n",
      "Filtering to 274 out of 349 time steps with at least 90.0% good quality pixels\n",
      "Applying fmask pixel quality/cloud mask\n",
      "Returning 274 time steps as a dask array\n",
      "Calculating geomedian baseline\n"
     ]
    }
   ],
   "source": [
    "# Create output folder. If it doesn't exist, create it\n",
    "output_dir = f\"output_data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for path_row in path_row_list:\n",
    "    for product in products:\n",
    "        print(f\"Processing path/row {path_row}, product {product}\")\n",
    "        \n",
    "        # Load path rows, optionally using only a radius around the\n",
    "        # path-row centroid to reduce processing time and memory use\n",
    "        query_params = define_query_params(\n",
    "            path_row, time_period, maturity, radius=50000\n",
    "        )\n",
    "        load_params = define_load_params(bands, product, query_params)\n",
    "\n",
    "        # Small test area\n",
    "        # query_params = define_query_params_lat_lon_test(time_period)\n",
    "\n",
    "        # Load data using Dask's .persist() to let us to re-use it each run\n",
    "        # rather than having to reload for each buffer size\n",
    "        # for geomedian filter by min good data\n",
    "        ds_filtered = load_data_geomedian(load_params, product, query_params).persist()\n",
    "\n",
    "        try:\n",
    "            print(\"Calculating geomedian baseline\")\n",
    "            # Calculate a cloud free geomedian baseline\n",
    "            ds_baseline = apply_geomedian(ds_filtered, geomedian_threads)\n",
    "\n",
    "            print(\"Calculating cloud shadow mask\")\n",
    "            # Reload data with no filter and calculate cloud shadow mask\n",
    "            ds = load_data(load_params, product, query_params).persist()\n",
    "            cloud_shadow_mask, nodata_mask = calc_cloud_shadow_mask(ds)\n",
    "\n",
    "            print(\"Calculating standard deviation and geomedian difference\")\n",
    "            # Calculate standard deviation per buffer in pixels\n",
    "            std_buffer_df, negative_buffer_df, positive_buffer_df = std_buffer_comp(\n",
    "                start_buffering, end_buffering, ds, cloud_shadow_mask, nodata_mask, ds_baseline\n",
    "            )\n",
    "\n",
    "            # Export results as csv with a \"product\" and \"path_row\" column\n",
    "            std_buffer_df.assign(product=product, path_row=path_row).to_csv(\n",
    "                f\"output_data/{path_row}_{product}_std_buffer.csv\", index=True\n",
    "            )\n",
    "            negative_buffer_df.assign(product=product, path_row=path_row).to_csv(\n",
    "                f\"output_data/{path_row}_{product}_negative_geomedian_diff_buffer.csv\", index=True\n",
    "            )\n",
    "            positive_buffer_df.assign(product=product, path_row=path_row).to_csv(\n",
    "                f\"output_data/{path_row}_{product}_positive_geomedian_diff_buffer.csv\", index=True\n",
    "            )\n",
    "\n",
    "            # Plot the standard deviation and gradient results\n",
    "            plot_std_gradient_buffer(\n",
    "                \"Standard Deviation\",\n",
    "                std_buffer_df,\n",
    "                path_row,\n",
    "                product,\n",
    "                start_buffering,\n",
    "                end_buffering,\n",
    "                export_figure=True,\n",
    "            )\n",
    "\n",
    "            plot_std_gradient_buffer(\n",
    "                \"Cloud Shadow Mean Difference\",\n",
    "                negative_buffer_df,\n",
    "                path_row,\n",
    "                product,\n",
    "                start_buffering,\n",
    "                end_buffering,\n",
    "                export_figure=True,\n",
    "            )\n",
    "            \n",
    "            plot_std_gradient_buffer(\n",
    "                \"Cloud Buffer Mean Difference\",\n",
    "                positive_buffer_df,\n",
    "                path_row,\n",
    "                product,\n",
    "                start_buffering,\n",
    "                end_buffering,\n",
    "                export_figure=True,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error - possibly no data for {product}. {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental: plotting all tile and product outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "# Identify output CSVs\n",
    "csvs = glob.glob(\"output_data/*std_buffer.csv\")\n",
    "\n",
    "# Combine into a singe dataframe\n",
    "df = pd.concat((pd.read_csv(f) for f in csvs), ignore_index=True)\n",
    "\n",
    "# Melt into long format for input into seaborn plotting\n",
    "df_long = df.melt(id_vars=[\"product\", \"path_row\", \"pixel_buffer\"], value_name=\"std\")\n",
    "\n",
    "# Add standard deviation gradient to dataframe\n",
    "df_long[\"std_gradient\"] = df_long.groupby([\"product\", \"path_row\", \"variable\"])[\n",
    "    \"std\"\n",
    "].transform(np.gradient)\n",
    "\n",
    "# Take mean of all bands\n",
    "df_long = df_long.groupby([\"product\", \"path_row\", \"pixel_buffer\"]).mean(\n",
    "    numeric_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot standard deviation across all path rows and products\n",
    "sns.relplot(\n",
    "    data=df_long,\n",
    "    x=\"pixel_buffer\",\n",
    "    y=\"std\",\n",
    "    col=\"product\",\n",
    "    hue=\"path_row\",\n",
    "    kind=\"line\",\n",
    "    facet_kws=dict(sharey=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot standard deviation across all path rows and products\n",
    "sns.relplot(\n",
    "    data=df_long,\n",
    "    x=\"pixel_buffer\",\n",
    "    y=\"std\",\n",
    "    col=\"product\",\n",
    "    kind=\"line\",\n",
    "    facet_kws=dict(sharey=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot standard deviation gradient across all path rows and products\n",
    "sns.relplot(\n",
    "    data=df_long,\n",
    "    x=\"pixel_buffer\",\n",
    "    y=\"std_gradient\",\n",
    "    hue=\"path_row\",\n",
    "    col=\"product\",\n",
    "    kind=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot standard deviation gradient across all path rows and products\n",
    "sns.relplot(\n",
    "    data=df_long,\n",
    "    x=\"pixel_buffer\",\n",
    "    y=\"std_gradient\",\n",
    "    col=\"product\",\n",
    "    kind=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** June 2023\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.13\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`sandbox compatible`, :index:`landsat 5`, :index:`landsat 7`, :index:`landsat 8`, :index:`landsat 9`, :index:`cloud masking`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
