{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements - A checklist to remind us if we tick all the boxes\n",
    "---------------------\n",
    "- [ ] Make a nice plot to select a time/ period of interest\n",
    "- [ ] Run WIT on a per-pixel basis\n",
    "- [ ] Return Water/Wet/FC percentage per pixel\n",
    "- [ ] Plot and output WIT spatially, with FC percentage represented as an alpha % for the colour\n",
    "- [ ] Output the results as a ArcGIS-compliant Geotiff (uint8), with the shapefile name and the date in the filename\n",
    "\n",
    "Functions or functionalities\n",
    "---------\n",
    "- bokeh wit plot: to do a stack plot of wit data with bokeh\n",
    "    - input: DataFrame\n",
    "    - output: stack plot of wit data\n",
    "- load_wit_data(**kwargs)\n",
    "    - input: csv file or poly_id in database\n",
    "    - output: DataFrame\n",
    "- load_wofs_fc(query)\n",
    "    - input: a query dictionary with time and geometry\n",
    "    - output: an xarray with water/wet/FC percentage\n",
    "- plot_spatial_wit(input_pixels_array)\n",
    "    - input: an xarray with water/wet/FC percentage\n",
    "    - output: 2 dimensional plot of input\n",
    "- write_geotiff(input_pixels_array, file_name)\n",
    "    - input: an xarray with water/wet/FC percentage\n",
    "            a string as file anme\n",
    "    - output: a geotiff file with input file name\n",
    "    \n",
    "Coding/writing style requirements\n",
    "-------------------------\n",
    "- Always break up a sentence if it's too long, slide showing up is a good indicator\n",
    "- Merge all the cells without essential output unless requied not so, e.g, explanation proceeding a functionality\n",
    "- Use `_LOG.debug` provided insted of `print`\n",
    "- Follow the comments in cells to fill in code rather than randomly dump\n",
    "- Keep all the variables humanly readable, a, b, c or aa, bb, cc etc. simple letters or their permutation are forbidden to be used globally\n",
    "- Something else I haven't come up with yet\n",
    "\n",
    "Does the front end plumbing that you're designing for WIT spatial encompass multiple potential sources of WIT?\n",
    "- Retrieve data from DB\n",
    "- User uploads WIT CSV file (ie if WA wanted to upload one of the WITs we've just shipped them)\n",
    "- Retrieve pre-calculated WIT from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary packages in this cell\n",
    "# check if anything you want is here already with different abbr. with Ctrl+F (maybe there is a better way?\n",
    "# but you got the idea)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import fiona\n",
    "import yaml\n",
    "from datacube import Datacube\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook, show, push_notebook\n",
    "from bokeh.layouts import layout, column, row, WidgetBox, gridplot\n",
    "from bokeh.models import (CheckboxGroup, Select,  CategoricalColorMapper, ColumnDataSource,HoverTool, Label,\n",
    "                          SingleIntervalTicker, Slider, DatetimeTickFormatter, YearsTicker, Legend, TapTool,\n",
    "                          CustomJS, LegendItem, field, Range1d)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.models.tickers import DatetimeTicker\n",
    "from bokeh.plotting import figure\n",
    "from datacube.virtual.impl import VirtualDatasetBox\n",
    "from datacube.virtual import construct\n",
    "from datacube.utils.geometry import CRS, Geometry\n",
    "from shapely.geometry import mapping, box\n",
    "from enum import Enum\n",
    "import os, sys, urllib, logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "from wit_tooling import query_wit_data, load_timeslice, convert_shape_to_polygon, generate_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "_LOG = logging.getLogger('spatial_wit')\n",
    "stdout_hdlr = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('[%(asctime)s.%(msecs)03d - %(levelname)s] %(message)s')\n",
    "stdout_hdlr.setFormatter(formatter)\n",
    "_LOG.addHandler(stdout_hdlr)\n",
    "_LOG.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put global variables in this cell\n",
    "# the values of variables can be changed accordingly\n",
    "shapefile = '/g/data1a/r78/DEA_Wetlands/shapefiles/ramsar_wetlands_3577_20190403.shp'\n",
    "csv_file = '/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'\n",
    "pd_yaml = '/g/data/u46/users/ea6141/wit_tooling/aux/fc_pd.yaml'\n",
    "s3_url = 'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/WIT_v3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the start of all functions\n",
    "----------------------------------------------\n",
    "Note: Put each function in a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokeh_WIT_plot(WITdata, polyName='provided polygon'):\n",
    "    '''\n",
    "    last modified: May 2020\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    WITdata : xarray data array produced by load_wit_data function\n",
    "    polyName : string\n",
    "               A name for the polygon to identify the plot, optional. Defaults to 'provided polygon' \n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    A bokeh stack plot of the contents of the vector file in water, wet, green, dry and bare. Plot can be zoomed in to select a date. \n",
    "    '''\n",
    "    \n",
    "    #set up color palate for bokeh WIT plot\n",
    "    pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "           sns.xkcd_rgb[\"neon blue\"],\n",
    "           sns.xkcd_rgb[\"grass\"],\n",
    "           sns.xkcd_rgb[\"beige\"],\n",
    "           sns.xkcd_rgb[\"brown\"]]  \n",
    "\n",
    "    #these are tools we want to use in the plot\n",
    "    TOOLS = [\"pan, wheel_zoom, box_zoom, reset, tap, save\"]\n",
    "\n",
    "    #lets put a title on the plot\n",
    "    title =f'Percentage of area dominated by WOfS, Wetness, Fractional Cover for {polyName}'    \n",
    "\n",
    "    #set up the x axis to recognise date and time. Note that you will only see the days when you zoom in.\n",
    "    p =figure(plot_width=1200, \n",
    "              plot_height = 400, \n",
    "              x_axis_type='datetime',\n",
    "             title=title, tools=TOOLS)\n",
    "    p.sizing_mode = \"scale_width\"\n",
    "\n",
    "    #align the title in the centre\n",
    "    p.title.align= \"center\"\n",
    "    p.title.text_font_size=\"12pt\"\n",
    "\n",
    "    #label axes\n",
    "    p.yaxis.axis_label=(\"percentage of polygon classified as type\")\n",
    "    p.yaxis.axis_label_text_font_size=\"8pt\"\n",
    "\n",
    "    #we need screen units to put the attribution label under the plot. Don't ask why.\n",
    "    label_opts = dict(\n",
    "        x=0, \n",
    "        y=0,\n",
    "        x_units='screen', \n",
    "        y_units='screen',\n",
    "        text_font_style=\"italic\", \n",
    "        text_font_size=\"8.5pt\")\n",
    "    \n",
    "    #underplot context\n",
    "    msg1 = 'The Fractional Cover algorithm developed by the Joint Remote Sensing Research Program\\n\\\n",
    "    and the Water Observations from Space algorithm developed by Geoscience Australia are used in the production of this data'\n",
    "    caption1 = Label(text=msg1, **label_opts)\n",
    "\n",
    "    p.add_layout(caption1, 'below')\n",
    "\n",
    "    p.xaxis.formatter=DatetimeTickFormatter(years =[\"%Y\"], months=[\"%m/%Y\"] ,days=[\"%d/%m/%Y\"])\n",
    "    p.xaxis.major_label_orientation = 45\n",
    "\n",
    "    #create the actual stack plot using data from the pandas dataframe \n",
    "    p.varea_stack(['water', \n",
    "                  'wet',\n",
    "                  'green',\n",
    "                  'dry',\n",
    "                  'bare'], x= 'utc_time', color=pal, fill_alpha=0.7, source = WITdata, \n",
    "                  legend_label=[\"water\",\"wet\",\"green\",\"dry\",\"bare\"], muted_color=\"grey\", muted_alpha=0.2)\n",
    "\n",
    "\n",
    "    #set the new WIT graph ranges.\n",
    "    left, right, bottom, top = WITdata.index[0], WITdata.index[-1], 0, 100 #set \n",
    "    p.x_range=Range1d(left, right)\n",
    "    p.y_range=Range1d(bottom, top)\n",
    "    p.xaxis.bounds=(left,right)\n",
    "    p.yaxis.bounds=(bottom,top)\n",
    "\n",
    "    #now we want to overplot the data on the plot\n",
    "    #create rectangle borders for no-data times (SLC-off only)\n",
    "    LS5_8_gap_start = datetime(2011,11,1)\n",
    "    LS5_8_gap_end = datetime(2013,4,1)\n",
    "\n",
    "    #plot our dead satellite rectangle\n",
    "    p.hbar(y=50, \n",
    "           height=100,\n",
    "           left=LS5_8_gap_start, \n",
    "           right=LS5_8_gap_end, \n",
    "           color=\"white\", \n",
    "           alpha=0.5, \n",
    "           hatch_color=\"white\", \n",
    "           hatch_pattern='/',\n",
    "           hatch_alpha=0.6,\n",
    "           line_color=\"white\",\n",
    "           line_width =2,\n",
    "           line_alpha=0.6)\n",
    "\n",
    "    p.legend\n",
    "    p.legend.location=\"bottom_left\"\n",
    "    p.legend.click_policy=\"mute\"\n",
    "    p.legend.background_fill_alpha=0.5\n",
    "    p.legend.border_line_alpha=0.5\n",
    "    p.legend.label_text_font_size=\"9pt\"   \n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(wit_df):\n",
    "    #give the index a name that reflects that it is time, measured in UTC not AEDT/AEST\n",
    "    wit_df = wit_df.set_index('TIME')\n",
    "    wit_df.index.name = 'utc_time'\n",
    "    #format the index of the dataframe as a date, not as a string\n",
    "    wit_df.index = pd.to_datetime(wit_df.index)\n",
    "    #Rename the columns so they are easier to understand and plot\n",
    "    wit_df = wit_df.rename(columns={\"WATER\" : \"water\", \n",
    "                            \"WET\" : \"wet\",\n",
    "                           \"PV\" : \"green\",\n",
    "                           \"NPV\" : \"dry\",\n",
    "                           \"BS\" : \"bare\"}) \n",
    "    #converting to percentages to make plotting easier\n",
    "    #first convert if not already a percentage\n",
    "    if wit_df.max().max() <=1.0:\n",
    "        wit_df = wit_df*100\n",
    "    #WITdata.head()\n",
    "    return wit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wit_data(**kwargs):\n",
    "    \"\"\"\n",
    "        input parameters:\n",
    "            csv: csv file path\n",
    "            shape: a shape from shape file\n",
    "            s3_url: s3 bucket path\n",
    "        output:\n",
    "            panda dataframe of wit data\n",
    "    \"\"\"\n",
    "    if kwargs.get(\"csv\") is not None:\n",
    "        wit_data = pd.read_csv(kwargs['csv'])\n",
    "    elif kwargs.get('shape') is not None:\n",
    "        _, wit_data = query_wit_data(kwargs['shape'])\n",
    "        wit_data = pd.DataFrame(data=wit_data, columns=['TIME', 'BS', 'NPV', 'PV', 'WET', 'WATER'])\n",
    "    elif kwargs.get('s3_url') is not None:\n",
    "        wit_data = pd.read_csv(kwargs['s3_url'], infer_datetime_format=True)\n",
    "    return wit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_product(product_yaml):\n",
    "    with open(product_yaml, 'r') as f:\n",
    "        recipe = yaml.safe_load(f)\n",
    "    fc_product = construct(**recipe)\n",
    "    return fc_product\n",
    "\n",
    "def query_datasets(fc_product, shape, crs, time_range):\n",
    "    dc = Datacube()\n",
    "    query_poly = convert_shape_to_polygon(shape['geometry'])\n",
    "    query_poly = Geometry(mapping(box(*query_poly.bounds)), CRS(crs))\n",
    "    query = {'geopolygon': query_poly, 'time': time_range}\n",
    "    datasets = fc_product.query(dc, **query)\n",
    "    grouped = fc_product.group(datasets, **query)\n",
    "    return grouped\n",
    "\n",
    "def load_wofs_fc(fc_product, grouped, time_slice):\n",
    "    if not (isinstance(time_slice, list) or isinstance(time_slice, tuple)):\n",
    "         time_slice = [time_slice]\n",
    "    to_load = VirtualDatasetBox(grouped.box.loc[time_slice], grouped.geobox,\n",
    "                grouped.load_natively, grouped.product_definitions, grouped.geopolygon)\n",
    "    fc_wofs_data = load_timeslice(fc_product, to_load)\n",
    "    return fc_wofs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_wit(fc_wofs_data, mask):\n",
    "    none_water_vars = list(fc_wofs_data.data_vars)[:-1]\n",
    "    water_var = list(fc_wofs_data.data_vars)[-1]\n",
    "    fc_data = fc_wofs_data[none_water_vars].where(fc_wofs_data[water_var] < 1, 0)\n",
    "    tcw_percent = fc_data['TCW'] >= -350\n",
    "    fc_percent = fc_data.drop('TCW').where(~tcw_percent, 0)\n",
    "    fc_wofs_perc = xr.merge([fc_percent, (tcw_percent.astype(\"int\") * 100),\n",
    "                             (fc_wofs_data[water_var].astype(\"int\") * 100)])\n",
    "    fc_wofs_perc = fc_wofs_perc.where(mask == int(shape['id']), -127).astype(\"int16\")\n",
    "    fc_wofs_perc.attrs.update(fc_wofs_data.attrs)\n",
    "    return fc_wofs_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the start of all non function functionalities\n",
    "------------------------------------------------------------------------\n",
    "Note: Keep a single functionality in a SINGLE cell; DONOT make functionalities tangled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wit data from database with a chosen shape\n",
    "with fiona.open(shapefile) as allshapes:\n",
    "    shape_crs = allshapes.crs_wkt\n",
    "    shape = next(iter(allshapes))\n",
    "    wit_data = load_wit_data(shape=shape)\n",
    "# or load from s3 bucket\n",
    "# s3_filename = 'Kerang%20Wetlands_Hird%20Swamp_VIC_17.csv'\n",
    "# wit_data = load_wit_data(s3_url='/'.join([s3_url, s3_filename]))\n",
    "# or load from local csv\n",
    "# wit_data = load_wit_data(csv=csv_file)\n",
    "wit_data = rename_columns(wit_data)\n",
    "wit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in the name of your polygon here (or extract it from something else?)\n",
    "polyName = \"Hird Swamp\" #change this as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = bokeh_WIT_plot(wit_data, polyName)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a(more) time slice(s)\n",
    "# it's helpful to get the location of data rather than load them\n",
    "# and it will save you time without querying database multiple times, which is very slow in case you don't know\n",
    "time_range = (wit_data.index.min(), wit_data.index.max())\n",
    "fc_product = construct_product(pd_yaml)\n",
    "datasets = query_datasets(fc_product, shape, shape_crs, time_range)\n",
    "_LOG.debug(\"Query datasets %s\", datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then decide with slice(s) you want to load\n",
    "# e.g. 1988-02-18 23:13:23.000  in wit_data concers you\n",
    "time_slice = np.datetime64(wit_data.index[4])\n",
    "_LOG.debug(\"load time slice %s\", time_slice)\n",
    "fc_wofs_data = load_wofs_fc(fc_product, datasets, time_slice)\n",
    "# first parameter is a tuple of (gemoetry, a_int)\n",
    "mask = generate_raster([(shape['geometry'], int(shape['id']))], datasets.geobox)\n",
    "fc_wofs_perc = spatial_wit(fc_wofs_data, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(16, 48))\n",
    "im1 = ax[0].imshow((fc_wofs_perc.water)[0].data)\n",
    "im2 = ax[1].imshow((fc_wofs_perc.PV)[0].data)\n",
    "im3 = ax[2].imshow((fc_wofs_perc.TCW)[0].data)\n",
    "fig.colorbar(im3, ax=ax[2])\n",
    "fig.colorbar(im1, ax=ax[0])\n",
    "fig.colorbar(im2, ax=ax[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
