{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping inundation according to flow rates\n",
    "* **Compatability:** Notebook currently compatible with both the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** [`wofs_albers`](https://explorer.sandbox.dea.ga.gov.au/wofs_albers),\n",
    "[`BoM's Water Data Online`](http://www.bom.gov.au/waterdata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "Many of Australia's water bodies are regulated by humans. Flows are controlled by regulatory bodies such as the Murray Darling Basin Authority and local governments to meet the needs of water users while maintaining ecosystems dependant on the surface water. It is important that regulators know where the water goes when it goes overbank to help manage wetland inundations for environmental purposes and be informed of rural or residential areas likely to be flooded as a result of a large dam release. \n",
    "\n",
    "Gauges have been placed along river systems all over Australia to monitor flow rates and water levels, however tracking where water goes when it spills over bank at a certain rate is challenging without combining the gauge data with satellite data.  \n",
    "\n",
    "#### Digital Earth Australia use case \n",
    "The Water Observations from Space (WOfS) dataset detects surface water in Australia based on Landsat data. By linking this dataset with gauge data, we can get information on where the water goes when it goes overbank according to flow rates measured by the gauge. Being able to see where water goes at different flow rates is valuable information for water regulators. \n",
    "\n",
    "### Description\n",
    "In this example, we take gauge data and link it to WOfS data by date to create a summary image of water frequency according to a user-specified flow rate. The worked example demonstrates how to:\n",
    "\n",
    "1. Generate a Flow Duration Curve from stream gauge data\n",
    "2. Use Dask loading to link the WOfS dataset to the stream gauge data\n",
    "3. Call WOfS data by flow rate as opposed to chronological time range\n",
    "4. Cloud mask WOfS data\n",
    "5. Generate a frequency image of water from the WOfS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "**To run this analysis**, run all the cells in the notebook, starting with the \"Load packages\" cell.\n",
    "\n",
    "**After finishing the analysis**, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages\n",
    "Load key Python packages and supporting functions for the analysis. This notebook relies on a module called `dea_bom`, which is located in the `Scripts` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "import dea_bom\n",
    "\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve stream gauge data from the Water Data Online website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This box retrieves data from http://www.bom.gov.au/waterdata/ using the `dea_bom` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_pkl = Path('stations.pkl')\n",
    "\n",
    "# If cache exists, get station data from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "\n",
    "# Preview the first five stations loaded\n",
    "print(f'{len(stations)} stations loaded; e.g.:')\n",
    "stations[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a map of stations and select a gauge that contains data\n",
    "\n",
    "Running this cell will generate a map displaying the locations of stream gauges in Australia. It will take about 20 seconds to load. Choose a gauge on the map by clicking on it. Note that after you click on a gauge it can take a second or two to respond. Also note that many gauges have no data available and will retrieve zero observations, so you will have to click around until you find a gauge with good data. \n",
    "\n",
    "When you have the station you want, **click the Done button before moving onto the next box**. If you want to choose a different gauge after having pressed the Done button, you must re-run this box to regenerate the map then choose another gauge and press Done again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe13ee252446470aab0df2b54b740c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations,\n",
    "                                                zoom=9,\n",
    "                                                center=(-34.72, 143.17));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a flow duration curve from the data selected above\n",
    "The code in the box below will automatically select the latitude and longitude of the selected gauge, but you can enter a different lat and lon if you want by editing the commented out \"lat\" and \"lon\" lines in the code below. \n",
    "The output will tell you what lat and lon has been selected. \n",
    "The buffer, which is the radius around the location point, is set to 8000 meters but you can change it if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lat and lon takes the location of the gauge (pos). You can change the lat and lon to a different location if necessary,\n",
    "# just comment out out this lat, lon = pos line below and define your own.\n",
    "lat, lon = station.pos\n",
    "\n",
    "# lat =\n",
    "# lon =\n",
    "\n",
    "# The buffer is how many meters radius around the location you want to display.\n",
    "buffer = 8000\n",
    "\n",
    "# Rearranging data into a flow duration curve\n",
    "gauge_data = gauge_data.dropna()\n",
    "gauge_data = gauge_data.sort_values('Value')\n",
    "gauge_data['rownumber'] = np.arange(len(gauge_data))\n",
    "gauge_data['Exceedence'] = (1 - (gauge_data.rownumber / len(gauge_data))) * 100\n",
    "\n",
    "# Plotting the flow duration curve\n",
    "gauge_data.plot(x='Exceedence', y='Value', figsize=(11, 7))\n",
    "plt.ylabel('cubic meters per second')\n",
    "plt.grid(True)\n",
    "plt.title('FDC')\n",
    "\n",
    "print(\"You have selected: lat = {}\".format(lat))\n",
    "print(\"You have selected: lon = {}\".format(lon))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the y-axis parameters in cubic meters per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What part of the Flow Duration Curve do you want to look at?\n",
    "yaxis_lower_parameter = 300\n",
    "yaxis_higher_parameter = 1750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the flow duration curve on a log scale allows us to better understand the extremeties of the flow rates. \n",
    "The next cell displays the selected part of the flow duration curve on a log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at it on a log scale\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', figsize=(11,7)) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This is the range you selected displayed as a log')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask loading WOfS data\n",
    "The next cell uses `Dask` to load only the parameters of the WOfS data without loading the images, which is a faster way to load WOfS data. \n",
    "Loading only the parameters is enough to link the WOfS dataset to the dataset from the stream gauge. \n",
    "The data are linked by date using `xarray`'s `.interp()` function. \n",
    "The code then takes into account the flow rate parameters entered by the user and creates a list of dates where there was a satellite pass while the gauge was reading that value. \n",
    "The output tells the user how many passes there were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gauge_data_xr = gauge_data.to_xarray()\n",
    "\n",
    "# Dask load wofs_albers data since 1988 (this loads the dataset parameters \n",
    "# only, not the actual satellite data)\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('1988-01-01', '2019-10-01'), # Change this date accordingly\n",
    "         'crs': 'EPSG:3577'} \n",
    "\n",
    "dc = datacube.Datacube(app='dc-WOfS')\n",
    "wofs_albers= dc.load(product = 'wofs_albers', \n",
    "                     dask_chunks = {}, \n",
    "                     group_by='solar_day', \n",
    "                     **query)\n",
    "\n",
    "# Merging satellite data with gauge data by timestamp\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time)\n",
    "\n",
    "# Here is where it takes into account user input for the FDC\n",
    "specified_level = merged_data.where((merged_data.Value > yaxis_lower_parameter) & \n",
    "                                    (merged_data.Value < yaxis_higher_parameter), \n",
    "                                    drop=True)\n",
    "\n",
    "# Get list of dates to keep\n",
    "date_list = specified_level.time.values\n",
    "\n",
    "print(\"You are about to load this many satellite passes: {}\".format(specified_level.time.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cloud masking the selected WOfS data\n",
    "The box below will load the selected WOfS images with `.compute()` and then cloud mask the images, meaning it will take out images that had too much cloud to see anything. \n",
    "It does this by using the `.make_mask()` function from the Geoscience datacube. \n",
    "The output will tell you how many passes remain after they were cloud masked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wofs_albers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d26f9553dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the passes that happened during the specified flow parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspecified_passes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwofs_albers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Prune out \"too cloudy\" passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecified_passes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwater\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wofs_albers' is not defined"
     ]
    }
   ],
   "source": [
    "# load the passes that happened during the specified flow parameters\n",
    "specified_passes = wofs_albers.sel(time=date_list).compute()\n",
    "\n",
    "# Prune out \"too cloudy\" passes\n",
    "cc = masking.make_mask(specified_passes.water, cloud=True)\n",
    "\n",
    "npixels_per_slice = specified_passes.water.shape[1] * specified_passes.water.shape[2]\n",
    "npixels_per_slice\n",
    "\n",
    "ncloud_pixels = cc.sum(dim='x').sum(dim='y')\n",
    "cloud_pixels_fraction = (ncloud_pixels/npixels_per_slice)\n",
    "\n",
    "clear_specified_passes = specified_passes.water.isel(time=cloud_pixels_fraction < 0.5)\n",
    "print(f\"After cloud masking, there are this many passes available: \n",
    "      f\"{clear_specified_passes.time.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an image of the waterbody based on flow\n",
    "This cell will generate a water frequency image for the selected location using the passes indicated above. \n",
    "One large plot is generated for easy viewing. \n",
    "A small plot next to the flow duration curve with the selected parameters is generated to remind the user which part of flow duration curve the images relates to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters for the image\n",
    "wet = (clear_specified_passes == 128).sum(dim='time')\n",
    "dry = (clear_specified_passes == 0).sum(dim='time')\n",
    "clear = wet + dry\n",
    "frequency = wet / clear\n",
    "frequency= frequency.fillna(0) #this is to get rid of the NAs that occur due to mountain shadows\n",
    "frequency = frequency.where(frequency!=0) #This is to tell it to make areas that were dry 100% of the time white\n",
    "\n",
    "# Plotting the image\n",
    "frequency.plot(figsize = (16, 12))\n",
    "plt.axis('off')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "\n",
    "ax1 = frequency.plot(ax=ax[0])\n",
    "\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', ax=ax[1]) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This was the specified range for which the image was generated (FDC log)')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file as a GeoTIFF\n",
    "You might want to use this water frequency image in another workflow.\n",
    "The following code will export the image as a `.tif` GeoTIFF file that can be loaded into common GIS software (e.g. ArcMap or QGIS). \n",
    "\n",
    "Enter a name for the `.tif` file below. \n",
    "The `../` part of the name means it will save this file one directory up from where this notebook is saved, i.e. in your `dea-notebooks` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output file name \n",
    "file_name = '../file_name_here.tif'\n",
    "\n",
    "# Set up the file for writing\n",
    "frequency_dataset = frequency.to_dataset()\n",
    "frequency_dataset.attrs=wofs_albers.attrs\n",
    "\n",
    "# Write GeoTIFF to a location\n",
    "write_geotiff(file_name, frequency_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** October 2019\n",
    "\n",
    "**Compatible `datacube` version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`WOfS`, :index:`dea_bom`, :index:`get_stations`, :index:`ui_select_station`, :index:`time series`, :index:`image compositing`, :index:`GeoTIFF`, :index:`exporting data`, :index:`external data`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
