{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting waterbodies from Sentinel-2 <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* [**Sign up to the DEA Sandbox**](https://docs.dea.ga.gov.au/setup/sandbox.html) to run this notebook interactively from a browser\n",
    "* **Compatibility:** Notebook currently compatible with both the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule),\n",
    "[ga_ls5t_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3),\n",
    "[wofs_albers](https://explorer.sandbox.dea.ga.gov.au/wofs_albers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "[DEA Waterbodies](https://www.ga.gov.au/dea/products/dea-waterbodies) is a time-series data product that summarises the surface area of open waterbodies in Australia using [Water Observations from Space (WOfS)](https://www.ga.gov.au/dea/products/wofs). \n",
    "WOfS classifies Landsat pixels into wet and dry. Landsat data have a resolution of 25m$^2$, but it would be really nice if we could instead use Sentinel 2 data with its 10m$^2$ resolution. This would help distinguish neighbouring waterbodies that are blurred together in Landsat (and hence in DEA Waterbodies). \n",
    "Sentinel 2 does not yet have WOfS.\n",
    "\n",
    "One alternative to WOfS that we _could_ evaluate for Sentinel 2 is the [Modified Normalised Difference Water Idex (MNDWI)](http://doi.org/10.1080/01431160600589179), which can be calculated directly from surface reflectance. \n",
    "MNDWI greater than zero is indicative of water. It is not as accurate as WOfS, but easier to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook compares DEA Waterbodies derived from WOfS to an analogous product derived from MNDWI. \n",
    "There are two main factors we can vary: how to derive our polygons, and how to derive our time series. \n",
    "Both polygons and time series can be generated from Landsat WOfS, from Landsat MNDWI, or from Sentinel 2 MNDWI.\n",
    "We can choose to combine any polygon method and any time series method. \n",
    "This gives us a grid of possible evaluations:\n",
    "\n",
    "| | Landsat WOfS polygons | Landsat MNDWI polygons | Sentinel 2 MNDWI polygons |\n",
    "|-|---------------|------------------------|---------------------------|\n",
    "|**Landsat WOfS time series** | DEA Waterbodies | Polygon proxy quality | Good differentation for merged waterbodies |\n",
    "|**Landsat MNDWI time series** | Time series proxy quality | Total proxy quality | - |\n",
    "|**Sentinel 2 MNDWI time series** | Sentinel 2 proxy quality | - | Highest resolution |\n",
    "\n",
    "The upper left corner is the existing DEA Waterbodies. \n",
    "Polygons derived from Sentinel 2 would be great for differentiating neighbouring waterbodies, even with lower resolution surface area data. \n",
    "Landsat WOfS polygons with MNDWI time series informs us how well MNDWI approximates the surface area time series. \n",
    "Similarly, Landsat MNDWI polygons with WOfS time series informs us how well the MNDWI polygons approximate those we obtain from WOfS. \n",
    "The highest attainable resolution is deriving both parts of the product from Sentinel 2.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Edit the analysis parameters and run all the cells in this notebook to analyse a region of Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datacube.virtual as virtual\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.cm\n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from dea_plotting import display_map\n",
    "from dea_spatialtools import xr_rasterize, xr_vectorize\n",
    "from dea_dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Sentinel_2_waterbodies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Dask\n",
    "\n",
    "Set up a local Dask server for parallelism and lazy loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34299</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/robbibt/proxy/8787/status' target='_blank'>/user/robbibt/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>14.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:34299' processes=1 threads=2, memory=14.18 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose which area of Australia to analyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lake Boort and Lake Lyndger\n",
    "xlim = (143.70141, 143.76180)\n",
    "ylim = (-36.14517, -36.09688)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the analysis area\n",
    "\n",
    "Display a map of the area we plan to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f3d6977eeb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_map(x=xlim, y=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a virtual product for the MNDWI calculation\n",
    "\n",
    "The [MNDWI](DOI:10.1080/01431160600589179) is given by\n",
    "\n",
    "$$\n",
    "    \\frac{\\mathrm{green} - \\mathrm{SWIR}}{\\mathrm{green} + \\mathrm{SWIR}}.\n",
    "$$\n",
    "\n",
    "We'll build a virtual product that calculates this without having to load all of the channels ourselves. \n",
    "A virtual product is just like a regular DEA product, except it has some transformations applied before we see it. \n",
    "We can define one with YAML that applies cloud masking and calculates the MNDWI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_yaml = \"\"\"\n",
    "products:\n",
    "    ls8_MNDWI:\n",
    "        recipe:\n",
    "            transform: expressions\n",
    "            output:\n",
    "                MNDWI:\n",
    "                    formula: (green - swir1) / (green + swir1)\n",
    "                    dtype: float32\n",
    "            input:\n",
    "                transform: apply_mask\n",
    "                mask_measurement_name: fmask\n",
    "                input:\n",
    "                    transform: expressions\n",
    "                    output:\n",
    "                        fmask: \n",
    "                            formula: (fmask == 1) | (fmask == 5)\n",
    "                            nodata: False\n",
    "                        green: green\n",
    "                        swir1: swir1\n",
    "                    input:\n",
    "                          product: ga_ls8c_ard_3\n",
    "                          measurements: [green, swir1, fmask]\n",
    "                          output_crs: EPSG:3577\n",
    "                          resolution: [-30, 30]\n",
    "                          resampling:\n",
    "                              fmask: nearest\n",
    "                              '*': average\n",
    "    s2a_MNDWI:\n",
    "        recipe:\n",
    "            transform: expressions\n",
    "            output:\n",
    "                MNDWI:\n",
    "                    formula: (nbart_green - nbart_swir_2) / (nbart_green + nbart_swir_2)\n",
    "                    dtype: float32\n",
    "            input:\n",
    "                transform: apply_mask\n",
    "                mask_measurement_name: fmask\n",
    "                input:\n",
    "                    transform: expressions\n",
    "                    output:\n",
    "                        fmask: \n",
    "                            formula: (fmask == 1) | (fmask == 5)\n",
    "                            nodata: False\n",
    "                        nbart_green: nbart_green\n",
    "                        nbart_swir_2: nbart_swir_2\n",
    "                    input:\n",
    "                        collate:\n",
    "                            - product: s2b_ard_granule\n",
    "                              measurements: [nbart_green, nbart_swir_2, fmask]\n",
    "                              output_crs: EPSG:3577\n",
    "                              resolution: [-10, 10]\n",
    "                              resampling:\n",
    "                                  fmask: nearest\n",
    "                                  '*': average\n",
    "                            - product: s2a_ard_granule\n",
    "                              measurements: [nbart_green, nbart_swir_2, fmask]\n",
    "                              output_crs: EPSG:3577\n",
    "                              resolution: [-10, 10]\n",
    "                              resampling:\n",
    "                                  fmask: nearest\n",
    "                                  '*': average\n",
    "    wofs_masked:\n",
    "        recipe:\n",
    "            transform: expressions\n",
    "            output:\n",
    "                water:\n",
    "                    formula: water\n",
    "                    nodata: -1\n",
    "            input:\n",
    "                transform: apply_mask\n",
    "                mask_measurement_name: mask\n",
    "                input:\n",
    "                    transform: expressions\n",
    "                    output:\n",
    "                        mask: \n",
    "                            formula: (water == 0) | (water == 128)\n",
    "                            nodata: False\n",
    "                        water:\n",
    "                            formula: water\n",
    "                            nodata: -1\n",
    "                    input:\n",
    "                        product: wofs_albers\n",
    "                        measurements: [water]\n",
    "                        output_crs: EPSG:3577\n",
    "                        resolution: [-25, 25]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can convert the YAML into a catalogue containing our custom virtual products, which we can use just like a datacube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = virtual.catalog_from_yaml(cat_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this catalogue to load our MNDWI virtual products for Sentinel 2 and Landsat 8. \n",
    "Use dask to avoid loading everything into memory at once if the data are too big, or otherwise use `.load` here to load the data immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error opening source dataset: http://dapds00.nci.org.au/thredds/fileServer/if87/2017-07-15/S2B_OPER_MSI_ARD_TL_SGS__20170715T032634_A001858_T55HBA_N02.05/NBART/T55HBA_20170715T002109_NBART_B03.TIF\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "HTTP response code: 503",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_HttpResponseError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_shim.pyx\u001b[0m in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_HttpResponseError\u001b[0m: HTTP response code: 503",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0fd7957f871f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load Sentinel-2 MNDWI data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0ms2a_mndwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"s2a_MNDWI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#.load()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load Landsat 8 MNDWI data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, dc, **query)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, grouped, **load_settings)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVirtualDatasetBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, grouped, **load_settings)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVirtualDatasetBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, grouped, **load_settings)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVirtualDatasetBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, grouped, **load_settings)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         groups = [fetch_child(child, source_index, grouped.filter(is_from(source_index)).map(strip_source))\n\u001b[0;32m--> 657\u001b[0;31m                   for source_index, child in enumerate(self._children)]\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mnon_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         groups = [fetch_child(child, source_index, grouped.filter(is_from(source_index)).map(strip_source))\n\u001b[0;32m--> 657\u001b[0;31m                   for source_index, child in enumerate(self._children)]\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mnon_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mfetch_child\u001b[0;34m(child, source_index, r)\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index_measurement_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/virtual/impl.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, grouped, **load_settings)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                     \u001b[0mfuse_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fuse_func'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                                     \u001b[0mdask_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dask_chunks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                                     resampling=merged.get('resampling', 'nearest'))\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/api/core.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(sources, geobox, measurements, resampling, fuse_func, dask_chunks, skip_broken_datasets, progress_cbk, **extra)\u001b[0m\n\u001b[1;32m    587\u001b[0m             return Datacube._xr_load(sources, geobox, measurements,\n\u001b[1;32m    588\u001b[0m                                      \u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                                      progress_cbk=progress_cbk)\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/api/core.py\u001b[0m in \u001b[0;36m_xr_load\u001b[0;34m(sources, geobox, measurements, skip_broken_datasets, progress_cbk)\u001b[0m\n\u001b[1;32m    524\u001b[0m                     _fuse_measurement(t_slice, datasets, geobox, m,\n\u001b[1;32m    525\u001b[0m                                       \u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                                       progress_cbk=_cbk)\n\u001b[0m\u001b[1;32m    527\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTerminateCurrentLoad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dc_partial_load'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/api/core.py\u001b[0m in \u001b[0;36m_fuse_measurement\u001b[0;34m(dest, datasets, geobox, measurement, skip_broken_datasets, progress_cbk)\u001b[0m\n\u001b[1;32m    716\u001b[0m                        \u001b[0mfuse_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeasurement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fuser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                        \u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                        progress_cbk=progress_cbk)\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/storage/_load.py\u001b[0m in \u001b[0;36mreproject_and_fuse\u001b[0;34m(datasources, destination, dst_gbox, dst_nodata, resampling, fuse_func, skip_broken_datasets, progress_cbk)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_so_far\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mignore_exceptions_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_broken_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrdr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                     \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_time_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_gbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_nodata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/storage/_rio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0m_LOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error opening source dataset: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlocked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/datacube/storage/_rio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0m_LOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"opening %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0moverride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: HTTP response code: 503"
     ]
    }
   ],
   "source": [
    "# Set up spatio-temporal query used to load data for both products\n",
    "query = {\n",
    "    \"x\": xlim,\n",
    "    \"y\": ylim,\n",
    "    \"time\": (\"2015-11\", \"2020-09\"),\n",
    "    \"group_by\": \"solar_day\",\n",
    "#     \"dask_chunks\": {\"x\": 300, \"y\": 300, \"time\": 1},\n",
    "}\n",
    "\n",
    "# Load Sentinel-2 MNDWI data\n",
    "s2a_mndwi = cat[\"s2a_MNDWI\"].load(dc, **query)  #.load()\n",
    "\n",
    "# Load Landsat 8 MNDWI data\n",
    "ls8_mndwi = cat[\"ls8_MNDWI\"].load(dc, **query)  # .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, grab WOfS for the same time period as our Landsat observations. \n",
    "WOfS is calculated based on Landsat, so it should have data for the exact same times as Landsat does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [str(t.values) for t in ls8_mndwi.time]\n",
    "\n",
    "wofs = cat[\"wofs_masked\"].load(\n",
    "    dc, x=xlim, y=ylim, time=times, dask_chunks=dask_chunks\n",
    ")  # Matches LS8 time\n",
    "wofs = xr.where(wofs == 128, 1, xr.where(wofs == 0, 0, np.nan)).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate an all-time average\n",
    "\n",
    "In analogy to WOfS all-time summary, calculate an all-time average for water derived from MNDWI. First, let's threshold each MNDWI frame so we can find the water. What would be a good threshold? This may vary depending on the satellite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the dates common to both datasets so we can visualise them with a fair comparison.\n",
    "common_dates = sorted(\n",
    "    set(list(s2a_mndwi.time.astype(\"datetime64[D]\").values))\n",
    "    & set(list(ls8_mndwi.time.astype(\"datetime64[D]\").values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_threshold = 0\n",
    "ls8_threshold = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "(\n",
    "    s2a_mndwi.MNDWI.sel(time=common_dates[3], method=\"nearest\") > s2_threshold\n",
    ").plot.imshow(ax=axs[0])\n",
    "(\n",
    "    ls8_mndwi.MNDWI.sel(time=common_dates[3], method=\"nearest\") > ls8_threshold\n",
    ").plot.imshow(ax=axs[1])\n",
    "axs[0].set_title(\"Sentinel 2 > threshold\")\n",
    "axs[1].set_title(\"LS8 > threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable threshold like local Otsu thresholding might be useful in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, summarise these thresholded scenes and also generate a summary for WOfS by calculating how often each pixel is wet in the data.\n",
    "\n",
    "Here we make the summaries and plot them. I've chosen some thresholds for S2 and LS8 that seem to get the best results and plotted these as contours - in reality we'd have no manual oversight on this, so this is something of a best-case attempt. To match the methodology of DEA Waterbodies, we need two thresholds: one for identifying waterbodies and one for finding their maximum extent. In WOfS (DEA Waterbodies) these are 5% and 10% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_mndwi_summary = (s2a_mndwi >= s2_threshold).MNDWI.mean(axis=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_mndwi_summary = (ls8_mndwi >= ls8_threshold).MNDWI.mean(axis=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wofs_summary = wofs.water.mean(axis=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_thresholds = [0.03, 0.08]\n",
    "ls8_thresholds = [0.05, 0.10]\n",
    "wofs_thresholds = [0.05, 0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "colours = [\"black\", \"white\"]\n",
    "s2a_mndwi_summary.plot.imshow(ax=axs[0])\n",
    "ls8_mndwi_summary.plot.imshow(ax=axs[1])\n",
    "s2a_mndwi_summary.plot.contour(levels=s2a_thresholds, ax=axs[0], colors=colours)\n",
    "ls8_mndwi_summary.plot.contour(levels=ls8_thresholds, ax=axs[1], colors=colours)\n",
    "wofs_summary.plot.contour(levels=wofs_thresholds, ax=axs[2], colors=colours)\n",
    "wofs_summary.plot.imshow(ax=axs[2])\n",
    "axs[0].set_title(\"Sentinel 2 MNDWI average\")\n",
    "axs[1].set_title(\"LS8 MNDWI average\")\n",
    "axs[2].set_title(\"WOfS water frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating polygons\n",
    "\n",
    "We can generate polygons by judicious choice of threshold for each of these. TODO: Use an adaptive threshold.\n",
    "\n",
    "The existing method for DEA Waterbodies is to generate polygons at the 10% level as well as the 5% level. Then, use the 10% polygons to detect waterbodies and the 5% waterbodies to get the maximum extent. We will use the thresholds from above, which are different for Sentinel 2 and Landsat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_polygons(mask):\n",
    "    gdf = xr_vectorize(mask, crs=\"EPSG:3577\")\n",
    "    # Vectorised polygons will have their attribute column\n",
    "    # set based on the pixel values of the mask.\n",
    "    # This is a boolean mask, so we can just check\n",
    "    # for attribute == 1.\n",
    "    return gdf[gdf.attribute == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_lower_wbs = mask_to_polygons(s2a_mndwi_summary >= s2a_thresholds[0])\n",
    "s2a_upper_wbs = mask_to_polygons(s2a_mndwi_summary >= s2a_thresholds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_lower_wbs = mask_to_polygons(ls8_mndwi_summary >= ls8_thresholds[0])\n",
    "ls8_upper_wbs = mask_to_polygons(ls8_mndwi_summary >= ls8_thresholds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wofs_lower_wbs = mask_to_polygons(wofs_summary >= wofs_thresholds[0])\n",
    "wofs_upper_wbs = mask_to_polygons(wofs_summary >= wofs_thresholds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the lower boundaries, but only if they contain an upper polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wbs = s2a_lower_wbs.loc[\n",
    "    gpd.sjoin(s2a_lower_wbs, s2a_upper_wbs, how=\"right\").index_left\n",
    "]\n",
    "ls8_wbs = ls8_lower_wbs.loc[\n",
    "    gpd.sjoin(ls8_lower_wbs, ls8_upper_wbs, how=\"right\").index_left\n",
    "]\n",
    "wofs_wbs = wofs_lower_wbs.loc[\n",
    "    gpd.sjoin(wofs_lower_wbs, wofs_upper_wbs, how=\"right\").index_left\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard everything less than 5 Landsat pixels in area: 4500 m$^2$ for Landsat Collection 3. This matches the methodology of DEA Waterbodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_threshold = 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wbs = s2a_wbs[s2a_wbs.area >= area_threshold]\n",
    "ls8_wbs = ls8_wbs[ls8_wbs.area >= area_threshold]\n",
    "wofs_wbs = wofs_wbs[wofs_wbs.area >= area_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for wbs, ax, t in zip(\n",
    "    [s2a_wbs, ls8_wbs, wofs_wbs], axs, [\"Sentinel 2 MNDWI\", \"Landsat 8 MNDWI\", \"WOfS\"]\n",
    "):\n",
    "    wbs.plot(ax=ax)\n",
    "    ax.set_title(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a few polygons that are duplicated or overlapping. Combine these by doing a unary union and then split back into polygons again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wbs = gpd.GeoDataFrame(\n",
    "    geometry=[poly for poly in s2a_wbs.unary_union], crs=\"EPSG:3577\"\n",
    ")\n",
    "ls8_wbs = gpd.GeoDataFrame(\n",
    "    geometry=[poly for poly in ls8_wbs.unary_union], crs=\"EPSG:3577\"\n",
    ")\n",
    "wofs_wbs = gpd.GeoDataFrame(\n",
    "    geometry=[poly for poly in wofs_wbs.unary_union], crs=\"EPSG:3577\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally give everything a new ID. We can use this later to generate our masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wbs[\"ID\"] = np.arange(1, len(s2a_wbs) + 1).astype(int)\n",
    "ls8_wbs[\"ID\"] = np.arange(1, len(ls8_wbs) + 1).astype(int)\n",
    "wofs_wbs[\"ID\"] = np.arange(1, len(wofs_wbs) + 1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the ID to be the index so we can query by it. Don't drop the ID so we can use it as a column for later rasterising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wbs.set_index(\"ID\", drop=False, inplace=True)\n",
    "ls8_wbs.set_index(\"ID\", drop=False, inplace=True)\n",
    "wofs_wbs.set_index(\"ID\", drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface area time series comparison\n",
    "\n",
    "Let's choose a waterbody and compare time series derived from different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a polygon in the Sentinel 2 waterbodies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wb = s2a_wbs.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_wb.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then find its equivalent in Landsat MNDWI and WOfS polygons by finding the polygon with the largest intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_wb = ls8_wbs.iloc[ls8_wbs.intersection(s2a_wb.geometry).area.argmax()]\n",
    "wofs_wb = wofs_wbs.iloc[wofs_wbs.intersection(s2a_wb.geometry).area.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_wb.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wofs_wb.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a mask that matches the waterbodies. There are nine masks, which corresponds to three different polygon sets and three different time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_sets = {\n",
    "    \"wofs\": wofs_wbs,\n",
    "    \"ls8\": ls8_wbs,\n",
    "    \"s2a\": s2a_wbs,\n",
    "}\n",
    "\n",
    "ts_dataarrays = {\n",
    "    \"wofs\": wofs.water,\n",
    "    \"ls8\": ls8_mndwi.MNDWI >= ls8_threshold,\n",
    "    \"s2a\": s2a_mndwi.MNDWI >= s2_threshold,\n",
    "}\n",
    "\n",
    "ids = {\n",
    "    \"wofs\": wofs_wb.ID,\n",
    "    \"ls8\": ls8_wb.ID,\n",
    "    \"s2a\": s2a_wb.ID,\n",
    "}\n",
    "\n",
    "area_per_px = {\n",
    "    \"wofs\": 25 ** 2,\n",
    "    \"ls8\": 30 ** 2,\n",
    "    \"s2a\": 10 ** 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {}  # (polygons, time series)\n",
    "for poly_name, poly_set in polygon_sets.items():\n",
    "    for ts_name, ts_dataarray in ts_dataarrays.items():\n",
    "        mask = xr_rasterize(poly_set, ts_dataarray.isel(time=0), attribute_col=\"ID\")\n",
    "        masks[poly_name, ts_name] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each mask has pixels set to the ID value of the polygon that contains those pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[\"ls8\", \"ls8\"].plot(cmap=\"rainbow\", add_colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the masks to extract pixel values for each time. We also want to extract how many pixels are invalid, so we can figure out which days have good observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_wet = {}\n",
    "ts_invalid = {}\n",
    "for ts_name, ts_dataarray in ts_dataarrays.items():\n",
    "    for poly_name, poly_set in polygon_sets.items():\n",
    "        mask = masks[poly_name, ts_name] == ids[poly_name]\n",
    "        ts_wet[poly_name, ts_name] = (\n",
    "            ts_dataarray.where(mask).sum(axis=(1, 2)) * area_per_px[ts_name]\n",
    "        ).load()\n",
    "        ts_invalid[poly_name, ts_name] = (\n",
    "            ts_dataarray.isnull().where(mask).sum(axis=(1, 2)) * area_per_px[ts_name]\n",
    "        ).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEA Waterbodies considers an observation valid if there is at least 90% valid pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_ok = {}\n",
    "for (poly_name, ts_name), invalid_px in ts_invalid.items():\n",
    "    max_extent = polygon_sets[poly_name].area.loc[ids[poly_name]]\n",
    "    ts_ok[poly_name, ts_name] = ts_invalid[poly_name, ts_name] < 0.1 * max_extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot all of these time series now. This step may take a while if you didn't preload the data, as it's where Dask has to finally load it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "# Subplot label padding.\n",
    "padding = 10  # pt\n",
    "# Our datasets have different date ranges, so set these manually for display.\n",
    "wofs_xlimits = (wofs.time.values.min(), wofs.time.values.max())\n",
    "xticks = np.arange(np.datetime64(\"2015\", \"Y\"), np.datetime64(\"2021\", \"Y\"))\n",
    "for x, poly_name in enumerate(polygon_sets):\n",
    "    for y, ts_name in enumerate(ts_dataarrays):\n",
    "        ax = axs[y, x]\n",
    "\n",
    "        # https://stackoverflow.com/questions/25812255/row-and-column-headers-in-matplotlibs-subplots\n",
    "        if x == 0:\n",
    "            # Label the vertical axis of subplots.\n",
    "            ax.annotate(\n",
    "                s=ts_name + \" time series\",\n",
    "                xy=(-0.1, 0.5),\n",
    "                xycoords=\"axes fraction\",\n",
    "                textcoords=\"offset points\",\n",
    "                size=\"large\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                xytext=(-padding, 0),\n",
    "                rotation=\"vertical\",\n",
    "            )\n",
    "        if y == 0:\n",
    "            # Label the horizontal axis of subplots.\n",
    "            ax.annotate(\n",
    "                s=poly_name + \" polygons\",\n",
    "                xy=(0.5, 1),\n",
    "                xycoords=\"axes fraction\",\n",
    "                textcoords=\"offset points\",\n",
    "                size=\"large\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                xytext=(0, padding),\n",
    "                rotation=\"horizontal\",\n",
    "            )\n",
    "\n",
    "        # Plot valid dates of the time series.\n",
    "        ok = ts_ok[poly_name, ts_name]\n",
    "        ts = ts_wet[poly_name, ts_name]\n",
    "        ax.plot(ts.time[ok], ts[ok], marker=\"x\", linestyle=\"None\")\n",
    "\n",
    "        ax.set_xlim(wofs_xlimits)\n",
    "        ax.set_xticks(xticks)\n",
    "        ax.set_xticklabels(xticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNDWI series are noticably noisier, with lots of no-water or low-water observations that are wet in WOfS. However, the general pattern matches WOfS, and in particular seems to bound it below. Maybe we could consider MNDWI a lower bound for wetness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also estimate a mean-squared difference between each time series and the WOfS time series with WOfS polygons (= DEA Waterbodies). This assumes Gaussian error, but for sufficiently large numbers of pixels the binomial distribution we actually have should be well-approximated by a Gaussian. By calculating such a difference, we can summarise the discrepancies between the above plots as a single number per plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pandas series of valid data for comparison.\n",
    "# We resample to daily to avoid time rounding issues.\n",
    "ok = ts_ok[\"wofs\", \"wofs\"]\n",
    "ts = ts_wet[\"wofs\", \"wofs\"]\n",
    "comparison_series = (\n",
    "    pd.Series(ts[ok], index=ts.time[ok].values, name=\"comparison\").resample(\"D\").mean()\n",
    ")\n",
    "\n",
    "differences = {}\n",
    "for poly_name in polygon_sets:\n",
    "    for ts_name in ts_dataarrays:\n",
    "        # Make a pandas series of valid data.\n",
    "        ok = ts_ok[poly_name, ts_name]\n",
    "        ts = ts_wet[poly_name, ts_name]\n",
    "        series = (\n",
    "            pd.Series(ts[ok], index=ts.time[ok].values, name=\"test\")\n",
    "            .resample(\"D\")\n",
    "            .mean()\n",
    "        )\n",
    "        # Join this with the comparison series to have a unified time index.\n",
    "        joint_series = pd.merge(\n",
    "            series, comparison_series, left_index=True, right_index=True, how=\"outer\"\n",
    "        )\n",
    "        # Interpolate and compute the difference.\n",
    "        joint_series.interpolate(inplace=True)\n",
    "        difference = joint_series.test - joint_series.comparison\n",
    "        # The mean-squared error is the difference we seek.\n",
    "        differences[poly_name, ts_name] = (difference ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at these differences as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "grid = np.zeros((3, 3))\n",
    "for x, poly_name in enumerate(sorted(polygon_sets)):\n",
    "    for y, ts_name in enumerate(sorted(ts_dataarrays)):\n",
    "        grid[x, y] = differences[poly_name, ts_name]\n",
    "plt.pcolor(grid, cmap=\"Reds\")\n",
    "plt.colorbar(label=\"Difference\")\n",
    "plt.xticks(np.arange(3) + 0.5, [i + \" polygons\" for i in sorted(polygon_sets)])\n",
    "plt.yticks(np.arange(3) + 0.5, [i + \" time series\" for i in sorted(ts_dataarrays)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polygons dominate the differences between the time series. This shows that the polygons are the most important change here between the datasets, dwarfing the impact of the low-water observations. To see these more clearly, we can normalise the difference by the kind of polygons before we plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.pcolor(grid / grid.max(axis=0), cmap=\"Reds\")\n",
    "plt.colorbar(label=\"Normalised difference\")\n",
    "plt.xticks(np.arange(3) + 0.5, [i + \" polygons\" for i in sorted(polygon_sets)])\n",
    "plt.yticks(np.arange(3) + 0.5, [i + \" time series\" for i in sorted(ts_dataarrays)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S2 and LS8 MNDWI are equally good when applied to non-WOfS polygons. S2 time series deviate appreciably when applied to WOfS polygons, though. This makes sense because S2 will include lots of dry areas considered part of the waterbody by the much larger WOfS pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** October 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`sentinel 2`, :index:`landsat 8`, :index:`water`, :index:`waterbodies`, :index:`MNDWI`, :index:`time series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
