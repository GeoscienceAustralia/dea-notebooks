{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Classification for Fractional Cover of Water Project <img align=\"right\" src=\"../../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `DEA Sandbox` environment\n",
    "* **Products used:** \n",
    "This notebook uses no DEA products. It uses either example drone data or uploaded drone data, in [WGS84](https://www.ga.gov.au/scientific-topics/positioning-navigation/wgs84) and [GeoTIFF format](https://earthdata.nasa.gov/esdis/eso/standards-and-references/geotiff) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background <img align=\"right\" src=\"./Data_and_figures/Fractional_cover_of_water.png\" style=\"width: 400px;\"/>\n",
    "The Fractional Cover of Water Project is a [Geoscience Australia](https://www.ga.gov.au/) - [Australian Rivers Institute](https://www.griffith.edu.au/australian-rivers-institute/our-people) project. The project requires the collection of drone field data to validate the development of a new algorithm that will classify a [Landsat](https://landsat.gsfc.nasa.gov/) or [Sentinel 2](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) image pixel into sub-pixel fractions of water and wet vegetation. \n",
    "\n",
    "This notebook allows a user to manually classify collected drone imagery as input to the algorithm development and validation process. Load the data in, run all the cells, and a [bokeh](https://docs.bokeh.org/en/latest/index.html) interactive plot allows the user to zoom in, click 1m x 1m cells, select the land cover type, and save the results to file. Open water cells can have a [Forel-Ule](http://forel-ule-scale.com/) water color recorded for the cell, where this was measured at the site using the [EyeOnWater](https://www.eyeonwater.org/) application.\n",
    "\n",
    "The image at right shows the variations in wet vegetation fractional cover type that will be collected by drone. `Floating, Emergent, OpenWater, GreenVeg(PV), DryVeg(NPV), BareSoil(BS), and Forel-Ule water colour (if the type is OpenWater)` Water height is additionally recorded though may not be retrievable from the algorithm due to the inherent limitations of top-down satellite imagery.\n",
    "\n",
    "Additional documentation is provided below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The notebook uses drone imagery to classify the land cover type, including `Floating, Emergent, OpenWater, GreenVeg(PV), DryVeg(NPV), BareSoil(BS), Forel-Ule water colour (if the type is OpenWater)`\n",
    "\n",
    "* first bring in the drone data in resolution (1, -1) (unit meter) as a GeoTiff raster image. This can be copied into the [DEA Sandbox](https://app.sandbox.dea.ga.gov.au/) by dragging and dropping the file.\n",
    "* classify the pixels into categories listed above\n",
    "* save the results as raster into `geotiff`\n",
    "\n",
    "To use the notebook, please refer the instruction video and doc linked below\n",
    "- [Written Workflow Instructions](https://drive.google.com/file/d/1CS7zQYdTUoMFBwbiOj6x74lxHGdLpcdZ/view?usp=sharing)\n",
    "- [Video Instructions](https://drive.google.com/file/d/1nygm8rFe1frTR91kRiGzhhwxYALLg5mH/view?usp=sharing)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get started\n",
    "### 1. Upload drone image\n",
    "\n",
    "Set the variable `drone_tif_path` accordingly\n",
    "e.g. `drone_tif_path = \"./DataAndFigures/drone_wetland_sml4.tif\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file name if necessary\n",
    "drone_tif_path = \"./Data_and_figures/Drone_wetland_sml.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Name your output file\n",
    "The default file name is results_tif_path = `./test.tif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sends the output file to the current directory and a file named `test.tif`. \n",
    "# You may want to rename this file\n",
    "results_tif_path = './test.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the rest of the notebook\n",
    "Now you should be all set up, you can just run the cells below by pressing `Shift + Enter` until the drone image shows up near the end. Alternatively, you can select `Run -->> Run All Cells` from the drop-down menu in JupyterLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import datacube\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "import xarray as xr\n",
    "import re\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "from datacube.utils.geometry import GeoBox\n",
    "from odc.algo import xr_reproject\n",
    "\n",
    "from rasterio import warp\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.transform import from_bounds\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook, show\n",
    "from bokeh.layouts import layout, column, row\n",
    "from bokeh.models import (CheckboxGroup, Select, ColumnDataSource, HoverTool, YearsTicker, Legend,\n",
    "                          CustomJS, LegendItem, field, Range1d, Circle, Button, RadioGroup, TextInput, WheelZoomTool,\n",
    "                          ResetTool, BoxZoomTool, SaveTool, LinearColorMapper, CategoricalColorMapper, \n",
    "                          Label, PreText, FileInput, Toggle, MultiPolygons)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.events import SelectionGeometry\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.palettes import Blues256\n",
    "from bokeh.colors import RGB, named\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only sandbox requires next two lines\n",
    "from dea_tools.dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required by bokeh\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drone imagery resample resolution\n",
    "# note to user: don't change it unless required\n",
    "# note to editor: change it whatever you want\n",
    "drone_res_tgt = (1, 1)\n",
    "# This is the Forel-Ule color scale \n",
    "furgb = np.array([\n",
    "        [1,33,88,188],\n",
    "        [2,49,109,197],\n",
    "        [3,50,124,187],\n",
    "        [4,75,128,160],\n",
    "        [5,86,143,150],\n",
    "        [6,109,146,152],\n",
    "        [7,105,140,134],\n",
    "        [8,117,158,114],\n",
    "        [9,123,166,84],\n",
    "        [10,125,174,56],\n",
    "        [11,149,182,69],\n",
    "        [12,148,182,96],\n",
    "        [13,165,188,118],\n",
    "        [14,170,184,109],\n",
    "        [15,173,181,95],\n",
    "        [16,168,169,101],\n",
    "        [17,174,159,92],\n",
    "        [18,179,160,83],\n",
    "        [19,175,138,68],\n",
    "        [20,164,105,5],\n",
    "        [21,161,44,4]], dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drone_tif(fname, res_tgt):\n",
    "    \"\"\"\n",
    "        load drone imagery with given file name and resolution\n",
    "        input:\n",
    "            fname: file name of drone imagery\n",
    "            res_tgt: resample resolution of output, type: tuple, e.g. res_tgt=(1, 1)\n",
    "        output:\n",
    "            xarray.DataSet of drone imagery\n",
    "        \n",
    "    \"\"\"\n",
    "    drone = xr.open_rasterio(fname, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "    drone = assign_crs(drone)\n",
    "    affine, width, height = warp.calculate_default_transform(drone.crs, 'EPSG:3577', drone.shape[1], drone.shape[2],\n",
    "                                             *drone.geobox.extent.boundingbox)\n",
    "    tgt_affine, tgt_width, tgt_height = warp.aligned_target(affine, width, height, res_tgt)\n",
    "    drone_geobox = GeoBox(tgt_width, tgt_height, tgt_affine, 'EPSG:3577')\n",
    "    drone_tgt = xr_reproject(drone, drone_geobox, resampling= 'bilinear' )\n",
    "    return drone_tgt.load()\n",
    "\n",
    "def load_results_tif(fname):\n",
    "    \"\"\"\n",
    "        load geotiff of classification results\n",
    "        input:\n",
    "            fname: file name of classification results\n",
    "        output:\n",
    "            xarray.DataSet of geotiff\n",
    "    \"\"\"\n",
    "    results = xr.open_rasterio(fname, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "    return results.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to user: just run it\n",
    "# note to editor: load drone imagery, convert to rgba image, set up coordinates and affine\n",
    "drone_tgt = load_drone_tif(drone_tif_path, drone_res_tgt)\n",
    "rgba_image = np.empty((drone_tgt.shape[1], drone_tgt.shape[2]), dtype='uint32')\n",
    "view = rgba_image.view(dtype='uint8').reshape(drone_tgt.shape[1], drone_tgt.shape[2], drone_tgt.shape[0])\n",
    "for i in range(3):\n",
    "    view[:, :, i] = (drone_tgt.data[i]).astype('uint8')\n",
    "view[:, :, 3] = 255\n",
    "scale_factor = np.array([drone_tgt.x.data.min(),\n",
    "                         drone_tgt.y.data.min() if drone_tgt.y.data.min() > 0 else drone_tgt.y.data.max()])\n",
    "xr_results = xr.DataArray(data=[np.zeros(rgba_image.shape, dtype='uint8')] * 2, dims=['band', 'y', 'x'], \n",
    "                     coords={'band': [1, 2], \n",
    "                     'y': drone_tgt.coords['y'], 'x':drone_tgt.coords['x']}, attrs={'nodata':0})\n",
    "select_poly_affine = from_bounds(drone_tgt.x.data.min()-scale_factor[0],\n",
    "                                 drone_tgt.y.data.max()-scale_factor[1], \n",
    "                                 drone_tgt.x.data.max()-scale_factor[0], \n",
    "                                 drone_tgt.y.data.min()-scale_factor[1],\n",
    "                                 drone_tgt.shape[2], drone_tgt.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to user: run it\n",
    "# note to editor: monstrous function required to redirect the bokeh interactive plot to a random jupyterlab port\n",
    "# or the jupyter notebook port via proxy\n",
    "def plot_doc(doc):\n",
    "    drone_source = ColumnDataSource(data={'img': [np.flip(rgba_image, axis=0)]})\n",
    "    results_source = ColumnDataSource(data={'category': [np.zeros(rgba_image.shape, dtype='uint8')],\n",
    "                                           'forel_ule': [np.zeros(rgba_image.shape, dtype='uint8')]})\n",
    "    \n",
    "    drone_file_input = TextInput(value=drone_tif_path, title=\"Load drone imagery\", height=50, width=600,\n",
    "                                sizing_mode='fixed')\n",
    "    def open_drone_tif(attrname, old, new):\n",
    "        fname = drone_file_input.value\n",
    "        if not path.exists(fname):\n",
    "            print(\"file doesn't exist!\")\n",
    "            return\n",
    "        drone_tgt = load_drone_tif(fname, drone_res_tgt)\n",
    "        rgba_image = np.empty((drone_tgt.shape[1], drone_tgt.shape[2]), dtype='uint32')\n",
    "        view = rgba_image.view(dtype='uint8').reshape(drone_tgt.shape[1], drone_tgt.shape[2], drone_tgt.shape[0])\n",
    "        for i in range(3):\n",
    "            view[:, :, i] = (drone_tgt.data[i]).astype('uint8')\n",
    "        view[:, :, 3] = 255\n",
    "        scale_factor = np.array([drone_tgt.x.data.min(),\n",
    "                         drone_tgt.y.data.min() if drone_tgt.y.data.min() > 0 else drone_tgt.y.data.max()])\n",
    "        drone_source.data['img'] = [np.flip(rgba_image, axis=0)]\n",
    "        global xr_results\n",
    "        xr_results = xr.DataArray(data=[np.zeros(rgba_image.shape, dtype='uint8')] * 2, dims=['band', 'y', 'x'], \n",
    "                     coords={'band': [1, 2], \n",
    "                     'y': drone_tgt.coords['y'], 'x':drone_tgt.coords['x']}, attrs={'nodata':0})\n",
    "        results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "        global select_poly_affine\n",
    "        select_poly_affine = from_bounds(drone_tgt.x.data.min()-scale_factor[0],\n",
    "                                 drone_tgt.y.data.max()-scale_factor[1], \n",
    "                                 drone_tgt.x.data.max()-scale_factor[0], \n",
    "                                 drone_tgt.y.data.min()-scale_factor[1],\n",
    "                                 drone_tgt.shape[2], drone_tgt.shape[1])\n",
    "        \n",
    "    drone_file_input.on_change('value', open_drone_tif)\n",
    "    \n",
    "    result_file_input = TextInput(value=results_tif_path, title=\"Results tiff file\", height=50, width=600,\n",
    "                                sizing_mode='fixed')\n",
    "    result_save_button = Button(label=\"Save results\", button_type=\"success\")\n",
    "    result_load_button = Button(label=\"Load results\", button_type=\"success\")\n",
    "    def open_result_tif(event):\n",
    "        fname = result_file_input.value\n",
    "        if not path.exists(fname):\n",
    "            print(\"file doesn't exist!\")\n",
    "            return\n",
    "        global xr_results\n",
    "        xr_results = load_results_tif(fname)\n",
    "        results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "        \n",
    "    def save_result_tif(event):\n",
    "        fname = result_file_input.value\n",
    "        if path.exists(fname):\n",
    "            time_now = str(datetime.now()).replace(':', '').replace(' ', '').replace('-', '')\n",
    "            os.rename(fname, fname + '.bak' + time_now)\n",
    "        write_cog(xr_results, fname)\n",
    "        \n",
    "    result_load_button.on_click(open_result_tif)\n",
    "    result_save_button.on_click(save_result_tif)\n",
    "    \n",
    "    drone_fig = figure(tooltips=[('x-cood', \"$x{0.0}\"), ('y-coord', \"$y{0.0}\")], title=\"image %s\" %(\"drone\"), \n",
    "            x_axis_type='auto', y_axis_type='auto', x_minor_ticks=10, y_minor_ticks=10,\n",
    "            x_axis_label=\"x origin %s\" % scale_factor[0],\n",
    "            y_axis_label=\"y origin %s\" % scale_factor[1],\n",
    "            tools=\"box_zoom, wheel_zoom, pan, tap, poly_select, reset\")\n",
    "    drone_fig.toolbar.active_scroll = drone_fig.select_one(WheelZoomTool)\n",
    "    drone_tag = ['drone', 1]\n",
    "    drone_fig.image_rgba(image='img', source=drone_source, \n",
    "                x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "               dw=drone_tgt.shape[2], dh=drone_tgt.shape[1],\n",
    "                         tags=drone_tag,\n",
    "                         level=\"image\")\n",
    "    transparent_white = RGB(255, 255, 255, 0)\n",
    "    cats_color = [named.hotpink.to_rgb(), named.limegreen.to_rgb(), named.purple.to_rgb(),\n",
    "                  named.deepskyblue.to_rgb(), named.darkgreen.to_rgb(), named.beige.to_rgb(),\n",
    "                  named.brown.to_rgb()]\n",
    "    cats_color_mapper = LinearColorMapper(cats_color, low=1, high=len(cats_color), low_color=transparent_white)\n",
    "    water_color = [RGB(f[1], f[2], f[3], 255) for f in furgb]\n",
    "    water_color_mapper = LinearColorMapper(water_color, low=1, high=21, low_color=transparent_white)\n",
    "    water_tag = ['forel_ule', 21]\n",
    "    cats_tag = ['cats', 10]\n",
    "    water_image = drone_fig.image(image='forel_ule', source=results_source, x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "                dw=drone_tgt.shape[2], dh=drone_tgt.shape[1], \n",
    "                color_mapper=water_color_mapper,\n",
    "                global_alpha=0.8,\n",
    "                level=\"image\", tags=water_tag)\n",
    "    \n",
    "    cats_image = drone_fig.image(image='category', source=results_source, x=drone_tgt.x.data.min()-scale_factor[0],\n",
    "                y=drone_tgt.y.data.min()-scale_factor[1],\n",
    "                dw=drone_tgt.shape[2], dh=drone_tgt.shape[1], \n",
    "                color_mapper=cats_color_mapper,\n",
    "                global_alpha=0.8,\n",
    "                level=\"image\", tags=cats_tag)\n",
    "   \n",
    "    coords_label = PreText(text=\"null\", width=100, sizing_mode='fixed')\n",
    "    select_poly_source = ColumnDataSource(data=dict(x=[[[[]]]], y=[[[[]]]]))\n",
    "    js_code = \"\"\"\n",
    "        if (cb_obj.final == false)\n",
    "        {\n",
    "            return;\n",
    "        }\n",
    "        const geometry = cb_obj.geometry;\n",
    "        const data = {'x': [[[[]]]], 'y': [[[[]]]]};\n",
    "        if (geometry.type == \"point\")\n",
    "        {\n",
    "            var ind_x = Math.floor(geometry.x);\n",
    "            var ind_y = Math.floor(geometry.y);\n",
    "            console.log(\"x:\", ind_x);\n",
    "            console.log(\"y:\", ind_y);\n",
    "            label.text = \"x=\" + ind_x.toString() +\";\" + \"y=\" + ind_y.toString();\n",
    "        }\n",
    "        else if (geometry.type == \"poly\")\n",
    "        {\n",
    "            var array_len = geometry.x.length;\n",
    "            for (var i=0; i<array_len; i++)\n",
    "            {\n",
    "                data['x'][0][0][0].push(Math.floor(cb_obj.geometry.x[i]));\n",
    "                data['y'][0][0][0].push(Math.floor(cb_obj.geometry.y[i]));\n",
    "            }\n",
    "            label.text = \"null\";\n",
    "            console.log(\"y:\", poly.data);\n",
    "        }\n",
    "        poly.data = data;\n",
    "    \"\"\"\n",
    "    js_callback = CustomJS(args={'label': coords_label, 'poly': select_poly_source}, \n",
    "                           code=js_code)\n",
    "    drone_fig.js_on_event(SelectionGeometry, js_callback)\n",
    "    select_poly = MultiPolygons(xs=\"x\", ys=\"y\", line_width=2)\n",
    "    drone_fig.add_glyph(select_poly_source, select_poly)\n",
    "        \n",
    "    def get_ind_from_coords():\n",
    "        ind_list = []\n",
    "        poly_list = []\n",
    "        if coords_label.text != \"null\":\n",
    "            coords = coords_label.text.split(';')\n",
    "            ind_list += [[abs(int(coords[1].split('=')[1])), abs(int(coords[0].split('=')[1]))]]\n",
    "            return ind_list\n",
    "        elif len(select_poly_source.data['x'][0][0][0]) > 0:\n",
    "            for x, y in zip(select_poly_source.data['x'][0][0][0], select_poly_source.data['y'][0][0][0]):\n",
    "                poly_list += [[x, y]]\n",
    "            poly_shape = Polygon(poly_list)\n",
    "            poly_mask = geometry_mask([poly_shape], out_shape=xr_results[0].data.shape,\n",
    "                                      transform=select_poly_affine, invert=True)\n",
    "            return np.flip(poly_mask, axis=0)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    cats = [\"NA\", \"Overstory\",\"Emergent\",\"Floating\",\"OpenWater\",\"GreenVeg\",\"DryVeg\",\"Bare\"]  \n",
    "    radio_group = RadioGroup(labels=cats, active=0, height=800, height_policy=\"fixed\", aspect_ratio=0.1)\n",
    "    forel_ule_scale = TextInput(value=\"0\", title=\"Forel-Ule Water Colour\", width=100, sizing_mode='fixed')  \n",
    "    def choose_cat(attrname, old, new):\n",
    "        ind_list = get_ind_from_coords()\n",
    "        if ind_list is None:\n",
    "            return\n",
    "        if attrname == 'active':\n",
    "            if isinstance(ind_list, list):\n",
    "                for ind_y, ind_x in ind_list:\n",
    "                    xr_results[0][ind_y, ind_x] = radio_group.active\n",
    "            else:\n",
    "                xr_results[0].data[ind_list] = radio_group.active\n",
    "            results_source.data['category'] = [np.flip(xr_results[0].data, axis=0)]\n",
    "        if attrname == 'value':  \n",
    "            check_numbers = re.match(r'^[0-9]+$', forel_ule_scale.value)\n",
    "            if check_numbers is None:\n",
    "                print(\"only input numbers\", forel_ule_scale.value)\n",
    "                forel_ule_scale.value = \"0\"\n",
    "            elif int(forel_ule_scale.value) < 0 or int(forel_ule_scale.value) > 21:\n",
    "                print(\"invalid value, please check!\")\n",
    "                forel_ule_scale.value = \"0\"\n",
    "            elif radio_group.active != 4 and int(forel_ule_scale.value) > 0:\n",
    "                forel_ule_scale.value = \"0\"\n",
    "                print(\"cannot set value for non-water\")\n",
    "            if isinstance(ind_list, list):\n",
    "                for ind_y, ind_x in ind_list:\n",
    "                    xr_results[1][ind_y, ind_x] = int(forel_ule_scale.value)\n",
    "            else:\n",
    "                xr_results[1].data[ind_list] = int(forel_ule_scale.value)\n",
    "            results_source.data['forel_ule'] = [np.flip(xr_results[1].data, axis=0)]\n",
    "            \n",
    "    radio_group.on_change('active', choose_cat)\n",
    "    forel_ule_scale.on_change('value', choose_cat)\n",
    "    \n",
    "    def coords_change(attrname, old, new):\n",
    "        ind_list = get_ind_from_coords()\n",
    "        if ind_list is None:\n",
    "            return\n",
    "        if isinstance(ind_list, list):\n",
    "            radio_group.active = xr_results[0].data[ind_list[0][0], ind_list[0][1]]\n",
    "            forel_ule_scale.value = str(xr_results[1].data[ind_list[0][0], ind_list[0][1]])\n",
    "        else:\n",
    "            radio_group.active = xr_results[0].data[ind_list][0]\n",
    "            forel_ule_scale.value = str(xr_results[1].data[ind_list][0])\n",
    "        \n",
    "    coords_label.on_change('text', coords_change)    \n",
    "    select_poly_source.on_change('data', coords_change)\n",
    "                  \n",
    "    overlay_toggle_category = Toggle(label=\"Overlay category\", button_type=\"success\",\n",
    "                                     height=50, width=150, sizing_mode='fixed', active=True)\n",
    "    overlay_toggle_water_color = Toggle(label=\"Overlay water color\", button_type=\"success\", \n",
    "                                        height=50, width=150, sizing_mode='fixed', active=True)\n",
    "    \n",
    "    def overlay_results(event):\n",
    "        if (overlay_toggle_water_color.active):\n",
    "            water_image.visible = True\n",
    "        else:\n",
    "            water_image.visible = False\n",
    "        if (overlay_toggle_category.active):\n",
    "            cats_image.visible = True\n",
    "        else:\n",
    "            cats_image.visible = False\n",
    "            \n",
    "    overlay_toggle_category.on_click(overlay_results)\n",
    "    overlay_toggle_water_color.on_click(overlay_results)\n",
    "    \n",
    "    control_group = column(coords_label, forel_ule_scale, radio_group)\n",
    "    result_group = row(result_file_input, column(result_load_button, result_save_button))\n",
    "    layouts = layout([drone_file_input, result_group, [overlay_toggle_category, overlay_toggle_water_color],\n",
    "                      [control_group, drone_fig]], sizing_mode='scale_height')\n",
    "    doc.add_root(layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remote_jupyter_proxy_url(port):\n",
    "    \"\"\"\n",
    "    Callable to configure Bokeh's show method when a proxy must be\n",
    "    configured.\n",
    "\n",
    "    If port is None we're asking about the URL\n",
    "    for the origin header.\n",
    "    \"\"\"\n",
    "    base_url = \"https://app.sandbox.dea.ga.gov.au/\"\n",
    "    host = urllib.parse.urlparse(base_url).netloc\n",
    "    # If port is None we're asking for the URL origin\n",
    "    # so return the public hostname.\n",
    "    if port is None:\n",
    "        return host\n",
    "\n",
    "    service_url_path = os.environ['JUPYTERHUB_SERVICE_PREFIX']\n",
    "    proxy_url_path = 'proxy/%d' % port\n",
    "\n",
    "    user_url = urllib.parse.urljoin(base_url, service_url_path)\n",
    "    full_url = urllib.parse.urljoin(user_url, proxy_url_path)\n",
    "    return full_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. If everything above worked, you should see your drone imagery below the next cell as well as an output file path and some green buttons.\n",
    "- When selecting polygons of multiple pixels, double-click to complete the polygon selection\n",
    "- Completing a new polygon will hide the old polygon\n",
    "- Hit the green `Save results` button frequently to make sure your results are saved during your session\n",
    "- You can switch between water color and category being displayed over your imagery by clicking `Overlay category` or `Overlay water color` buttons\n",
    "- You probably want to have your imagery open in a GIS on another screen to compare with this imagery while classifying, otherwise you'll be scrolling in and out a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you know your url\n",
    "# notebook_url = \"http://localhost:8888\"\n",
    "show(plot_doc, notebook_url=remote_jupyter_proxy_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** October 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`sandbox compatible`, :index:`bokeh`, :index:`COG`, :index:`classification`, :index:`DEA Sandbox`, :index:`drones`, :index:`Forel-Ule`, :index:`GeoTIFF`, :index:`inland water`,:index:`water`,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
