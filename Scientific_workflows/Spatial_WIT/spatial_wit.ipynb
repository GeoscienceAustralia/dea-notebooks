{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial display for Wetlands Insight Tool results <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatibility:** Notebook currently compatible with both the `NCI VDI` environment (data source: C2) and the `DEA sandbox` (data source: C3)\n",
    "\n",
    "\n",
    "* **Special requirements:** \n",
    "    * If running on the [NCI](https://nci.org.au/), ensure that `module load dea` is   run prior to launching this notebook\n",
    "    * Check you have the latest version of the `wit_tooling` package by \n",
    "      copying and pasting the following code into a cell below and running the cell\n",
    "    \n",
    "    `!pip install git+git://github.com/GeoscienceAustralia/wit_tooling`\n",
    "    * Check you have the `awswrangler` package, if not, copy and paste the following code into a cell below and run the cell\n",
    "    \n",
    "    `!pip install awswrangler`\n",
    "    * If running on the sandbox, you'll need `s3` credential to access the wit bucket storage\n",
    "      \n",
    "      \n",
    "* **Products used:** \n",
    "    * NCI VID\n",
    "        * Collection 2 Landsat Surface Reflectance: \n",
    "        [ls5_nbart_albers](https://explorer.dea.ga.gov.au/ls5_nbart_albers),\n",
    "        [ls7_nbart_albers](https://explorer.dea.ga.gov.au/ls7_nbart_albers),\n",
    "        [ls8_nbart_albers](https://explorer.dea.ga.gov.au/ls8_nbart_albers)\n",
    "        * Collection 2 Landsat Fractional Cover, \n",
    "        generated using the Joint Remote Sensing Research Program algorithm: \n",
    "        [ls5_fc_albers](https://explorer.dea.ga.gov.au/ls5_fc_albers),\n",
    "        [ls7_fc_albers](https://explorer.dea.ga.gov.au/ls7_fc_albers),\n",
    "        [ls8_fc_albers](https://explorer.dea.ga.gov.au/ls8_fc_albers)\n",
    "        * Water Observations from Space, \n",
    "        generated using the Geoscience Australia Algorithm:\n",
    "        [wofs_albers](https://explorer.sandbox.dea.ga.gov.au/wofs_albers)\n",
    "    * DEA Sandbox\n",
    "        * Collection 3 Landsat Surface Reflectance\n",
    "        * Collection 3 Landsat Fractional Cover\n",
    "        * Collection 3 Water Observations from Space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The Spatial Wetlands Insight Tool is a tool in development to display the coverage of water, \"wetness\" and vegetation fractional cover in a wetland spatially. It is generated off existing Wetlands Insight Tool temporal runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook uses an existing Wetlands Insight Tool temporal plot, \n",
    "generated from an existing WIT run, to create a spatial plot of water, \"wetness\", green/photosynthetic vegetation, dry/non-photosynthetic vegetation, and bare soil for a chosen observation date. \n",
    "\n",
    "1. First we load the existing WIT data from either: \n",
    "    * a saved csv location\n",
    "    * a shapefile to retrieve the existing WIT data from the database (NCI) or S3 bucket (sandbox) of previous runs\n",
    "    * a csv from an Amazon s3 data bucket\n",
    "2. Then we choose a time of interest to plot Spatial WIT\n",
    "3. Finally we output Spatial WIT to a file for each cover type\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook:\n",
    "-----------------------------\n",
    "* Follow the instructions under `Special Requirements` above to load `dea` and install `wit_tooling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary packages in this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fiona\n",
    "from datacube.utils.cog import write_cog\n",
    "import datacube\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook, show\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.models import (CheckboxGroup, Select, ColumnDataSource, HoverTool, YearsTicker, Legend,\n",
    "                          CustomJS, LegendItem, field, Range1d, Circle, Button, RadioGroup, TextInput, WheelZoomTool,\n",
    "                          ResetTool, BoxZoomTool, SaveTool, LinearColorMapper, Label)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.colors import RGB\n",
    "from bokeh.plotting import figure\n",
    "import datetime\n",
    "\n",
    "from os import path\n",
    "import os, sys, logging\n",
    "import seaborn as sns\n",
    "import ssl\n",
    "import urllib\n",
    "from wit_util import *\n",
    "from wit_tooling import load_wit_data, query_datasets, construct_product, load_wofs_fc, generate_raster, spatial_wit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "stdout_hdlr = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('[%(asctime)s.%(msecs)03d - %(levelname)s] %(message)s')\n",
    "stdout_hdlr.setFormatter(formatter)\n",
    "_LOG.addHandler(stdout_hdlr)\n",
    "_LOG.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "If you are using a shapefile, csv file, or Amazon s3 link to the existing WIT run, \n",
    "the path must be set in the cell below this cell:\n",
    "\n",
    "* `shapefile`: path to shapefile either on NCI (e.g. `'/g/data1a/r78/DEA_Wetlands/shapefiles/ramsar_wetlands_3577_20190403.shp'`), given you have permissions to the project directory, or\n",
    "\n",
    "    on sandbox (e.g. `'./sample_data/Ramsar_sthwest/ramsar_WIT_sthwest_3577.shp'`). The shapefile must be in [Australian Albers EPSG 3577 projection](https://spatialreference.org/ref/epsg/gda94-australian-albers/)\n",
    "* `csv_file`: path to WIT results CSV (e.g. `'/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'`) on NCI, not necessary on sandbox\n",
    "* `pd_yaml`: Yaml file necessary to generate WIT \n",
    "(e.g. `'/g/data/u46/users/ea6141/wit_tooling/aux/fc_pd.yaml'` for `C2`, and `'./sample_data/fc_pd_reproject.yaml'` for `C3`). \n",
    "Specifies input datasets.\n",
    "* `s3_url`: Amazon s3 url link to pre-generated WIT csvs (output from `C2`) folder \n",
    "(e.g. `'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/WIT_v3'`), not necessary if working with `C3` data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put global variables in this cell\n",
    "shapefile = './sample_data/Ramsar_sthwest/ramsar_WIT_sthwest_3577.shp'\n",
    "csv_file = '/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'\n",
    "pd_yaml = './sample_data/fc_pd_reproject.yaml'\n",
    "s3_url = 'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/mdba/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geotiff(spatial_wit_xr, filename, force=False):\n",
    "    \"\"\"\n",
    "        save spatial WIT result to geotiffs, each band will be output to individual tiff\n",
    "        input:\n",
    "            an xarray Dataset of spatial WIT\n",
    "            overwrite existing file if force=True, otherwise no output\n",
    "        output:\n",
    "            multiple cloud-optimized geotiffs (cogs) on disk\n",
    "    \"\"\"\n",
    "    for var in spatial_wit_xr.data_vars:       \n",
    "        #create file name per band\n",
    "        band_output = file_name + \"_\" + var + \".tif\"\n",
    "        if path.exists(band_output):\n",
    "            _LOG.warning(\"output geotif %s exists\", band_output)\n",
    "            if force:\n",
    "                _LOG.warning(\"existing geotif %s will be overwritten\", band_output)\n",
    "                os.remove(band_output)\n",
    "            else:\n",
    "                continue\n",
    "        spatial_wit_xr[var].attrs.update(spatial_wit_xr.attrs)\n",
    "        write_cog(spatial_wit_xr[var], band_output, blocksize=16)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WIT data using one of the methods in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list we wanna explore\n",
    "poly_candidates = {2: 2, 5: 5}\n",
    "# c3_s3 = False on NCI\n",
    "# c3_s3 = True on sandbox\n",
    "c3_s3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table and crawl metadata for db-like query\n",
    "if c3_s3:\n",
    "    import awswrangler as wr\n",
    "    import boto3\n",
    "    session = boto3.Session(profile_name='dev')\n",
    "    db_name = 'wit_test'\n",
    "    if db_name not in wr.catalog.databases(boto3_session=session).values:\n",
    "        wr.catalog.create_database(db_name, boto3_session=session)\n",
    "    table_ramsar = 'data_ramsar'\n",
    "    wit_path = \"s3://dea-wit-dev/c3-samples-3577/ramsar/all/\"\n",
    "    wr.s3.store_parquet_metadata(path=wit_path, database=db_name, table=table_ramsar, dataset=False, mode='overwrite', boto3_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: iterate over all possible loading routes,\n",
    "# i.e., database and csv on s3 (not responsible for local csv, users supposed to know)\n",
    "# load wit data from database with a chosen shape\n",
    "with fiona.open(shapefile) as allshapes:\n",
    "    shape_crs = allshapes.crs_wkt\n",
    "    shape_list = iter(allshapes)\n",
    "    while True:\n",
    "        shape = next(shape_list)\n",
    "        if int(shape['id']) == poly_candidates[2]:\n",
    "            break\n",
    "    polyName = shape['properties'].get('WetlandNam', '')\n",
    "    poly_outline = np.array(shape['geometry']['coordinates'][0])\n",
    "    if c3_s3:\n",
    "        wit_data = load_wit_s3(shape['geometry'], db_name, table_ramsar, session)\n",
    "        wit_data = wit_data.rename(columns={'time': 'utc_time', 'bs': 'bare', 'pv': 'green', 'npv': 'dry'})\n",
    "    else:\n",
    "        s3_filename = 'area_percent_' + shape['id'] + '_0.csv'\n",
    "        wit_data = load_wit_data(s3_url='/'.join([s3_url, s3_filename]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial wit for the chosen shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's helpful to get the location of data rather than load them\n",
    "# and it will save you time without querying database multiple times\n",
    "time_range = (wit_data.utc_time.min(), wit_data.utc_time.max())\n",
    "#build a product for our data using the yaml file to specify which datasets we need\n",
    "fc_product = construct_product(pd_yaml)\n",
    "datasets = query_datasets(fc_product, shape, shape_crs, time_range)\n",
    "_LOG.debug(\"Query datasets %s\", datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first time slice to init spatial wit plot\n",
    "_, idx_wit, idx_datasets = np.intersect1d(wit_data.utc_time.to_numpy().astype('datetime64[s]'), datasets.box.time.values.astype('datetime64[s]'), return_indices=True)\n",
    "time_slice = datasets.box.time.values[idx_datasets[0]]\n",
    "_LOG.debug(\"load time slice %s\", time_slice)\n",
    "if c3_s3:\n",
    "    fc_wofs_data = load_wofs_fc_c3(fc_product, datasets, time_slice)\n",
    "else:\n",
    "    fc_wofs_data = load_wofs_fc(fc_produce, datasets, time_slice)\n",
    "# mask by the geometry of given polygon\n",
    "# first parameter of generate_raster is a tuple of (shape geometry, [integer of shape id])\n",
    "mask = generate_raster([(shape['geometry'], int(shape['id']))], datasets.geobox)\n",
    "fc_wofs_perc = spatial_wit(fc_wofs_data, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't wanna comment or change this section on this instance\n",
    "# don't review this section for any non functionality essential occation\n",
    "def plot_doc(doc):\n",
    "    source = ColumnDataSource(data=wit_data)\n",
    "    for i in range(10):\n",
    "        source.data['dummy'+str(i)] = np.ones(source.data['utc_time'].shape) * i * 10\n",
    "\n",
    "    #set up color palate for bokeh WIT plot\n",
    "    pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "           sns.xkcd_rgb[\"neon blue\"],\n",
    "           sns.xkcd_rgb[\"grass\"],\n",
    "           sns.xkcd_rgb[\"beige\"],\n",
    "           sns.xkcd_rgb[\"brown\"]]  \n",
    "\n",
    "    #lets put a title on the plot\n",
    "    title =f'Percentage of area dominated by WOfS, Wetness, Fractional Cover for {polyName}'    \n",
    "\n",
    "    #set up the x axis to recognise date and time. Note that you will only see the days when you zoom in.\n",
    "    wit_plot = figure(plot_width=1200, \n",
    "              plot_height = 400, \n",
    "              x_axis_type='datetime',\n",
    "             title=title, tools=[\"box_select\", ResetTool(), BoxZoomTool(dimensions=\"width\")])\n",
    "    \n",
    "    hovernames = []\n",
    "    nonselected_circle = Circle(fill_alpha=0, fill_color=None, line_color=None)\n",
    "    for i in range(10):\n",
    "        circle_group_name = 'circlegroup' + str(i)\n",
    "        renderer = wit_plot.circle(y=\"dummy\" + str(i), x= 'utc_time', size=20, fill_color=None, \n",
    "                        line_alpha=0, source = source, muted_color=\"white\", muted_alpha=0, name=circle_group_name)\n",
    "        renderer.nonselection_glyph = nonselected_circle\n",
    "        hovernames.append(circle_group_name)\n",
    "    wit_plot.varea_stack(['water', \n",
    "                  'wet',\n",
    "                  'green',\n",
    "                  'dry',\n",
    "                  'bare'], x= 'utc_time', name = \"stackplot\", color=pal, fill_alpha=0.7, source = source, \n",
    "                  legend_label=[\"water\",\"wet\",\"green\",\"dry\",\"bare\"], muted_color=\"grey\", muted_alpha=0.2)\n",
    "    wit_plot.sizing_mode = \"scale_width\"\n",
    "\n",
    "    #align the title in the centre\n",
    "    wit_plot.title.align= \"center\"\n",
    "    wit_plot.title.text_font_size=\"12pt\"\n",
    "\n",
    "    #label axes\n",
    "    wit_plot.yaxis.axis_label=(\"percentage of polygon classified as type\")\n",
    "    wit_plot.yaxis.axis_label_text_font_size=\"8pt\"\n",
    "\n",
    "    #we need screen units to put the attribution label under the plot. Don't ask why.\n",
    "    label_opts = dict(\n",
    "        x=0, \n",
    "        y=0,\n",
    "        x_units='screen', \n",
    "        y_units='screen',\n",
    "        text_font_style=\"italic\", \n",
    "        text_font_size=\"8.5pt\")\n",
    "\n",
    "    #underplot context\n",
    "    msg1 = 'The Fractional Cover algorithm developed by the Joint Remote Sensing Research Program\\n\\\n",
    "    and the Water Observations from Space algorithm developed by Geoscience Australia are used in the production of this data'\n",
    "    caption1 = Label(text=msg1, **label_opts)\n",
    "\n",
    "    wit_plot.add_layout(caption1, 'below')\n",
    "\n",
    "    wit_plot.xaxis.formatter=DatetimeTickFormatter()\n",
    "    wit_plot.xaxis.ticker = YearsTicker(interval=1)\n",
    "    wit_plot.xaxis.major_label_orientation = 45\n",
    "    \n",
    "    #set the new WIT graph ranges.\n",
    "    left, right, bottom, top = source.data['utc_time'][0], source.data['utc_time'][-1], 0, 100 #set \n",
    "    wit_plot.x_range=Range1d(left, right)\n",
    "    wit_plot.y_range=Range1d(bottom, top)\n",
    "    wit_plot.xaxis.bounds=(left,right)\n",
    "    wit_plot.yaxis.bounds=(bottom,top)\n",
    "\n",
    "    #now we want to overplot the data on the plot\n",
    "    #create rectangle borders for no-data times (SLC-off only)\n",
    "    LS5_8_gap_start = datetime.datetime(2011,11,1)\n",
    "    LS5_8_gap_end = datetime.datetime(2013,4,1)\n",
    "\n",
    "    #plot our dead satellite rectangle\n",
    "    wit_plot.hbar(y=50, \n",
    "           height=100,\n",
    "           left=LS5_8_gap_start, \n",
    "           right=LS5_8_gap_end, \n",
    "           name =\"LS7 SLC-OFF\",\n",
    "           color=\"white\", \n",
    "           alpha=0.5, \n",
    "           hatch_color=\"white\", \n",
    "           hatch_pattern='/',\n",
    "           hatch_alpha=0.6,\n",
    "           line_color=\"white\",\n",
    "           line_width =2,\n",
    "           line_alpha=0.6)\n",
    "\n",
    "    wit_plot.legend.location=\"bottom_left\"\n",
    "    wit_plot.legend.background_fill_alpha=0.5\n",
    "    wit_plot.legend.border_line_alpha=0.5\n",
    "    wit_plot.legend.label_text_font_size=\"9pt\" \n",
    "\n",
    "    #reverse the legend \n",
    "    wit_plot.legend[0].items.reverse()\n",
    "    \n",
    "    wit_hover = HoverTool(names = hovernames,\n",
    "                      tooltips = [\n",
    "        (\"observation\", \"$index\"),\n",
    "        (\"date\", \"@utc_time{%F}\"),\n",
    "        (\"bare\",\"@bare{0.0}%\"),\n",
    "        (\"dry\", \"@dry{0.0}%\"),\n",
    "        (\"green\",\"@green{0.0}%\"),\n",
    "        (\"wet\",\"@wet{0.0}%\"),\n",
    "        (\"water\",\"@water{0.0}%\")],     \n",
    "                    formatters=\n",
    "        {\"@utc_time\":\"datetime\"})\n",
    "\n",
    "    #trialling different ways of getting the tools to work. Both adding tools and including in the figure work.\n",
    "    wit_plot.add_tools(wit_hover, WheelZoomTool(), SaveTool())\n",
    "    \n",
    "    # down below is interactivity between plots\n",
    "    # WARNING: DON'T MODIFY UNLESS YOU ABSOLUTELY KNOW WHAT YOU'RE DOING\n",
    "    def sw_update(attrname, old, new):\n",
    "        time_slice = new\n",
    "        if c3_s3:\n",
    "            _, idx_wit, idx_datasets = np.intersect1d(np.datetime64(time_slice, 's'), datasets.box.time.values.astype('datetime64[s]'), return_indices=True)\n",
    "            fc_wofs_data = load_wofs_fc_c3(fc_product, datasets,  datasets.box.time.values[idx_datasets[0]])\n",
    "        else:\n",
    "            fc_wofs_data = load_wofs_fc(fc_product, datasets, np.datetime64(time_slice))\n",
    "        fc_wofs_perc = spatial_wit(fc_wofs_data, mask)\n",
    "        for var in fc_wofs_perc.data_vars:\n",
    "            sw_source.data[var] = [np.flip(fc_wofs_perc[var].data[0], axis=0)]\n",
    "        sw_plot.title.text = \"Spatial wit for time %s\" % time_slice\n",
    "\n",
    "    datasets_time_source = ColumnDataSource(data=dict(time=pd.to_datetime(datasets.box.time.data).astype('str')))\n",
    "    wit_time_source = ColumnDataSource(data=dict(time=wit_data.utc_time.astype('str')))\n",
    "    selected_time_slice = ColumnDataSource(data=dict(time=[]))\n",
    "    time_select = Select(title=\"time slice\", value='', options=list(wit_time_source.data['time']), \n",
    "                         height=50, width=200, sizing_mode=\"fixed\")\n",
    "    time_select.on_change('value', sw_update)\n",
    "    \n",
    "    def minmax_time_update(attrname, old, new):\n",
    "        if radio_group.active == 0:\n",
    "            time_source = wit_time_source.data['time']\n",
    "        elif radio_group.active == 1:\n",
    "            time_source = datasets_time_source.data['time']\n",
    "        if minmax_time_input.value != \"\":\n",
    "            min_time = minmax_time_input.value.split(\";\")[0]\n",
    "            max_time = minmax_time_input.value.split(\";\")[1]\n",
    "            time_source = time_source[(time_source >= min_time) & (time_source <= max_time)]\n",
    "        time_source = list(time_source)\n",
    "        time_select.options = time_source\n",
    "        time_select.value = time_source[0]\n",
    "        \n",
    "    minmax_time_input = TextInput(value=\"\")\n",
    "    minmax_time_input.on_change('value', minmax_time_update)\n",
    "    \n",
    "    radio_group = RadioGroup(labels=[\"time slices from wit results\", \"time slices from available datasets\"], \n",
    "                             active=0, height=50, width=250, sizing_mode='fixed')\n",
    "    radio_group.on_change('active', minmax_time_update)\n",
    "    \n",
    "    js_code = \"\"\"\n",
    "        const inds=cb_obj.indices;\n",
    "        if (inds.length == 0) {\n",
    "            target_minmax.value = \"\"\n",
    "            return\n",
    "        }\n",
    "        var min_index = inds[0];\n",
    "        var max_index = inds[0];\n",
    "        var data_s = source.data;\n",
    "        for (var i=0; i<inds.length; i++) {\n",
    "            max_index = Math.max(max_index, inds[i]);\n",
    "            min_index = Math.min(min_index, inds[i]);\n",
    "        }\n",
    "        target_minmax.value = data_s['time'][min_index] + \";\" + data_s['time'][max_index];\n",
    "    \"\"\"\n",
    "    js_callback = CustomJS(args={'source': wit_time_source, 'target_minmax': minmax_time_input}, \n",
    "                           code=js_code)\n",
    "    source.selected.js_on_change('indices', js_callback)\n",
    "    \n",
    "    def reset_time_selection(event):\n",
    "        if radio_group.active == 0:\n",
    "            options_input = wit_time_source.data['time']\n",
    "        elif radio_group.active == 1:\n",
    "            options_input = datasets_time_source.data['time']\n",
    "        time_select.options = list(options_input)\n",
    "        minmax_time_input.value = \"\"\n",
    "        \n",
    "    reset_button = Button(label='reset time selection', height=50, width=80, sizing_mode='fixed', button_type='success')\n",
    "    reset_button.on_click(reset_time_selection)\n",
    "    # above is interactivity between plots\n",
    "    \n",
    "    # down below is spatial wit plot\n",
    "    image_list = {}\n",
    "    color_map_dict = {}\n",
    "    # all below is to setup the pallete\n",
    "    transparent_white = RGB(255, 255, 255, 0)\n",
    "    colbat_blue = [RGB(3, 10, 167, 1)]\n",
    "    neon_blue = [RGB(4, 217, 255, 1)]\n",
    "    grass_green = [RGB(63, 155, 11, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "    soil_brown = [RGB(96, 70, 15, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "    dry_biege = [RGB(230, 218, 166, t) for t in np.arange(0.1, 1, 0.1) ]\n",
    "    var_colors = [soil_brown, grass_green, dry_biege, neon_blue, colbat_blue]\n",
    "    for var, cm in zip(fc_wofs_perc.data_vars, var_colors):\n",
    "        image_list[var] = [np.flip(fc_wofs_perc[var].data[0], axis=0)]\n",
    "        color_map_dict[var] = LinearColorMapper([transparent_white]+cm, low=0, high=100,\n",
    "                                   nan_color=transparent_white)\n",
    "    sw_source = ColumnDataSource(data=image_list)\n",
    "\n",
    "    # do the image plot\n",
    "    if c3_s3:\n",
    "        tooltips = [\n",
    "            (\"x\", \"$x\"),\n",
    "            (\"y\", \"$y\"),\n",
    "            (\"bare\",\"@bs\"),\n",
    "            (\"dry\", \"@npv\"),\n",
    "            (\"green\",\"@pv\"),\n",
    "            (\"wet\",\"@TCW\"),\n",
    "            (\"water\",\"@water\")]\n",
    "    else:\n",
    "        tooltips = [\n",
    "            (\"x\", \"$x\"),\n",
    "            (\"y\", \"$y\"),\n",
    "            (\"bare\",\"@BS\"),\n",
    "            (\"dry\", \"@NPV\"),\n",
    "            (\"green\",\"@PV\"),\n",
    "            (\"wet\",\"@TCW\"),\n",
    "            (\"water\",\"@water\")]\n",
    "    sw_plot = figure(plot_width=900, plot_height = 900,\n",
    "             tooltips = tooltips)\n",
    "    \n",
    "\n",
    "    for var in fc_wofs_perc.data_vars:\n",
    "        sw_plot.image(image=var, source=sw_source, x=fc_wofs_data.x.data.min(), y=fc_wofs_data.y.data.min(),\n",
    "            dh=(fc_wofs_data.y.data.max() - fc_wofs_data.y.data.min()),\n",
    "            dw=(fc_wofs_data.x.data.max() - fc_wofs_data.x.data.min()),\n",
    "            color_mapper = color_map_dict[var])\n",
    "    sw_plot.line(poly_outline[:,0], poly_outline[:,1], line_width=3)\n",
    "    sw_plot.y_range.update(start=poly_outline[:,1].min(), end=poly_outline[:,1].max())\n",
    "    sw_plot.x_range.update(start=poly_outline[:,0].min(), end=poly_outline[:,0].max())\n",
    "    \n",
    "    sw_plot.title.text = \"Spatial wit at time %s\" % time_slice\n",
    "    sw_plot.title.text_font_size=\"12pt\"\n",
    "    # above is spatial wit plot\n",
    "    \n",
    "    layouts = layout([[radio_group, time_select, reset_button],\n",
    "        [wit_plot],[sw_plot]\n",
    "        ], sizing_mode='scale_both')\n",
    "    doc.add_root(layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remote_jupyter_proxy_url(port):\n",
    "    \"\"\"\n",
    "    Callable to configure Bokeh's show method when a proxy must be\n",
    "    configured.\n",
    "\n",
    "    If port is None we're asking about the URL\n",
    "    for the origin header.\n",
    "    \"\"\"\n",
    "    base_url = \"https://app.sandbox.dea.ga.gov.au/\"\n",
    "    host = urllib.parse.urlparse(base_url).netloc\n",
    "    # If port is None we're asking for the URL origin\n",
    "    # so return the public hostname.\n",
    "    if port is None:\n",
    "        return host\n",
    "\n",
    "    service_url_path = os.environ['JUPYTERHUB_SERVICE_PREFIX']\n",
    "    proxy_url_path = 'proxy/%d' % port\n",
    "\n",
    "    user_url = urllib.parse.urljoin(base_url, service_url_path)\n",
    "    full_url = urllib.parse.urljoin(user_url, proxy_url_path)\n",
    "    \n",
    "    return full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if c3_s3:\n",
    "    notebook_url = remote_jupyter_proxy_url\n",
    "else:\n",
    "    notebook_url = \"http://localhost:8889\"\n",
    "    \n",
    "show(plot_doc, notebook_url=notebook_url)\n",
    "#notebook_url is the server address of jupyter notebook, change accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spatial WIT as geotiff\n",
    "# each variable will be output to individual COG\n",
    "# file_name works as prefix, the final output file name will be \"file_name_bandname\", e.g. \"test_BS.tif\"\n",
    "# by default force=False := not overwriting existing geotif\n",
    "file_name = \"test_\" + str(time_slice)\n",
    "save_geotiff(fc_wofs_perc, file_name, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** 17th May 2021\n",
    "\n",
    "**Compatible datacube version:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.4.dev73+g9e22ff5c\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags**: :index:`no_testing`,:index:`NCI compatible`,:index:`sandbox compatible`, :index:`landsat 5`, :index:`landsat 7`,  :index:`landsat 8`, :index:`dea_plotting`, :index:`time series`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
