{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C3 FC percentile validation\n",
    "\n",
    "* [**Sign up to the DEA Sandbox**](https://docs.dea.ga.gov.au/setup/sandbox.html) to run this notebook interactively from a browser\n",
    "* **Compatibility:** Notebook currently compatible with the`DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[fc_percentile_albers_annual](https://explorer.sandbox.dea.ga.gov.au/products/fc_percentile_albers_annual), \n",
    "C3 fc percentile test product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The notebook is to validate the new C3 fc percentile product against the C2 product `fc_percentile_albers_annual`. It produced the output for the validation report.\n",
    "\n",
    "1. Generate distritubtions and plot PDFs as the validation results\n",
    "2. Produce the summary of validation results\n",
    "3. Plot examples of the findings\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Install the package needed by\n",
    "\n",
    "`!pip install awswrangler`\n",
    "\n",
    "in the top cell or the terminal then restart notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import rasterio\n",
    "import boto3\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import re\n",
    "from datacube.utils.dask import start_local_dask\n",
    "from datacube import Datacube\n",
    "from osgeo import ogr, gdal, osr\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.stats as sps\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a local cluster\n",
    "client = start_local_dask(n_workers=1, threads_per_worker=7, memory_limit='56GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `dev` is the credential profile name\n",
    "# change it accordingly\n",
    "session = boto3.Session(profile_name='dev')\n",
    "fc_bucket = \"s3://dea-public-data-dev/test/fc-percentile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the available file paths/prefix\n",
    "fc_x_dirs = wr.s3.list_directories(fc_bucket, boto3_session=session)\n",
    "fc_file_dirs = []\n",
    "for x_idx in fc_x_dirs:\n",
    "    fc_file_dirs += wr.s3.list_directories(x_idx, boto3_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://dea-public-data-dev/test/fc-percentile/x12/y19/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x12/y20/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x14/y29/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x15/y29/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x17/y19/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x17/y20/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x17/y37/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x18/y19/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x18/y20/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x18/y37/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x19/y25/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x20/y25/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x24/y40/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x27/y42/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x27/y43/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x28/y31/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x28/y42/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x28/y43/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x31/y40/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x33/y25/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x35/y21/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x35/y22/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x35/y29/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x36/y22/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x37/y20/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x37/y21/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x37/y36/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x38/y15/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x38/y20/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x38/y21/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x38/y37/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x39/y13/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x39/y15/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x39/y38/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x40/y07/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x40/y13/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x40/y38/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x41/y07/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x42/y37/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x42/y38/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x43/y14/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x43/y15/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x43/y35/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x44/y15/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x44/y16/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x44/y17/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x45/y16/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x45/y17/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x46/y17/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x47/y25/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x49/y23/',\n",
       " 's3://dea-public-data-dev/test/fc-percentile/x49/y24/']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_file_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seamask(shape_file, data_shape, orig_coords, resolution):\n",
    "    \"\"\"\n",
    "        creak mask without oceans\n",
    "        input:\n",
    "            shape_file: the shape file of Australia coastline\n",
    "            data_shape: the shape of loaded data to be masked upon\n",
    "            orig_coords: the origin of the image for gdal to decide the transform\n",
    "            resolution: pixel size with signs, e.g., (30, -30) for C3 and (25, -25) for C2\n",
    "        output:\n",
    "            a numpy array of mask, where valid pixels = 1\n",
    "    \"\"\"\n",
    "    source_ds = ogr.Open(shape_file)\n",
    "    source_layer = source_ds.GetLayer()\n",
    "    source_layer.SetAttributeFilter(\"FEAT_CODE!='sea'\")\n",
    "\n",
    "    yt, xt = data_shape\n",
    "    xres = resolution[0]\n",
    "    yres = resolution[1]\n",
    "    no_data = 0\n",
    "\n",
    "    xcoord, ycoord = orig_coords\n",
    "    geotransform = (xcoord - (xres*0.5), xres, 0, ycoord - (yres*0.5), 0, yres)\n",
    "\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xt, yt, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform(geotransform)\n",
    "    albers = osr.SpatialReference()\n",
    "    albers.ImportFromEPSG(3577)\n",
    "    target_ds.SetProjection(albers.ExportToWkt())\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    band.SetNoDataValue(no_data)\n",
    "\n",
    "    gdal.RasterizeLayer(target_ds, [1], source_layer, burn_values=[1])\n",
    "    return band.ReadAsArray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(input_array, pixel_size, size_div=150*150):\n",
    "    \"\"\"\n",
    "        randomly sample the data with replacement\n",
    "        input:\n",
    "            input_array: the array of data to sample\n",
    "            pixel_size: area of a pixel, e.g., 30^2 for C3 and 25^2 for C2\n",
    "            size_div: area which includes integer numbers of pixels for both C2 and C3, default 150^2\n",
    "        output:\n",
    "            mean and variance of the random samples\n",
    "    \"\"\"\n",
    "    sample_mean = 0\n",
    "    sample_var = 0\n",
    "    tmp_array = input_array.reshape(-1)\n",
    "    tmp_array = tmp_array[~np.isnan(tmp_array)]\n",
    "    size_d = size_div / pixel_size * 1e3\n",
    "    batches = tmp_array.size // size_d\n",
    "    for i in range(int(batches*2)):\n",
    "        sample_array = tmp_array[np.random.randint(0, int(tmp_array.size), int(size_d))]\n",
    "        sample_mean += sample_array.mean()\n",
    "        sample_var += np.var(sample_array)\n",
    "    return (sample_mean/batches/2, sample_var/batches/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Generate mean and variance for each grid in the list\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Datacube()\n",
    "var_list = [\"pv_pc_\", \"npv_pc_\", \"bs_pc_\"]\n",
    "perc_list = [\"10\", \"50\", \"90\"]\n",
    "i = 0\n",
    "pd_columns = []\n",
    "for v in var_list:\n",
    "    for p in perc_list:\n",
    "        pd_columns += [v+p+'_mean']\n",
    "        pd_columns += [v+p+'_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the path/prefix of all the test grids\n",
    "for f_dir in fc_file_dirs:\n",
    "    dataset = None\n",
    "    for i in range(1987, 2021):\n",
    "        # get the path/prefix of every year for the grid\n",
    "        non_empty_list = wr.s3.list_objects(f_dir + str(i), boto3_session=session, suffix=['tif'])\n",
    "        if non_empty_list == []:\n",
    "            continue\n",
    "        tmp_set = []\n",
    "        # load all the data into dask array and named by the year\n",
    "        for o in non_empty_list:\n",
    "            data = xr.open_rasterio(o, chunks={'x':3200, 'y':3200})\n",
    "            data.name = re.findall(r'(?<=P1Y_)\\w+', o)[0]\n",
    "            tmp_set += [data]\n",
    "        # make the xarray the similar format as C2\n",
    "        tmp_set = xr.merge(tmp_set)\n",
    "        tmp_set = tmp_set.rename_dims({'band': 'time'})\n",
    "        tmp_set = tmp_set.rename_vars({'band': 'time'})\n",
    "        tmp_set.time.data[0] = i\n",
    "        if dataset is None:\n",
    "            dataset = tmp_set\n",
    "        else:\n",
    "            dataset = xr.concat([dataset, tmp_set], dim='time')\n",
    "    # mask nodata\n",
    "    re_c3 = dataset.where(dataset.qa==2, 0)\n",
    "    # query and load C2 by the geolocation of grid\n",
    "    query = {'time':('1987-01-01', '2021-01-01'), 'x': (re_c3.x.data.min() - 15, re_c3.x.data.max() + 15), 'y': (re_c3.y.data.min() - 15, re_c3.y.data.max() + 15), 'crs': 'EPSG:3577'}\n",
    "    c2_data = dc.load(product='fc_percentile_albers_annual', **query, dask_chunks={'time':1})\n",
    "    # mask nodata\n",
    "    re_c2 = c2_data.where(c2_data > -1, 0)\n",
    "    \n",
    "    # generate raster of oceans mask\n",
    "    c2_land_raster = generate_seamask(\"aus_map/cstauscd_r_3577.shp\", re_c2.PV_PC_10.shape[1:], (re_c2.x.data.min(), re_c2.y.data.max()), (25, -25))\n",
    "    c3_land_raster = generate_seamask(\"aus_map/cstauscd_r_3577.shp\", re_c3.pv_pc_10.shape[1:], (re_c3.x.data.min(), re_c3.y.data.max()), (30, -30))\n",
    "    # init panda dataframe to save the results\n",
    "    results_c2 = pd.DataFrame(columns=pd_columns, index=np.arange(1987, 2021))\n",
    "    results_c3 = pd.DataFrame(columns=pd_columns, index=np.arange(1987, 2021))\n",
    "    \n",
    "    print(\"start load data\")\n",
    "    re_c3.load()\n",
    "    re_c2.load()\n",
    "    # compute mean and variance for each band and each year\n",
    "    for y in range(1987, 2021):\n",
    "        for v in var_list:\n",
    "            for p in perc_list:\n",
    "                results_c3.loc[y, v+p+'_mean'], results_c3.loc[y, v+p+'_var'] = random_samples(re_c3[v+p].loc[dict(time=y)].where(c3_land_raster > 0, 0).data, 30**2)\n",
    "                results_c2.loc[y, v+p+'_mean'], results_c2.loc[y, v+p+'_var'] = random_samples(re_c2[v.upper()+p].loc[dict(time=str(y)+'-01-01')].where(c2_land_raster > 0, 0).data, 25**2)\n",
    "    # save the results to csvs\n",
    "    # named after grid index and product version, e.g., x14_y29_c2.csv\n",
    "    results_c2.to_csv('_'.join(f_dir.split('/')[-3:-1])+'_c2.csv')\n",
    "    results_c3.to_csv('_'.join(f_dir.split('/')[-3:-1])+'_c3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Plot PDFs of each grid with the mean and variance saved in csvs\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_dir in fc_file_dirs:\n",
    "    tile_name = '_'.join(f_dir.split('/')[-3:-1])\n",
    "    if os.path.exists(tile_name+'.png'):\n",
    "        continue\n",
    "    # read in results from csvs\n",
    "    results_c2 = pd.read_csv(tile_name+'_c2.csv', index_col=0)\n",
    "    results_c3 = pd.read_csv(tile_name+'_c3.csv', index_col=0)\n",
    "    fig, axs = plt.subplots(34, 9,  sharey=True, sharex=True, figsize=(20, 60))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    # plot PDFs for each year and each band\n",
    "    for y in range(1987, 2021):\n",
    "        for v in var_list:\n",
    "            for p in perc_list:\n",
    "                x = np.arange(results_c3.loc[y, v+p+'_mean']-3*np.sqrt(results_c3.loc[y, v+p+'_var']), results_c3.loc[y, v+p+'_mean']+3*np.sqrt(results_c3.loc[y, v+p+'_var']), 1)\n",
    "                axs[j, i].plot(norm.pdf(x, results_c3.loc[y, v+p+'_mean'], np.sqrt(results_c3.loc[y, v+p+'_var'])), label='C3 distribution', color='darkblue')\n",
    "                x = np.arange(results_c2.loc[y, v+p+'_mean']-3*np.sqrt(results_c2.loc[y, v+p+'_var']), results_c2.loc[y, v+p+'_mean']+3*np.sqrt(results_c2.loc[y, v+p+'_var']), 1)\n",
    "                axs[j, i].plot(norm.pdf(x, results_c2.loc[y, v+p+'_mean'], np.sqrt(results_c2.loc[y, v+p+'_var'])), label='C2 distribution', color='darkorange')\n",
    "                # set title of columns of plotting grid\n",
    "                if j == 0:\n",
    "                    axs[j, i].set_title(v+p)\n",
    "                # set title of rows of plotting grid\n",
    "                if i == 0:\n",
    "                    axs[j, i].set_ylabel(str(y), rotation=90, size='large')\n",
    "                i += 1\n",
    "        j += 1\n",
    "        i = 0\n",
    "    plt.tight_layout()\n",
    "    # plot legends shared by all subplots\n",
    "    handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper left')\n",
    "    fig.savefig(tile_name+'.png')\n",
    "    print(\"plot\", tile_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.. Plot the summary of the validation results\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to summarize\n",
    "mean_columns = []\n",
    "for v in var_list:\n",
    "    for p in perc_list:\n",
    "        mean_columns += [v+p+'_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot the difference of mean for all testing grids in the list\n",
    "fig, axs = plt.subplots(3, 3,  sharey=True, sharex=True, figsize=(6, 6))\n",
    "for f_dir in fc_file_dirs:\n",
    "    tile_name = '_'.join(f_dir.split('/')[-3:-1])\n",
    "    if tile_name in ['x40_y13', 'x43_y15', 'x45_y17']:\n",
    "        continue\n",
    "    # read in the results saved in the csvs\n",
    "    results_c2 = pd.read_csv(tile_name+'_c2.csv', index_col=0)\n",
    "    results_c3 = pd.read_csv(tile_name+'_c3.csv', index_col=0)\n",
    "    # compute the difference of mean for all the bands\n",
    "    mean_diff = results_c3[mean_columns] - results_c2[mean_columns]\n",
    "    i = 0\n",
    "    j = 0\n",
    "    # scatter plot the differences\n",
    "    for v in var_list:\n",
    "        for p in perc_list:\n",
    "            axs[i, j].plot(mean_diff[v+p+'_mean'], 'o', color='SteelBlue',  mfc='none', markersize=3)\n",
    "            # set title of columns of plotting grid\n",
    "            if i == 0:\n",
    "                axs[i, j].set_title('pc_'+str(p))\n",
    "            # set title of rows of plotting grid\n",
    "            if j == 0:\n",
    "                axs[i, j].set_ylabel(v.split('_')[0], rotation=90, size='large')\n",
    "            j += 1\n",
    "        i += 1\n",
    "        j = 0\n",
    "# mark the crutial time points\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i, j].axvline(x=1987, linestyle='--', color='darkgreen', label='1987 LS5 start')\n",
    "        axs[i, j].axvline(x=1999, linestyle='--', color='darkblue', label='1999 LS5/LS7 switch')\n",
    "        axs[i, j].axvline(x=2003, linestyle='--', color='darkorange', label='2003 LS7 broken')\n",
    "        axs[i, j].axvline(x=2013, linestyle='--', color='OliveDrab', label='2013 LS8 start')\n",
    "# plot the legends shared by all subplots\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "fig.savefig(\"all_tiles_mean_diff.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histgram plot for the difference of mean for all testing grids in the list\n",
    "fig, axs = plt.subplots(3, 3,  sharey=True, sharex=True, figsize=(6, 6))\n",
    "mean_diff = None\n",
    "# compute the difference of mean for all grids\n",
    "for f_dir in fc_file_dirs:\n",
    "    tile_name = '_'.join(f_dir.split('/')[-3:-1])\n",
    "    if tile_name in ['x40_y13', 'x43_y15', 'x45_y17']:\n",
    "        continue\n",
    "    results_c2 = pd.read_csv(tile_name+'_c2.csv', index_col=0)\n",
    "    results_c3 = pd.read_csv(tile_name+'_c3.csv', index_col=0)\n",
    "    if mean_diff is None:\n",
    "        mean_diff = results_c3[mean_columns] - results_c2[mean_columns]\n",
    "    else:\n",
    "        mean_diff = mean_diff.append(results_c3[mean_columns] - results_c2[mean_columns])\n",
    "i = 0\n",
    "j = 0\n",
    "for v in var_list:\n",
    "    for p in perc_list:\n",
    "        # histgram plot for each band\n",
    "        axs[i, j].hist(mean_diff[v+p+'_mean'].to_numpy(), color='SteelBlue', bins=50, density=True)\n",
    "        kde = sps.gaussian_kde(mean_diff[v+p+'_mean'].to_numpy())\n",
    "        axs[i, j].plot(np.arange(-20, 20, 0.1), kde.pdf(np.arange(-20, 20, 0.1)), color='darkorange', linestyle='--', linewidth=1)\n",
    "        if i == 0:\n",
    "            axs[i, j].set_title('pc_'+str(p))\n",
    "        if j == 0:\n",
    "            axs[i, j].set_ylabel(v.split('_')[0], rotation=90, size='large')\n",
    "        j += 1\n",
    "    i += 1\n",
    "    j = 0\n",
    "fig.savefig(\"all_tiles_hist.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.. Plot FC percentile band of any testing grid\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fc percentile band as required\n",
    "# reading data is the same as in the loop of computation above\n",
    "f_dir = fc_bucket + 'x45/y17/'\n",
    "dataset = None\n",
    "for i in range(1987, 2021):\n",
    "    non_empty_list = wr.s3.list_objects(f_dir + str(i), boto3_session=session, suffix=['tif'])\n",
    "    if non_empty_list == []:\n",
    "        continue\n",
    "    tmp_set = []\n",
    "    for o in non_empty_list:\n",
    "        data = xr.open_rasterio(o, chunks={'x':3200, 'y':3200})\n",
    "        data.name = re.findall(r'(?<=P1Y_)\\w+', o)[0]\n",
    "        tmp_set += [data]\n",
    "    tmp_set = xr.merge(tmp_set)\n",
    "    tmp_set = tmp_set.rename_dims({'band': 'time'})\n",
    "    tmp_set = tmp_set.rename_vars({'band': 'time'})\n",
    "    tmp_set.time.data[0] = i\n",
    "    if dataset is None:\n",
    "        dataset = tmp_set\n",
    "    else:\n",
    "        dataset = xr.concat([dataset, tmp_set], dim='time')\n",
    "re_c3 = dataset.where(dataset.qa==2)\n",
    "query = {'time':('1987-01-01', '2021-01-01'), 'x': (re_c3.x.data.min() - 15, re_c3.x.data.max() + 15), 'y': (re_c3.y.data.min() - 15, re_c3.y.data.max() + 15), 'crs': 'EPSG:3577'}\n",
    "c2_data = dc.load(product='fc_percentile_albers_annual', **query, dask_chunks={'time':1})\n",
    "re_c2 = c2_data.where(c2_data > -1)\n",
    "\n",
    "c2_land_raster = generate_seamask(\"aus_map/cstauscd_r_3577.shp\", re_c2.PV_PC_10.shape[1:], (re_c2.x.data.min(), re_c2.y.data.max()), (25, -25))\n",
    "c3_land_raster = generate_seamask(\"aus_map/cstauscd_r_3577.shp\", re_c3.pv_pc_10.shape[1:], (re_c3.x.data.min(), re_c3.y.data.max()), (30, -30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the valid data for a band\n",
    "re_c3.pv_pc_10.loc[dict(time=2018)].where(c3_land_raster > 0).compute().plot(aspect=1.5, size=10)\n",
    "plt.savefig('x45y17_2018_c3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title too long for C2, drop spatial_ref: 3577\n",
    "re_c2 = re_c2.drop_vars('spatial_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the valid data for a band\n",
    "re_c2.PV_PC_10.loc[dict(time='2018-01-01')].where(c2_land_raster > 0).compute().plot(aspect=1.5, size=10)\n",
    "plt.savefig('x45y17_2018_c2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** August 2021\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.4.dev81+g80d466a2\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags**: :index:`sandbox compatible`, :index:`landsat 8`, :index:`landsat 7`, :index: `landsat 5`, :index: `fc percentile`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
