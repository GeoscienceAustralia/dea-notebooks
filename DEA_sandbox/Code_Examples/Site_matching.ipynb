{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching satellite images to field samples <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI`|`DEA Sandbox` environment only\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "An important aspect of working with satellite data is linking it to physical processes and features of the Earth. \n",
    "A key technical aspect of this is the ability to easily identify the satellite data that is closest in time and space to when measurements are made on the ground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook covers how to return a measurement of the Normalised Difference Chlorophyll Index (NDCI) for the pixel closest to a sampling location that measured the concentration of Chlorophyll-*a*.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "from datacube.utils.geometry import CRS, point\n",
    "import dask\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import xarray as xr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from utils.dea_datahandling import load_ard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Give your datacube app a unique name. \n",
    "Ideally, this will be the same as the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Site_matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "* `sample_loc_file`: Name and location of the csv file containing sampling locations with corresponding latitudes and longitudes (e.g. `../Supplementary_data/Site_matching/locations.csv`).\n",
    "* `sample_data_file`: Name and location of the csv file containing sampling dates for each location and sample measurements (e.g. `../Supplementary_data/Site_matching/dates.csv`).\n",
    "* `obs_window`: Number of days from the ground observation to search for a matching satellite image (e.g. `7`). The window is applied both before and after the ground observation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loc_file = (\"utils/chlorophyll_sampling_coorong_locations.csv\")\n",
    "sample_date_file = (\"utils/chlorophyll_sampling_coorong_dates.csv\")\n",
    "obs_window = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the location csv\n",
    "locations = pd.read_csv(sample_loc_file)\n",
    "\n",
    "# View the first 5 entries\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observations csv\n",
    "observations = pd.read_csv(sample_date_file)\n",
    "\n",
    "# View the first 5 entries\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the closest satellite data in time and space\n",
    "* for each site:\n",
    "    * loop over each date and extract key satellite band values and the computed NDCI at the pixel closest to the specified lat,lon of the site\n",
    "    * return no observations if the closest date is more than +/-`obs_window` days out\n",
    "    * record the valid results\n",
    "* return a single file containing all valid results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all site dates to loop over\n",
    "site_dates = observations[\"Date\"].values\n",
    "\n",
    "# Define the satellite products to search and measurements to return\n",
    "products = [\"s2a_ard_granule\", \"s2b_ard_granule\"]\n",
    "measurements = [\"nbart_red_edge_1\", \"nbart_red\"]\n",
    "\n",
    "# Construct empty lists to store data\n",
    "red_values = []\n",
    "rededge_values = []\n",
    "ndci_values = []\n",
    "time_deltas = []\n",
    "site_names = []\n",
    "match_values = []\n",
    "match_dates = []\n",
    "\n",
    "# Loop over all sites\n",
    "for site in locations.itertuples():\n",
    "    # Extract information from locations table\n",
    "    site_latitude = site.Lat\n",
    "    site_longitude = site.Long\n",
    "    site_name = site.SiteName\n",
    "    site_count = site.Index + 1\n",
    "\n",
    "    print(f\"Processing site: {site_name}\")\n",
    "\n",
    "    # Extract the ground observations for the current site\n",
    "    site_values = observations.iloc[:, site_count].to_list()\n",
    "\n",
    "    # Convert from (long, lat) to (x, y) for finding nearest pixel to site\n",
    "    site_point_ll = point(site_longitude, site_latitude, crs=CRS(\"EPSG:4326\"))\n",
    "    site_xy = site_point_ll.to_crs(CRS(\"EPSG:3577\")).points[0]\n",
    "    site_x = site_xy[0]\n",
    "    site_y = site_xy[1]\n",
    "\n",
    "    # Generate area to search over by adding buffer in degrees\n",
    "    buffer = 0.001\n",
    "    search_lon = (site_longitude - buffer, site_longitude + buffer)\n",
    "    search_lat = (site_latitude - buffer, site_latitude + buffer)\n",
    "\n",
    "    # Find all Sentinel-2 timesteps for selected area\n",
    "    # Load with dask, meaning that data won't be loaded until\n",
    "    # an exact value needs to be returned\n",
    "    ds_s2 = load_ard(\n",
    "        dc,\n",
    "        products=products,\n",
    "        measurements=measurements,\n",
    "        x=search_lon,\n",
    "        y=search_lat,\n",
    "        output_crs=\"EPSG:3577\",\n",
    "        resolution=(-10, 10),\n",
    "        lazy_load=True,\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Loop over all dates to identify closest data within 7 days\n",
    "    for count, date_string in enumerate(site_dates):\n",
    "        # Get the date to compare to\n",
    "        target_date = datetime.strptime(date_string, \"%d/%m/%Y\")\n",
    "\n",
    "        # Isolate the timestep that is closest to the sample date\n",
    "        ds_closest = ds_s2.sel(time=target_date, method=\"nearest\")\n",
    "\n",
    "        # Calculate the time-difference between sample date and closest date\n",
    "        time_delta = np.abs(pd.to_datetime(target_date) - ds_closest.time.values)\n",
    "\n",
    "        if time_delta.days <= obs_window:\n",
    "            # Isolate the pixel that is closest to the site location\n",
    "            ds_closest = ds_closest.sel(x=site_x, y=site_y, method=\"nearest\")\n",
    "\n",
    "            # Calculate the NDCI from the Red Edge and Red bands\n",
    "            ds_closest[\"ndci\"] = (ds_closest.nbart_red_edge_1 - ds_closest.nbart_red) / (ds_closest.nbart_red_edge_1 + ds_closest.nbart_red)\n",
    "\n",
    "            # If NDCI value is not NaN, and the site value is not NaN, record the entries\n",
    "            if (np.isnan(ds_closest.ndci.values.item()) == False) and (np.isnan(site_values[count]) == False):\n",
    "                # Append appropriate values to list\n",
    "                site_names.append(site_name)\n",
    "                match_dates.append(target_date)\n",
    "                match_values.append(site_values[count])\n",
    "                ndci_values.append(round(ds_closest.ndci.values.item(), 4))\n",
    "                red_values.append(ds_closest.nbart_red.values.item())\n",
    "                rededge_values.append(ds_closest.nbart_red_edge_1.values.item())\n",
    "                time_deltas.append(int(time_delta.days))\n",
    "\n",
    "# Compile all valid results into a Pandas table\n",
    "location_results = pd.DataFrame(\n",
    "    {\n",
    "        \"SiteName\": site_names,\n",
    "        \"ObservationDate\": match_dates,\n",
    "        \"TimeDelta\": time_deltas,\n",
    "        \"ObservationValue\": match_values,\n",
    "        \"Red\": red_values,\n",
    "        \"RedEdge\": rededge_values,\n",
    "        \"NDCI\": ndci_values,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save valid results to a csv\n",
    "file_path = \"MatchedData.csv\"\n",
    "location_results.to_csv(file_path, na_rep=\"NaN\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform linear regression and calculate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(location_results[\"NDCI\"]).reshape(-1, 1)\n",
    "y = location_results[\"ObservationValue\"]\n",
    "\n",
    "x_lin = np.linspace(np.min(X), np.max(X), 100).reshape(-1, 1)\n",
    "\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X, y)\n",
    "\n",
    "predictions = lm.predict(x_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_results.plot.scatter(x=\"NDCI\", y=\"ObservationValue\")\n",
    "plt.plot(x_lin, predictions, \"k\")\n",
    "plt.title(\"Linear fit\")\n",
    "plt.xlabel(\"NDCI\")\n",
    "plt.ylabel(\"Chlorophyll-a Concentration (mg/L)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_rsq = lm.score(X, y)\n",
    "spearman_rho = spearmanr(X, y).correlation\n",
    "\n",
    "print(\"Linear fit results\")\n",
    "print(f\"Pearson's R^2 = {pearson_rsq}\")\n",
    "print(f\"Spearman's rho = {spearman_rho}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform polynomial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = location_results[\"NDCI\"]\n",
    "\n",
    "poly_func = np.poly1d(np.polyfit(x, y, deg=2))\n",
    "poly_coeff, poly_ssqres, _, _, _ = np.polyfit(x, y, deg=2, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_results.plot.scatter(x=\"NDCI\", y=\"ObservationValue\")\n",
    "plt.plot(x_lin, poly_func(x_lin), \"k\")\n",
    "plt.title(\"Polynomial Fit\")\n",
    "plt.xlabel(\"NDCI\")\n",
    "plt.ylabel(\"Chlorophyll-a Concentration (mg/L)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ssqtot = np.sum((y - np.mean(y))**2)\n",
    "poly_pearson_rsq = 1 - poly_ssqres/poly_ssqtot\n",
    "\n",
    "print(\"Polynomial fit results\")\n",
    "print(f\"Pearson's R^2 = {poly_pearson_rsq[0]}\")\n",
    "print(f\"Spearman's rho = {spearman_rho}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** October 2019\n",
    "\n",
    "**Compatible `datacube` version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`sentinel 2`, :index:` landsat 8`, :index:`dea_plotting`, :index:`rgb`, :index:`NDVI`, :index:`time series`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
