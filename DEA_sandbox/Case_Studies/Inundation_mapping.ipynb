{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping inundation according to flow rates \n",
    "* **Compatability:** Notebook currently compatible with both the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[wofs_albers](https://explorer.sandbox.dea.ga.gov.au/wofs_albers),\n",
    "[BoM's Water Data Online](http://www.bom.gov.au/waterdata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Many of Australia's water bodies are regulated by humans. \n",
    "Flows are controlled by regulatory bodies such as the Murray Darling Basin Authority and local governments to meet the needs of water users while maintaining ecosystems dependant on the surface water. \n",
    "It is important that regulators know where the water goes when it goes overbank to help manage wetland inundations for environmental purposes and be informed of rural or residential areas likely to be flooded as a result of a large dam release. \n",
    "\n",
    "Gauges have been placed along river systems all over Australia to monitor flow rates and water levels, however tracking where water goes when it spills over bank at a certain rate is challenging without combining the gauge data with satellite data.  \n",
    "\n",
    "### Digital Earth Australia use case \n",
    "The [Water Observations from Space (WOfS)](https://www.ga.gov.au/scientific-topics/community-safety/flood/wofs) dataset detects surface water in Australia based on Landsat data. \n",
    "By linking this dataset with gauge data, we can get information on where the water goes when it goes overbank according to flow rates measured by the gauge. \n",
    "Being able to see where water goes at different flow rates is valuable information for water regulators. \n",
    "\n",
    "## Description\n",
    "In this example, we take gauge data from the Bureau of Meteorology (BOM) [Water Data Online](http://www.bom.gov.au/waterdata/) webpage and link it to WOfS data to create a summary image of water frequency according to a user-specified flow rate. \n",
    "The worked example demonstrates how to:\n",
    "\n",
    "1. Generate a Flow Duration Curve from stream gauge data\n",
    "2. Use Dask loading to link the WOfS dataset to the stream gauge data\n",
    "3. Call WOfS data by flow rate as opposed to chronological time range\n",
    "4. Cloud mask WOfS data\n",
    "5. Generate a frequency image of water from the WOfS data\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "**To run this analysis**, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and supporting functions for the analysis. This notebook relies on a module called `dea_bom`, which is located in the `Scripts` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "sys.path.append('utils')\n",
    "import dea_bom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Inundation_mapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve stream gauge data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This box retrieves data from the Bureau of Meteorology (BOM) [Water Data Online](http://www.bom.gov.au/waterdata/) webpage using the `dea_bom` module.\n",
    "We restrict the list of gauges to locations that we have identified as having valid data. Please note that the data in this example is cached. If you wish to access the live BOM website, you will need to go into the utils folder and delete or move the file called stations.pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_pkl = Path('utils/stations.pkl')\n",
    "\n",
    "# If cache exists, get station data from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "\n",
    "# Filter list to stations with available data\n",
    "stations_with_data = pickle.load(open(str('utils/stations_with_data.pkl'), 'rb'))\n",
    "stations = [i for i in stations if i.name in stations_with_data]\n",
    "\n",
    "# Preview the first five stations loaded\n",
    "print(f'{len(stations)} stations loaded; e.g.:')\n",
    "stations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a map of stations and select a gauge that contains data\n",
    "\n",
    "Running this cell will generate a map displaying the locations of stream gauges in Australia. It will take about 20 seconds to load. Choose a gauge on the map by clicking on it. Note that after you click on a gauge it can take a second or two to respond. \n",
    "\n",
    "When you have the station you want, **click the Done button before moving onto the next box**. If you want to choose a different gauge after having pressed the `Done` button, you must re-run this box to regenerate the map then choose another gauge and press `Done` again. \n",
    "\n",
    "> **Note:** If all gauges you click on return \"0 observations\", this could indicate an issue with fetching data from the BOM webpage. In this case, re-start the notebook and try again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations,\n",
    "                                                zoom=10,\n",
    "                                                center=(-34.72, 143.17));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a flow duration curve from the data selected above\n",
    "A flow duration curve is a way of displaying flow rate data that is often used by hydrologists to characterise a river. \n",
    "Flows for each day are ranked from highest to lowest flow on the y-axis. \n",
    "The x-axis is \"exceedence\", which means \"the percentage of the time the river was at that flow or higher\", with the formula for the x-axis being `1-(rank/number of data points) * 100`. \n",
    "A flow duration curve is useful for this application as it allows the user to select satellite data by flow rate rather than by date. \n",
    "\n",
    "The code in the box below will automatically select the latitude and longitude of the selected gauge, but you can enter a different `lat` and `lon` if you want by editing the commented out `lat` and `lon` lines in the code below. \n",
    "The output will tell you what `lat` and `lon` has been selected. \n",
    "The `buffer`, which is the radius around the location point, is set to 8000 meters but you can change it if you like.\n",
    "\n",
    "> **Note:** If nothing happens when you run this cell, **return to the previous cell and click the Done button**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lat and lon takes the location of the gauge. You can change the lat \n",
    "# and lon to a different location if necessary, just comment out out this \n",
    "# lat, lon = pos line below and define your own.\n",
    "lat, lon = station.pos\n",
    "\n",
    "# lat =\n",
    "# lon =\n",
    "\n",
    "# The buffer is how many meters radius around the location you want to display.\n",
    "buffer = 8000\n",
    "\n",
    "# Rearranging data into a flow duration curve\n",
    "gauge_data = gauge_data.dropna()\n",
    "gauge_data = gauge_data.sort_values('Value')\n",
    "gauge_data['rownumber'] = np.arange(len(gauge_data))\n",
    "gauge_data['Exceedence'] = (1 - (gauge_data.rownumber / len(gauge_data))) * 100\n",
    "\n",
    "# Plotting the flow duration curve\n",
    "gauge_data.plot(x='Exceedence', y='Value', figsize=(11, 7))\n",
    "plt.ylabel('Cubic meters per second')\n",
    "plt.grid(True)\n",
    "plt.title('FDC')\n",
    "\n",
    "print(f'You have selected: lat = {lat}')\n",
    "print(f'You have selected: lon = {lon}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the y-axis parameters in cubic meters per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What part of the Flow Duration Curve do you want to look at?\n",
    "yaxis_lower_parameter = 250\n",
    "yaxis_higher_parameter = 1750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the flow duration curve on a log scale allows us to better understand the extremeties of the flow rates. \n",
    "The next cell displays the selected part of the flow duration curve on a log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data on a log scale\n",
    "gauge_data.plot(x='Exceedence',\n",
    "                y='Value',\n",
    "                logy=True,\n",
    "                title='Selected range displayed on a log scale',\n",
    "                figsize=(11, 7))\n",
    "plt.axhspan(yaxis_lower_parameter,\n",
    "            yaxis_higher_parameter,\n",
    "            color='red',\n",
    "            alpha=0.2)\n",
    "plt.ylabel('Cubic meters per second (log)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask loading WOfS data\n",
    "The next cell uses `Dask` to load only the parameters of the WOfS data without loading the images, which is a faster way to load WOfS data. \n",
    "Loading only the parameters is enough to link the WOfS dataset to the dataset from the stream gauge. \n",
    "The data are linked by date using `xarray`'s `.interp()` function. \n",
    "The code then takes into account the flow rate parameters entered by the user and creates a list of dates where there was a satellite pass while the gauge was reading that value. \n",
    "The output tells the user how many passes there were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up a query which defines the area and time period to load data for\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('1988-01-01', '2019-10-01'), # Change this date accordingly\n",
    "         'crs': 'EPSG:3577'} \n",
    "\n",
    "# Dask load wofs_albers data (this loads the dataset parameters only, \n",
    "# not the actual satellite data)\n",
    "wofs_albers = dc.load(product = 'wofs_albers', \n",
    "                      dask_chunks = {}, \n",
    "                      group_by='solar_day', \n",
    "                      **query)\n",
    "\n",
    "# Merging satellite data with gauge data by timestamp\n",
    "gauge_data_xr = gauge_data.to_xarray()\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time, method='nearest')\n",
    "\n",
    "# Here is where it takes into account user input for the FDC\n",
    "specified_level = merged_data.where((merged_data.Value > yaxis_lower_parameter) & \n",
    "                                    (merged_data.Value < yaxis_higher_parameter), \n",
    "                                    drop=True)\n",
    "\n",
    "# Get list of dates to keep\n",
    "date_list = specified_level.time.values\n",
    "\n",
    "print(f'You are about to load {specified_level.time.shape[0]} satellite passes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cloud masking the selected WOfS data\n",
    "The box below will load the selected WOfS images with `.compute()` and then cloud filter the images, meaning it will take out images that had too much cloud to see anything. \n",
    "It does this by using the `.make_mask()` function to calculate the fraction of cloud pixels in each image.\n",
    "The output will tell you how many passes remain after they were cloud filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the passes that happened during the specified flow parameters\n",
    "specified_passes = wofs_albers.sel(time=date_list).compute()\n",
    "\n",
    "# Calculate the number of cloudy pixels per timestep\n",
    "cc = masking.make_mask(specified_passes.water, cloud=True)\n",
    "ncloud_pixels = cc.sum(dim=['x', 'y'])\n",
    "\n",
    "# Calculate the total number of pixels per timestep\n",
    "npixels_per_slice = (specified_passes.water.shape[1] * \n",
    "                     specified_passes.water.shape[2])\n",
    "\n",
    "# Calculate the proportion of cloudy pixels\n",
    "cloud_pixels_fraction = (ncloud_pixels / npixels_per_slice)\n",
    "\n",
    "# Filter out \"too cloudy\" passes (i.e. more than 50% cloud)\n",
    "clear_specified_passes = specified_passes.water.isel(\n",
    "    time=cloud_pixels_fraction < 0.5)\n",
    "\n",
    "print(f'After cloud filtering, there are '\n",
    "      f'{clear_specified_passes.time.shape[0]} passes available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an image of the waterbody based on flow\n",
    "This cell will generate a water frequency image for the selected location using the passes indicated above. \n",
    "One large plot is generated for easy viewing. \n",
    "A small plot next to the flow duration curve with the selected parameters is generated to remind the user which part of flow duration curve the images relates to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all wet and dry pixels\n",
    "wet = masking.make_mask(clear_specified_passes, wet=True).sum(dim='time')\n",
    "dry = masking.make_mask(clear_specified_passes, dry=True).sum(dim='time')\n",
    "\n",
    "# Calculate how frequently each pixel was wet when it was observed\n",
    "clear = wet + dry\n",
    "frequency = wet / clear\n",
    "\n",
    "# Remove persistent NAs that occur due to mountain shadows\n",
    "frequency = frequency.fillna(0)  \n",
    "\n",
    "# Set pixels that remain dry 100% of the time to nodata so they appear white\n",
    "frequency = frequency.where(frequency != 0)  \n",
    "\n",
    "# Plotting the image\n",
    "fig, axes = plt.subplots(nrows=1, \n",
    "                         ncols=2, \n",
    "                         figsize=(14, 9), \n",
    "                         gridspec_kw={'width_ratios': [3, 1]})\n",
    "frequency.plot(ax=axes[0])\n",
    "axes[0].set_title('Water frequency\\n(percentage of wet observations)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot the gauge data\n",
    "gauge_data.plot(ax=axes[1], x='Exceedence', y='Value', logy=True, legend=False) \n",
    "axes[1].axhspan(ymin=yaxis_lower_parameter, \n",
    "                ymax=yaxis_higher_parameter, \n",
    "                color='red', \n",
    "                alpha=0.2)\n",
    "axes[1].set_title('Specified range for which the\\nimage was generated (FDC log)')\n",
    "axes[1].set_ylabel('Cubic meters per second (log)')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file as a GeoTIFF\n",
    "You might want to use this water frequency image in another workflow.\n",
    "The following code will export the image as a `.tif` GeoTIFF file that can be loaded into common GIS software (e.g. ArcMap or QGIS). \n",
    "\n",
    "Enter a name for the `.tif` file below. \n",
    "The `../` part of the name means it will save this file one directory up from where this notebook is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output file name \n",
    "file_name = '../file_name_here.tif'\n",
    "\n",
    "# Set up the file for writing\n",
    "frequency_dataset = frequency.to_dataset()\n",
    "frequency_dataset.attrs=wofs_albers.attrs\n",
    "\n",
    "# Write GeoTIFF to a location\n",
    "write_geotiff(file_name, frequency_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** November 2019\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`WOfS`, :index:`dea_bom`, :index:`get_stations`, :index:`ui_select_station`, :index:`time series`, :index:`image compositing`, :index:`GeoTIFF`, :index:`exporting data`, :index:`external data`, :index:`interactive`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
