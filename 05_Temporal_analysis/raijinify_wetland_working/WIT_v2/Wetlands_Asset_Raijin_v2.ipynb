{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow:\n",
    "    - take notebook of most updated code for WIT\n",
    "    - copy bits into this notebook\n",
    "    - when this notebook runs\n",
    "    - merge cells and copy into the merged_cells notebook\n",
    "    - then test that \n",
    "    - then remove defaults and run on raijin   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you run this on raijin:\n",
    "-remove defaults #DesiredChunks and #part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of wetland edits\n",
    "\n",
    "push to github every time you change one of these!!!!\n",
    "- wofs bit flags - include low angle wofs\n",
    "- check for 90% coverage of shape, not just load\n",
    "- if no data, redo load with no 90% thing, then monthly aggregate before checking for coverage\n",
    "-  tighten graph and increase text size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T22:48:07.501507Z",
     "start_time": "2019-02-19T22:48:07.425278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape file is /g/data/r78/rjd547/Ramsar_Wetlands/shapefiles/ExplodedRAMSAR.shp\n"
     ]
    }
   ],
   "source": [
    "# #!/usr/bin/python\n",
    "\n",
    "\n",
    "# | Authors:  | Bex Dunn|\n",
    "# |----------|----------------|\n",
    "# | Created: | Jan 7, 2019 |\n",
    "# | Last edited: | April 16,2019 |\n",
    "\n",
    "\n",
    "#  Before running this script load these modules:\n",
    "# `module use /g/data/v10/public/modules/modulefiles` \n",
    "# `module load dea`\n",
    "# This code is designed to run on raijin, on the Australian NCI. \n",
    "# The shell script to run this code has a *.sh extension\n",
    "\n",
    "# changelog: incorporated wofs with terrain + low sensor angle shadow, otherwise we miss areas that are visibly\n",
    "#            wet during winter months. This may cause issues in wetlands surrounded by terrain or veg that can \n",
    "#            shadow the surface and make it appear wet in indices.\n",
    "#          : changed the no-data behaviour. We are now visualising as proportion of visible pixels, where the \n",
    "#            data within a box surrounding the query returned 90% good data. \n",
    "\n",
    "# \n",
    "# This code takes a supplied shapefile of a polygon and queries Digital Earth\n",
    "# Australia http://geoscienceaustralia.github.io/digitalearthau/\n",
    "# for WOfS, Fractional Cover and NBART. It calculates thresholded tasselled cap wetness. The dominant result for\n",
    "# each pixel is calculated and the percentage area of the polygon covered by water, wet vegetation, \n",
    "# photosynthetic vegetation, non-photosynthetic vegetation and bare soil is output into a jpg stacked plot and to\n",
    "# csv. The resulting data can be used to monitor changes in wetland behaviour spatiotemporally. \n",
    "\n",
    "# - Input Datasets:\n",
    "# - Landsat 5\n",
    "# - Landsat 7\n",
    "# - Landsat 8\n",
    "\n",
    "# -- Fractional Cover --\n",
    "# - PV - Photosythetic vegetation\n",
    "# - NPV - Non-Photosythetic vegetation\n",
    "# - BS - Bare Soil\n",
    "\n",
    "# - WOfS Feature Layers (WOFLs)\n",
    "\n",
    "# __Future Work:__ \n",
    "# - do this by max extent of wetness        \n",
    "\n",
    "### Import Statements: import the modules we need ------------------------------\n",
    "\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "\n",
    "#$#$#$#$#$\n",
    "\n",
    "import datacube\n",
    "import datetime\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "from shapely import geometry\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "#keep the plotting modules in here as we want to output the stackplots to *.jpg\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "from digitalearthau.utils import wofs_fuser\n",
    "\n",
    "#append path to dea notebooks scripts to the system so we can access it\n",
    "sys.path.append('/g/data/r78/rjd547/jupyter_notebooks/dea-notebooks/10_Scripts')\n",
    "import DEADataHandling, DEAPlotting, TasseledCapTools\n",
    "\n",
    "# setup the datacube \n",
    "dc = datacube.Datacube(app='wetlands insight tool')\n",
    "\n",
    "### Set up polygon\n",
    "poly_path='/g/data/r78/rjd547/Ramsar_Wetlands/shapefiles/ExplodedRAMSAR.shp'\n",
    "print(f'Shape file is {poly_path}')\n",
    "\n",
    "#part = sys.argv[1] #take an argument from the command line (our parallelish scripte)\n",
    "#part = int(part)\n",
    "#print(f'system argument received is {part}')\n",
    "\n",
    "# #Desired number of chunks\n",
    "# if len(sys.argv)<3:\n",
    "#     print('Usage: this script takes 2 arguments - update your submission script')\n",
    "# #DesiredChunks = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T22:48:07.501507Z",
     "start_time": "2019-02-19T22:48:07.425278Z"
    }
   },
   "outputs": [],
   "source": [
    "#defaults \n",
    "#part =19 #coburg\n",
    "#part = 15 #vic lakes\n",
    "part = 8 #hattah lakes \n",
    "DesiredChunks=64\n",
    "\n",
    "global Output_dir\n",
    "Output_dir = '/g/data/r78/rjd547/Ramsar_Wetlands/Ramsar_Outputs_3_v2/'\n",
    "\n",
    "# add in a delay between dc.load calls to avoid overloading the database - 5 seconds in this case\n",
    "time.sleep(5*part)\n",
    "#open the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T22:48:07.501507Z",
     "start_time": "2019-02-19T22:48:07.425278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk size is 5\n",
      "There are 54 generated chunks\n",
      "Running for polygon IDs in the range 35 to 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20190329/lib/python3.6/site-packages/fiona/collection.py:336: FionaDeprecationWarning: Collection slicing is deprecated and will be disabled in a future version.\n",
      "  return self.session.__getitem__(item)\n"
     ]
    }
   ],
   "source": [
    "#this code tells us which polygon ids will be running on this particular (node?). Shapessubset will be the subset of polygons that our function\n",
    "#will run over. \n",
    "with fiona.open(poly_path) as allshapes:\n",
    "        #get the crs of the polygon file to use when processing each polygon\n",
    "        crs = geometry.CRS(allshapes.crs_wkt)\n",
    "        #get the list of all the shapes in the shapefile\n",
    "        ShapesList = list(allshapes)\n",
    "        ChunkSize = ceil(len(ShapesList)/DesiredChunks) #this was set due to Claire having 64000 polygons in her code\n",
    "        print(f'chunk size is {ChunkSize}')\n",
    "        print(f'There are {int(len(ShapesList)/ChunkSize)} generated chunks')\n",
    "        shapessubset = allshapes[(part - 1) * ChunkSize: part * ChunkSize]\n",
    "        print(f'Running for polygon IDs in the range {(part - 1) * ChunkSize} to {part * ChunkSize}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions that are run in the mainline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RAMSAR_polyName(shapefile):\n",
    "    ''' function designed specifically for the RAMSAR wetlands australia shapefile. Takes the shapefile and extracts\n",
    "    the ramsar name, wetland name and objectID from the ESRI shapefile format and turns it into a useful string for our output.\n",
    "    :Inputs: shapefile with RAMSAR_NAM, WETLAND_NA, and OBJECTID as properties. \n",
    "    Author: Bex Dunn Last Edited: March 2019'''\n",
    "    # get the ramsar name from the shapes \n",
    "    RAMSAR_NAME = '_'.join(shapefile['properties']['RAMSAR_NAM'].split(' '))\n",
    "    WETLAND_NAME = '_'.join(shapefile['properties']['WETLAND_NA'].split(' '))\n",
    "    STATE = '_'.join(shapefile['properties']['STATE'].split(' ')) \n",
    "    ID = shapefile['id']\n",
    "    polyName = f'{RAMSAR_NAME}-{WETLAND_NAME}-{STATE}-{ID}'\n",
    "    print(f'processing polygon {polyName}')\n",
    "    return(polyName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_ls578_data(query, geom):\n",
    "    '''create a function that takes in the masked proportion, query and geometry and returns the fully masked surface reflectance data'''\n",
    "    ## Set up datasets\n",
    "    #set cloudmasking threshold and load landsat nbart data\n",
    "    landsat_masked_prop = 0.90\n",
    "    ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart',\n",
    "            masked_prop=landsat_masked_prop)\n",
    "\n",
    "    ### mask the data with our original polygon to remove extra data \n",
    "\n",
    "    data = ls578_ds\n",
    "    mask = rasterio.features.geometry_mask([geom.to_crs(data.geobox.crs)for geoms in [geom]],\n",
    "                                               out_shape=data.geobox.shape,\n",
    "                                               transform=data.geobox.affine,\n",
    "                                               all_touched=False,\n",
    "                                               invert=False)\n",
    "\n",
    "    #for some reason xarray is not playing nicely with our old masking function\n",
    "    mask_xr = xr.DataArray(mask, dims = ('y','x'))\n",
    "    ls578_ds = data.where(mask_xr==False)\n",
    "    return ls578_ds, mask_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_tcw(sr_data, mask, threshold=-350):\n",
    "    '''uses TasseledCapTools and an input threshold (defaults to -350) to create masked over-threshold tasseled cap '''\n",
    "\n",
    "    #transform the nbart into tci\n",
    "    tci = TasseledCapTools.thresholded_tasseled_cap(sr_data,wetness_threshold=-350, drop=True , drop_tc_bands=True)\n",
    "\n",
    "    #select only finite values (over threshold values)\n",
    "    tcw = xr.ufuncs.isfinite(tci.wetness_thresholded)\n",
    "\n",
    "    # #reapply the polygon mask\n",
    "    tcw = tcw.where(mask==False)\n",
    "\n",
    "    return tcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BigBadFunkyFunction(lilshape,crs):\n",
    "    '''This is a function that does lots of things. It takes a single polygon and does all the things #FIXME '''\n",
    "### This is set up to be shapefile-specific. I'm not sure this can be avoided, as often shapefiles are pretty specific..\n",
    "    try:\n",
    "        first_geometry = lilshape['geometry']\n",
    "        polyName = get_RAMSAR_polyName(lilshape)\n",
    "        geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "        query = {'geopolygon': geom}#, 'time': ('2001-01-01', '2003-01-01') }# this should run for all time, if there is no time set?\n",
    "        #load and mask data. selecting data with more than 90% clear for the geobox around the polygon... #FIXME\n",
    "        ls578_ds, mask_xr= get_masked_ls578_data(query,geom)\n",
    "        print('running tasselled cap transform')\n",
    "        #calculate tasselled cap wetness within masked AOI\n",
    "        tcw = get_masked_tcw(ls578_ds, mask_xr, threshold=-350)\n",
    "        print('ran tasselled cap transform')\n",
    "        ### load wofls and select only wet pixels\n",
    "        print('loading wofls')\n",
    "\n",
    "        #wofls = dc.load(product = 'wofs_albers', like=ls578_ds, fuse_func=wofs_fuser)\n",
    "        wofls = dc.load(product = 'wofs_albers',fuse_func=wofs_fuser, **query)\n",
    "        #match wofs to tcw, because we didn't filter wofs for slc-off yet\n",
    "        wofls = wofls.where(wofls.time==tcw.time)\n",
    "        # #reapply the polygon mask\n",
    "        wofls = wofls.where(mask_xr==False)\n",
    "        #use bit values in wofs to select wet observations\n",
    "        wet_wofs = wofls.where(wofls.water==128)\n",
    "        #but also get the terrain and low-angle shadow wofs for this application\n",
    "        shadow_wofs = wofls.where(wofls.water== 136) #use bit values for wet (128) and terrain/low-angle (8)\n",
    "        print('wet and shadowed wofls acquired')\n",
    "\n",
    "        #------\n",
    "        #create a combined wofs dataset to mask fractional cover with\n",
    "        all_wofs=wet_wofs.copy(deep=True)\n",
    "        #fill wet_wofs with shadow_wofs, where wet_wofs is nan\n",
    "        combined_wofs = all_wofs.fillna(shadow_wofs)\n",
    "\n",
    "\n",
    "        ### load in fractional cover data\n",
    "        print('loading fractional cover data')\n",
    "        #load the data according to our query\n",
    "        #choose a mask proportion to look for a clear timestep\n",
    "        fc_ds = DEADataHandling.load_clearlandsat(dc, query,product='fc',masked_prop=0.90)\n",
    "\n",
    "        ### mask FC with polygon\n",
    "        fc_ds = fc_ds.where(mask_xr==False)\n",
    "\n",
    "        ### mask FC with wetness\n",
    "        fc_ds_noTCW=fc_ds.where(tcw==False)\n",
    "        #match timesteps\n",
    "        fc_ds_noTCW= fc_ds_noTCW.where(fc_ds_noTCW.time==tcw.time)\n",
    "        print('loaded fractional cover data')\n",
    "\n",
    "        print('calculating dominant fraction for each Fractional Cover pixel')\n",
    "        #drop data percentage and Unmixing Error\n",
    "        fc_tester = fc_ds_noTCW.drop(['data_perc','UE'])\n",
    "\n",
    "        #following robbi's advice, cast the dataset to a dataarray\n",
    "        maxFC = fc_tester.to_array(dim='variable', name='maxFC')\n",
    "\n",
    "        #turn FC array into integer only as nanargmax doesn't seem to handle floats the way we want it to\n",
    "        FC_int = maxFC.astype('int8')\n",
    "\n",
    "        #use numpy.nanargmax to get the index of the maximum value along the variable dimension\n",
    "        #BSPVNPV=np.nanargmax(FC_int, axis=0)\n",
    "        BSPVNPV=FC_int.argmax(dim='variable')\n",
    "\n",
    "        #work out where we have actual values!\n",
    "        FC_mask=xr.ufuncs.isfinite(maxFC).all(dim='variable')\n",
    "\n",
    "        # #re-mask with nans to remove no-data\n",
    "        BSPVNPV=BSPVNPV.where(FC_mask)\n",
    "\n",
    "        #restack the Fractional cover dataset all together\n",
    "        FC_dominant = xr.Dataset({\n",
    "            'BS': (BSPVNPV==0).where(FC_mask),\n",
    "            'PV': (BSPVNPV==1).where(FC_mask),\n",
    "            'NPV': (BSPVNPV==2).where(FC_mask),\n",
    "        })\n",
    "        # count number of Fractional Cover pixels for each cover type in area of interest\n",
    "        FC_count = FC_dominant.sum(dim=['x','y'])\n",
    "\n",
    "        ### Calculate number of pixels in area of interest\n",
    "        #number of pixels in area of interest\n",
    "        pixels = (mask_xr==0).sum(dim=['x','y'])\n",
    "\n",
    "        #count number of tcw pixels\n",
    "        tcw_pixel_count = tcw.sum(dim=['x','y'])\n",
    "\n",
    "        #count number of wofs pixels\n",
    "        wofs_pixels = wet_wofs.water.count(dim=['x','y'])+shadow_wofs.water.count(dim=['x','y'])\n",
    "\n",
    "        #count percentage of area of wofs\n",
    "        wofs_area_percent = (wofs_pixels/pixels)*100\n",
    "\n",
    "        #count number of tcw pixels\n",
    "        tcw_pixel_count = tcw.sum(dim=['x','y'])\n",
    "\n",
    "        #calculate percentage area wet\n",
    "        tcw_area_percent = (tcw_pixel_count/pixels)*100\n",
    "\n",
    "        #calculate wet not wofs\n",
    "        tcw_less_wofs = tcw_area_percent-wofs_area_percent\n",
    "\n",
    "        ### tasselled cap can actually be less than wofs!! (this is generally a bad sign... but possible)\n",
    "        # this will put a nan in here and wipe out the entire timestep. which is kinda what we want.\n",
    "        #tcw_less_wofs= tcw_less_wofs.where(tcw_less_wofs >0)\n",
    "        #alternatively we can gap fill with a 0. which is a bit sneaky and wrong\n",
    "        tcw_less_wofs = tcw_less_wofs.where(tcw_less_wofs>0,0)\n",
    "\n",
    "        ###Fractional cover pixel count method\n",
    "        #Get number of FC pixels, divide by total number of pixels per polygon\n",
    "        #Work out the number of nodata pixels in the data, so that we can graph the variables by number of observed pixels.\n",
    "\n",
    "        Bare_soil_percent=(FC_count.BS/pixels)*100\n",
    "\n",
    "        Photosynthetic_veg_percent=(FC_count.PV/pixels)*100\n",
    "\n",
    "        NonPhotosynthetic_veg_percent=(FC_count.NPV/pixels)*100\n",
    "\n",
    "        NoData = 100 - wofs_area_percent- tcw_less_wofs - Photosynthetic_veg_percent - NonPhotosynthetic_veg_percent - Bare_soil_percent\n",
    "\n",
    "        NoDataPixels = (NoData/100) * pixels\n",
    "\n",
    "        #now scale %of area by % of observed area using the number of actually observed pixels\n",
    "\n",
    "        Bare_soil_percent2=(FC_count.BS/(pixels - NoDataPixels))*100\n",
    "\n",
    "        Photosynthetic_veg_percent2=(FC_count.PV/(pixels- NoDataPixels))*100\n",
    "\n",
    "        NonPhotosynthetic_veg_percent2=(FC_count.NPV/(pixels- NoDataPixels))*100\n",
    "\n",
    "        #recalculate wofs area %\n",
    "        wofs_area_percent2 = (wofs_pixels/(pixels - NoDataPixels))*100\n",
    "        #recount tcw %\n",
    "        tcw_pixel_count2 = tcw.sum(dim=['x','y'])\n",
    "\n",
    "        #recalculate percentage area wet\n",
    "        tcw_area_percent2 = (tcw_pixel_count2/(pixels - NoDataPixels))*100\n",
    "\n",
    "        #recalculate percentage area wet\n",
    "        tcw_area_percent2 = (tcw_pixel_count2/(pixels - NoDataPixels))*100\n",
    "\n",
    "        #recalculate wet not wofs\n",
    "        tcw_less_wofs2 = tcw_area_percent2-wofs_area_percent2\n",
    "\n",
    "        #alternatively we can gap fill with a 0. which is a bit sneaky and wrong\n",
    "        tcw_less_wofs2 = tcw_less_wofs2.where(tcw_less_wofs2>0,0)\n",
    "\n",
    "        #last check for timestep matching before we plot\n",
    "        wofs_area_percent2=wofs_area_percent2.where(wofs_area_percent2.time==Bare_soil_percent2.time)\n",
    "        Bare_soil_percent2=Bare_soil_percent2.where(Bare_soil_percent2.time==wofs_area_percent2.time)\n",
    "        Photosynthetic_veg_percent2=Photosynthetic_veg_percent2.where(Photosynthetic_veg_percent2.time==wofs_area_percent2.time)\n",
    "        NonPhotosynthetic_veg_percent2=NonPhotosynthetic_veg_percent2.where(NonPhotosynthetic_veg_percent2.time==wofs_area_percent2.time)\n",
    "\n",
    "\n",
    "        #set up color palette\n",
    "        pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "               sns.xkcd_rgb[\"neon blue\"],\n",
    "               sns.xkcd_rgb[\"grass\"],\n",
    "               sns.xkcd_rgb[\"beige\"],\n",
    "               sns.xkcd_rgb[\"brown\"]]       \n",
    "\n",
    "        #make a stacked area plot\n",
    "        plt.clf()\n",
    "        fig= plt.figure(figsize = (12,4))\n",
    "        plt.stackplot(wofs_area_percent.time.values, \n",
    "                      wofs_area_percent2, \n",
    "                      tcw_less_wofs2, \n",
    "                      Photosynthetic_veg_percent2, \n",
    "                      NonPhotosynthetic_veg_percent2,\n",
    "                      Bare_soil_percent2,\n",
    "                      labels=['open water',\n",
    "                              'wet',\n",
    "                              'green veg',\n",
    "                              'dead veg',\n",
    "                              'bare soil',\n",
    "                             ], colors=pal, alpha = 0.6)\n",
    "        plt.title(f'Percentage of area WOfS, Wetness, Fractional Cover for {polyName}')\n",
    "\n",
    "\n",
    "        #set axis limits to the min and max\n",
    "        plt.axis(xmin = wofs_area_percent2.time[0].data, xmax = wofs_area_percent2.time[-1].data, ymin = 0, ymax = 100)\n",
    "\n",
    "        #add a legend and a tight plot box\n",
    "        plt.legend(loc='lower left', framealpha=0.6)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        #create rectangle borders for no-data times (SLC-off only)\n",
    "        LS5_8_gap_start = datetime(2011,11,1)\n",
    "        LS5_8_gap_end = datetime(2013,4,1)\n",
    "\n",
    "        # convert to matplotlib date representation\n",
    "        gap_start = mdates.date2num(LS5_8_gap_start)\n",
    "        gap_end = mdates.date2num(LS5_8_gap_end)\n",
    "        gap = gap_end - gap_start\n",
    "\n",
    "\n",
    "        #set date ticks every year\n",
    "        years = mdates.YearLocator(2)\n",
    "        yearsFmt = mdates.DateFormatter('%Y')\n",
    "        ax = plt.gca()\n",
    "\n",
    "        #set up rectangle\n",
    "        slc_rectangle= Rectangle((gap_start,0), gap, 100,alpha = 0.5, facecolor=sns.xkcd_rgb['white'],\n",
    "                     edgecolor=sns.xkcd_rgb['white'], hatch=\"////\",linewidth=2)\n",
    "        ax.add_patch(slc_rectangle)\n",
    "        fig.autofmt_xdate()\n",
    "\n",
    "        #save the figure\n",
    "        plt.savefig(f'{Output_dir}{polyName}.png')#, transparent=True)\n",
    "        plt.show()\n",
    "        print(f'plot created for {polyName}')\n",
    "\n",
    "        #make a new dataframe using the data from the xarray of wofs area for the polygon\n",
    "\n",
    "        ### start setup of dataframe by adding only one dataset\n",
    "        WOFS_df = pd.DataFrame(data=wofs_area_percent2.data, index=wofs_area_percent2.time.values,columns=['wofs_area_percent'])\n",
    "\n",
    "        #add data into pandas dataframe for export\n",
    "        WOFS_df['tcw_area_percent']=tcw_less_wofs2.data\n",
    "        WOFS_df['PV_percent']=Photosynthetic_veg_percent2.data\n",
    "        WOFS_df['NPV_percent']=NonPhotosynthetic_veg_percent2.data\n",
    "        WOFS_df['BS_percent']=Bare_soil_percent2.data\n",
    "\n",
    "        #call the composite dataframe something sensible, like PolyDrill\n",
    "        PolyDrill_df = WOFS_df.round(2)\n",
    "\n",
    "        #save the csv of the output data used to create the stacked plot for the polygon drill\n",
    "        PolyDrill_df.to_csv(f'{Output_dir}{polyName}.csv')\n",
    "        print(f'wrote output data to file {Output_dir}{polyName}.csv')\n",
    "        return 1\n",
    "    except:\n",
    "        print(f'did not run for {polyName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing polygon Hattah-Kulkyne_Lakes-Lake_Hattah-VIC-35\n",
      "Loading ls5\n",
      "    Loading 231 filtered ls5 timesteps\n",
      "Loading ls7\n",
      "    Ignoring SLC-off observations for ls7\n",
      "    Loading 52 filtered ls7 timesteps\n",
      "Loading ls8\n",
      "    Loading 82 filtered ls8 timesteps\n",
      "Combining and sorting ls5, ls7, ls8 data\n",
      "    Replacing invalid -999 values with NaN (data will be coerced to float64)\n",
      "running tasselled cap transform\n",
      "ran tasselled cap transform\n",
      "loading wofls\n",
      "wet and shadowed wofls acquired\n",
      "loading fractional cover data\n",
      "Loading ls5\n",
      "    Loading 231 filtered ls5 timesteps\n"
     ]
    }
   ],
   "source": [
    "  #-----------------------------------------------------------------------#\n",
    "\n",
    "# Launch a process for each polygon.\n",
    "\n",
    "### for each shapefile in our subset of shapefiles:\n",
    "for shapes in shapessubset:\n",
    "    ### try to run the function once, for the shapefile and given crs\n",
    "    result = BigBadFunkyFunction(shapes, crs)\n",
    "    ### if result is False ie. doesn't run\n",
    "    if not result: \n",
    "        print('first go did not succeed')\n",
    "        ### Try to run the function again\n",
    "        result = BigBadFunkyFunction(shapes, crs)\n",
    "        ### if that didn't work:    \n",
    "        if not result:\n",
    "            print('second go did not succeed, running for last time')\n",
    "            ### try for a third and last time\n",
    "            result = BigBadFunkyFunction(shapes, crs)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Wrapped in the try-except clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-19-33f0a765104a>, line 230)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-33f0a765104a>\"\u001b[0;36m, line \u001b[0;32m230\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def UnwrappedBigBadFunkyFunction(lilshape,crs):\n",
    "    '''This is a function that does lots of things. It takes a single polygon and does all the things #FIXME '''\n",
    "### This is set up to be shapefile-specific. I'm not sure this can be avoided, as often shapefiles are pretty specific..\n",
    "\n",
    "    first_geometry = lilshape['geometry']\n",
    "    polyName = get_RAMSAR_polyName(lilshape)\n",
    "    geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "    query = {'geopolygon': geom, 'time': ('2001-01-01', '2003-01-01') }# this should run for all time, if there is no time set?\n",
    "    #load and mask data. selecting data with more than 90% clear for the geobox around the polygon... #FIXME\n",
    "    ls578_ds, mask_xr= get_masked_ls578_data(query,geom)\n",
    "    print('running tasselled cap transform')\n",
    "    #calculate tasselled cap wetness within masked AOI\n",
    "    tcw = get_masked_tcw(ls578_ds, mask_xr, threshold=-350)\n",
    "    print('ran tasselled cap transform')\n",
    "    ### load wofls and select only wet pixels\n",
    "    print('loading wofls')\n",
    "\n",
    "    #wofls = dc.load(product = 'wofs_albers', like=ls578_ds, fuse_func=wofs_fuser)\n",
    "    wofls = dc.load(product = 'wofs_albers',fuse_func=wofs_fuser, **query)\n",
    "    #match wofs to tcw, because we didn't filter wofs for slc-off yet\n",
    "    wofls = wofls.where(wofls.time==tcw.time)\n",
    "    # #reapply the polygon mask\n",
    "    wofls = wofls.where(mask_xr==False)\n",
    "    #use bit values in wofs to select wet observations\n",
    "    wet_wofs = wofls.where(wofls.water==128)\n",
    "    #but also get the terrain and low-angle shadow wofs for this application\n",
    "    shadow_wofs = wofls.where(wofls.water== 136) #use bit values for wet (128) and terrain/low-angle (8)\n",
    "    print('wet and shadowed wofls acquired')\n",
    "\n",
    "    #------\n",
    "    #create a combined wofs dataset to mask fractional cover with\n",
    "    all_wofs=wet_wofs.copy(deep=True)\n",
    "    #fill wet_wofs with shadow_wofs, where wet_wofs is nan\n",
    "    combined_wofs = all_wofs.fillna(shadow_wofs)\n",
    "\n",
    "\n",
    "    ### load in fractional cover data\n",
    "    print('loading fractional cover data')\n",
    "    #load the data according to our query\n",
    "    #choose a mask proportion to look for a clear timestep\n",
    "    fc_ds = DEADataHandling.load_clearlandsat(dc, query,product='fc',masked_prop=0.90)\n",
    "\n",
    "    ### mask FC with polygon\n",
    "    fc_ds = fc_ds.where(mask_xr==False)\n",
    "\n",
    "    ### mask FC with wetness\n",
    "    fc_ds_noTCW=fc_ds.where(tcw==False)\n",
    "    #match timesteps\n",
    "    fc_ds_noTCW= fc_ds_noTCW.where(fc_ds_noTCW.time==tcw.time)\n",
    "    print('loaded fractional cover data')\n",
    "\n",
    "    print('calculating dominant fraction for each Fractional Cover pixel')\n",
    "    #drop data percentage and Unmixing Error\n",
    "    fc_tester = fc_ds_noTCW.drop(['data_perc','UE'])\n",
    "\n",
    "    #following robbi's advice, cast the dataset to a dataarray\n",
    "    maxFC = fc_tester.to_array(dim='variable', name='maxFC')\n",
    "\n",
    "    #turn FC array into integer only as nanargmax doesn't seem to handle floats the way we want it to\n",
    "    FC_int = maxFC.astype('int8')\n",
    "\n",
    "    #use numpy.nanargmax to get the index of the maximum value along the variable dimension\n",
    "    #BSPVNPV=np.nanargmax(FC_int, axis=0)\n",
    "    BSPVNPV=FC_int.argmax(dim='variable')\n",
    "\n",
    "    #work out where we have actual values!\n",
    "    FC_mask=xr.ufuncs.isfinite(maxFC).all(dim='variable')\n",
    "\n",
    "    # #re-mask with nans to remove no-data\n",
    "    BSPVNPV=BSPVNPV.where(FC_mask)\n",
    "\n",
    "    #restack the Fractional cover dataset all together\n",
    "    FC_dominant = xr.Dataset({\n",
    "        'BS': (BSPVNPV==0).where(FC_mask),\n",
    "        'PV': (BSPVNPV==1).where(FC_mask),\n",
    "        'NPV': (BSPVNPV==2).where(FC_mask),\n",
    "    })\n",
    "    # count number of Fractional Cover pixels for each cover type in area of interest\n",
    "    FC_count = FC_dominant.sum(dim=['x','y'])\n",
    "\n",
    "    ### Calculate number of pixels in area of interest\n",
    "    #number of pixels in area of interest\n",
    "    pixels = (mask_xr==0).sum(dim=['x','y'])\n",
    "\n",
    "    #count number of tcw pixels\n",
    "    tcw_pixel_count = tcw.sum(dim=['x','y'])\n",
    "\n",
    "    #count number of wofs pixels\n",
    "    wofs_pixels = wet_wofs.water.count(dim=['x','y'])+shadow_wofs.water.count(dim=['x','y'])\n",
    "\n",
    "    #count percentage of area of wofs\n",
    "    wofs_area_percent = (wofs_pixels/pixels)*100\n",
    "\n",
    "    #count number of tcw pixels\n",
    "    tcw_pixel_count = tcw.sum(dim=['x','y'])\n",
    "\n",
    "    #calculate percentage area wet\n",
    "    tcw_area_percent = (tcw_pixel_count/pixels)*100\n",
    "\n",
    "    #calculate wet not wofs\n",
    "    tcw_less_wofs = tcw_area_percent-wofs_area_percent\n",
    "\n",
    "    ### tasselled cap can actually be less than wofs!! (this is generally a bad sign... but possible)\n",
    "    # this will put a nan in here and wipe out the entire timestep. which is kinda what we want.\n",
    "    #tcw_less_wofs= tcw_less_wofs.where(tcw_less_wofs >0)\n",
    "    #alternatively we can gap fill with a 0. which is a bit sneaky and wrong\n",
    "    tcw_less_wofs = tcw_less_wofs.where(tcw_less_wofs>0,0)\n",
    "\n",
    "    ###Fractional cover pixel count method\n",
    "    #Get number of FC pixels, divide by total number of pixels per polygon\n",
    "    #Work out the number of nodata pixels in the data, so that we can graph the variables by number of observed pixels.\n",
    "\n",
    "    Bare_soil_percent=(FC_count.BS/pixels)*100\n",
    "\n",
    "    Photosynthetic_veg_percent=(FC_count.PV/pixels)*100\n",
    "\n",
    "    NonPhotosynthetic_veg_percent=(FC_count.NPV/pixels)*100\n",
    "\n",
    "    NoData = 100 - wofs_area_percent- tcw_less_wofs - Photosynthetic_veg_percent - NonPhotosynthetic_veg_percent - Bare_soil_percent\n",
    "\n",
    "    NoDataPixels = (NoData/100) * pixels\n",
    "\n",
    "    #now scale %of area by % of observed area using the number of actually observed pixels\n",
    "\n",
    "    Bare_soil_percent2=(FC_count.BS/(pixels - NoDataPixels))*100\n",
    "\n",
    "    Photosynthetic_veg_percent2=(FC_count.PV/(pixels- NoDataPixels))*100\n",
    "\n",
    "    NonPhotosynthetic_veg_percent2=(FC_count.NPV/(pixels- NoDataPixels))*100\n",
    "\n",
    "    #recalculate wofs area %\n",
    "    wofs_area_percent2 = (wofs_pixels/(pixels - NoDataPixels))*100\n",
    "    #recount tcw %\n",
    "    tcw_pixel_count2 = tcw.sum(dim=['x','y'])\n",
    "\n",
    "    #recalculate percentage area wet\n",
    "    tcw_area_percent2 = (tcw_pixel_count2/(pixels - NoDataPixels))*100\n",
    "\n",
    "    #recalculate percentage area wet\n",
    "    tcw_area_percent2 = (tcw_pixel_count2/(pixels - NoDataPixels))*100\n",
    "\n",
    "    #recalculate wet not wofs\n",
    "    tcw_less_wofs2 = tcw_area_percent2-wofs_area_percent2\n",
    "\n",
    "    #alternatively we can gap fill with a 0. which is a bit sneaky and wrong\n",
    "    tcw_less_wofs2 = tcw_less_wofs2.where(tcw_less_wofs2>0,0)\n",
    "\n",
    "    #last check for timestep matching before we plot\n",
    "    wofs_area_percent2=wofs_area_percent2.where(wofs_area_percent2.time==Bare_soil_percent2.time)\n",
    "    Bare_soil_percent2=Bare_soil_percent2.where(Bare_soil_percent2.time==wofs_area_percent2.time)\n",
    "    Photosynthetic_veg_percent2=Photosynthetic_veg_percent2.where(Photosynthetic_veg_percent2.time==wofs_area_percent2.time)\n",
    "    NonPhotosynthetic_veg_percent2=NonPhotosynthetic_veg_percent2.where(NonPhotosynthetic_veg_percent2.time==wofs_area_percent2.time)\n",
    "\n",
    "\n",
    "    #set up color palette\n",
    "    pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "           sns.xkcd_rgb[\"neon blue\"],\n",
    "           sns.xkcd_rgb[\"grass\"],\n",
    "           sns.xkcd_rgb[\"beige\"],\n",
    "           sns.xkcd_rgb[\"brown\"]]       \n",
    "\n",
    "    #make a stacked area plot\n",
    "    plt.clf()\n",
    "    fig= plt.figure(figsize = (12,4))\n",
    "    plt.stackplot(wofs_area_percent.time.values, \n",
    "                  wofs_area_percent2, \n",
    "                  tcw_less_wofs2, \n",
    "                  Photosynthetic_veg_percent2, \n",
    "                  NonPhotosynthetic_veg_percent2,\n",
    "                  Bare_soil_percent2,\n",
    "                  labels=['open water',\n",
    "                          'wet',\n",
    "                          'green veg',\n",
    "                          'dead veg',\n",
    "                          'bare soil',\n",
    "                         ], colors=pal, alpha = 0.6)\n",
    "    plt.title(f'Percentage of area WOfS, Wetness, Fractional Cover for {polyName}')\n",
    "\n",
    "\n",
    "    #set axis limits to the min and max\n",
    "    plt.axis(xmin = wofs_area_percent2.time[0].data, xmax = wofs_area_percent2.time[-1].data, ymin = 0, ymax = 100)\n",
    "\n",
    "    #add a legend and a tight plot box\n",
    "    plt.legend(loc='lower left', framealpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #create rectangle borders for no-data times (SLC-off only)\n",
    "    LS5_8_gap_start = datetime(2011,11,1)\n",
    "    LS5_8_gap_end = datetime(2013,4,1)\n",
    "\n",
    "    # convert to matplotlib date representation\n",
    "    gap_start = mdates.date2num(LS5_8_gap_start)\n",
    "    gap_end = mdates.date2num(LS5_8_gap_end)\n",
    "    gap = gap_end - gap_start\n",
    "\n",
    "\n",
    "    #set date ticks every year\n",
    "    years = mdates.YearLocator(2)\n",
    "    yearsFmt = mdates.DateFormatter('%Y')\n",
    "    ax = plt.gca()\n",
    "        \n",
    "    #set up rectangle\n",
    "    slc_rectangle= Rectangle((gap_start,0), gap, 100,alpha = 0.5, facecolor=sns.xkcd_rgb['white'],\n",
    "                 edgecolor=sns.xkcd_rgb['white'], hatch=\"////\",linewidth=2)\n",
    "    ax.add_patch(slc_rectangle)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    #save the figure\n",
    "    plt.savefig(f'{Output_dir}{polyName}.png')#, transparent=True)\n",
    "    plt.show()\n",
    "    print(f'plot created for {polyName}')\n",
    "\n",
    "    #make a new dataframe using the data from the xarray of wofs area for the polygon\n",
    "\n",
    "    ### start setup of dataframe by adding only one dataset\n",
    "    WOFS_df = pd.DataFrame(data=wofs_area_percent2.data, index=wofs_area_percent2.time.values,columns=['wofs_area_percent'])\n",
    "\n",
    "    #add data into pandas dataframe for export\n",
    "    WOFS_df['tcw_area_percent']=tcw_less_wofs2.data\n",
    "    WOFS_df['PV_percent']=Photosynthetic_veg_percent2.data\n",
    "    WOFS_df['NPV_percent']=NonPhotosynthetic_veg_percent2.data\n",
    "    WOFS_df['BS_percent']=Bare_soil_percent2.data\n",
    "\n",
    "    #call the composite dataframe something sensible, like PolyDrill\n",
    "    PolyDrill_df = WOFS_df.round(2)\n",
    "\n",
    "    #save the csv of the output data used to create the stacked plot for the polygon drill\n",
    "    PolyDrill_df.to_csv(f'{Output_dir}{polyName}.csv')\n",
    "    print(f'wrote output data to file {Output_dir}{polyName}.csv')\n",
    "    return 1\n",
    "except:\n",
    "    print(f'Did not run for {polyName}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #-----------------------------------------------------------------------#\n",
    "\n",
    "# Launch a process for each polygon.\n",
    "\n",
    "### for each shapefile in our subset of shapefiles:\n",
    "for shapes in shapessubset:\n",
    "    ### try to run the function once, for the shapefile and given crs\n",
    "    result = UnwrappedBigBadFunkyFunction(shapes, crs)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
